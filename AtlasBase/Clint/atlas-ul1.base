@extract -b @(topd)/gen.inc what=crsetup
@ROUT dcases.axpy scases.axpy
9
1 2 0 0 axpy1_x0y0.c       "R. Clint Whaley"
2 2 1 1 axpy1_x1y1.c       "R. Clint Whaley"
3 2 1 1 axpy32_x1y1.c      "R. Clint Whaley"
4 2 1 1 axpy32p32_x1y1.c   "R. Clint Whaley"
5 2 1 1 axpy8p8m0_x1y1.c   "R. Clint Whaley"
6 2 1 1 axpy16p4x16_x1y1.c "R. Clint Whaley"
7 2 1 1 axpy16p4m0_x1y1.c  "R. Clint Whaley"
8 2 1 1 axpy4p40_x1y1.c    "R. Clint Whaley"
@ROUT dcases.axpy
9 2 1 1 daxpy_sse2.c        "R. Clint Whaley" \
@ROUT scases.axpy
9 2 1 1 saxpy_sse.c         "R. Clint Whaley" \
@ROUT dcases.axpy scases.axpy
gcc
-x assembler-with-cpp
@ROUT zcases.axpy
8
@ROUT ccases.axpy
7
@ROUT ccases.axpy zcases.axpy
1 2 0 0 caxpy1_x0y0.c       "R. Clint Whaley"
2 2 1 1 caxpy1_x1y1.c       "R. Clint Whaley"
3 2 1 1 caxpy8p1_x1y1.c     "R. Clint Whaley"
4 2 1 1 caxpy8p4m0_x1y1.c   "R. Clint Whaley"
5 0 1 1 caxpy1_a0x0y0.c     "R. Clint Whaley"
6 2 1 1 caxpy2p32_x1y1.c    "R. Clint Whaley"
@ROUT zcases.axpy
7 2 1 1 zaxpy_sse3.c        "R. Clint Whaley" \
@ROUT ccases.axpy
7 2 1 1 caxpy_sse3.c        "R. Clint Whaley" \
@ROUT ccases.axpy zcases.axpy
gcc
-x assembler-with-cpp
@ROUT zcases.axpy
8 2 1 1 zaxpy_avx.c        "R. Clint Whaley" \
gcc
-x assembler-with-cpp
@ROUT ccases.axpy zcases.axpy scases.axpy dcases.axpy

<ID> <alpha> <incX> <incY> <rout> <author> [\
 <CC>
  <CCFLAGS>]

  ID : unique num > 0
  <alpha> valid values are 1, -1; all others are X.

<ID> <alpha> <incX> <incY> <rout> <author> [\
 <CC>
  <CCFLAGS>]

  ID : unique num > 0
@ROUT ccases.axpy zcases.axpy
  <alpha> valid values are 1, -1, and 0 (means imag component 0, real X);
          all others are X.
@ROUT scases.axpy dcases.axpy
  <alpha> valid values are 1, -1; all others are X.
@ROUT ccases.axpy zcases.axpy scases.axpy dcases.axpy
  <incX> : 0 - any inc, all other is fixed incX
  <incY> : 0 - any inc, all other is fixed incY

          name key: axpy<unroll>p<prefetch>m<muladd>_x<incX>y<incY>.c
          if p is not there, no prefetch
          if m not there, muladd=1 (combined multiply/add instruction
@ROUT asum_stub
   @define rt @asum@
@ROUT nrm2_stub
   @define rt @nrm2@
@ROUT asum_stub nrm2_stub
#include "atlas_misc.h"
TYPE ATL_U@up@(rt)(const int N, const TYPE *X, const int incX);

TYPE ATL_@up@(rt)(const int N, const TYPE *X, const int incX)
@ROUT set_stub
   @define rt @set@
@ROUT scal_stub
   @define rt @scal@
@ROUT scal_stub set_stub
#include "atlas_misc.h"
void ATL_U@up@(rt)(const int N, const SCALAR alpha, TYPE *X, const int incX);

void ATL_@up@(rt)(const int N, const SCALAR alpha, TYPE *X, const int incX)
@ROUT scal_stub asum_stub nrm2_stub set_stub
{
   int incx;
   if (N > 0)
   {
      if (incX > 0) incx = incX;
      else if (incX < 0)
      {
         X += ((N-1)SHIFT) * incX;
         incx = -incX;
      }
@ROUT asum_stub nrm2_stub
      else return(ATL_rzero);
      return(ATL_U@up@(rt)(N, X, incx));
@ROUT scal_stub set_stub
      else return;
      ATL_U@up@(rt)(N, alpha, X, incx);
@ROUT scal_stub asum_stub nrm2_stub set_stub
   }
@ROUT asum_stub nrm2_stub
   return(ATL_rzero);
@ROUT scal_stub asum_stub nrm2_stub set_stub
}
@ROUT dot_stub
   @define rt @dot@
@ROUT swap_stub
   @define rt @swap@
@ROUT copy_stub
   @define rt @copy@
@ROUT dot_stub
#include "atlas_misc.h"
#ifdef TREAL
   TYPE ATL_UDOT(const int N, const TYPE *X, const int incX, 
                const TYPE *Y, const int incY);
#else
   void ATL_UDOT(const int N, const TYPE *X, const int incX, 
                 const TYPE *Y, const int incY, SCALAR dot);
#endif

#ifdef TREAL
   TYPE ATL_DOT(const int N, const TYPE *X, const int incX, 
                const TYPE *Y, const int incY)
#else
   void ATL_DOT(const int N, const TYPE *X, const int incX, 
                const TYPE *Y, const int incY, SCALAR dot)
#endif
{
   #ifdef TREAL
      TYPE dot=ATL_rzero;
   #endif
@ROUT rot_stub
   @define rt @rot@
#include "atlas_misc.h"
void ATL_ROT(const int N, TYPE *X, const int incX, TYPE *Y, const int incY,
             TYPE c, TYPE s)
{
   void ATL_UROT(const int, TYPE *, const int, TYPE *, const int, TYPE, TYPE);
@ROUT swap_stub
#include "atlas_misc.h"
void ATL_USWAP(const int N, TYPE *X, const int incX, TYPE *Y, const int incY);

void ATL_SWAP(const int N, TYPE *X, const int incX,
@ROUT copy_stub
#include "atlas_misc.h"
void ATL_UCOPY(const int N, const TYPE *X, const int incX,
               TYPE *Y, const int incY);

void ATL_@up@(rt)(const int N, const TYPE *X, const int incX,
@ROUT axpby_stub
   @define rt @axpby@
@ROUT axpy_stub
   @define rt @axpy@
@ROUT cpsc_stub
   @define rt @cpsc@
@ROUT axpy_stub cpsc_stub axpby_stub
#include "atlas_misc.h"
@ROUT axpby_stub
void ATL_UAXPBY(const int N, const SCALAR alpha, const TYPE *X, const int incX,
                const SCALAR beta, TYPE *Y, const int incY);
@ROUT axpy_stub cpsc_stub
void ATL_U@up@(rt)(const int N, const SCALAR alpha, const TYPE *X, const int incX,
               TYPE *Y, const int incY);
@ROUT axpy_stub cpsc_stub axpby_stub

void ATL_@up@(rt)(const int N, const SCALAR alpha, const TYPE *X, const int incX,
@ROUT axpby_stub
               const SCALAR beta, TYPE *Y, const int incY)
{
@ROUT axpy_stub copy_stub swap_stub cpsc_stub
              TYPE *Y, const int incY)
{
@ROUT axpy_stub copy_stub swap_stub dot_stub cpsc_stub axpby_stub rot_stub
   int incx=incX, incy=incY;

@ROUT axpby_stub swap_stub copy_stub dot_stub rot_stub `   if (N > 0)`
@ROUT axpy_stub cpsc_stub `   if (!SCALAR_IS_ZERO(alpha) && N > 0)`
   {
/*
 *    Manipulate incX and inxY such that:
 *    -  Both are positive
 *    -  else if incX or incY has abs()=1, make it positive
 *    -  if both abs(inc) are 1, or if neither, make incY positive
 */
      if (incX > 0 && incY > 0) goto L1;
      else if (incY < 0)
      {
         if (incX < 0) /* make both positive */
         {
            incx = -incX;
            incy = -incY;
            X += ((N-1)SHIFT)*incX;
            Y += ((N-1)SHIFT)*incY;
         }
         else if (incX != 1 || incY == -1)
         {
            incy = -incY;
            Y += ((N-1)SHIFT)*incY;
            incx = -incX;
            X += ((N-1)SHIFT)*incX;
         }
      }
      else if (incX == -1 && incY != 1)
      {
         incx = 1;
         X -= ((N-1)SHIFT);
         incy = -incY;
         Y += ((N-1)SHIFT)*incY;
      }
@ROUT dot_stub
   #ifdef TREAL
      else if (!incX || !incY) return(0.0);
   #else
      else if (!incX || !incY) {*dot = dot[1] = 0.0; return;}
   #endif
@ROUT axpy_stub copy_stub swap_stub cpsc_stub axpby_stub rot_stub
      else if (!incX || !incY) return;
@ROUT axpy_stub copy_stub swap_stub dot_stub cpsc_stub axpby_stub rot_stub
L1:
@ROUT dot_stub
      #ifdef TREAL
         dot = ATL_UDOT(N, X, incx, Y, incy);
      #else
         ATL_UDOT(N, X, incx, Y, incy, dot);
      #endif
@ROUT rot_stub
      ATL_U@up@(rt)(N, X, incx, Y, incy, c, s);
@ROUT swap_stub copy_stub 
      ATL_U@up@(rt)(N, X, incx, Y, incy);
@ROUT axpby_stub
      ATL_U@up@(rt)(N, alpha, X, incx, beta, Y, incy);
@ROUT axpy_stub cpsc_stub
      ATL_U@up@(rt)(N, alpha, X, incx, Y, incy);
@ROUT axpy_stub copy_stub swap_stub dot_stub cpsc_stub axpby_stub rot_stub
   }
@ROUT dot_stub 
   #ifdef TREAL
      return(dot);
   #endif
@ROUT axpy_stub copy_stub swap_stub dot_stub cpsc_stub axpby_stub rot_stub
}
@ROUT !
@ifdef ! iu
   @define iu @32@
@endifdef
@ROUT zdot1_x1y1_sse2
#include "atlas_asm.h"

#ifndef ATL_SSE2
   #error "This kernel requires SSE2"
#endif
#ifdef ATL_GAS_x8632
   #define FSIZE 4
   #define movq movl
   #define addq addl
   #define subq subl
   #define rsp  esp
   #define rax  eax
   #define N    %edi
   #define X    %edx
   #define Y    %ecx
   #define II   %eax
#else
   #define N    %rdi
   #define X    %rsi
   #define Y    %rcx
   #define II   %rax
#endif

#define rSr     %xmm0
#define rSi     %xmm1
#define rX      %xmm2
#define rY      %xmm3
#define rZ      %xmm4

#ifdef ATL_ARCH_Core2
   #define MOVAPD movaps
   #define MOVUPD movups
#else
   #define MOVAPD movapd
   #define MOVUPD movupd
#endif
#define PREFX   prefetchnta
#define PREFY   PREFX
#ifndef YDIST
   #define YDIST   1152
#endif
#ifndef XDIST
   #define XDIST   YDIST
#endif
/*
                rdi/4              rsi/8          rdx/12
void ATL_UDOT(const int N, const TYPE *X, const int incx,
                     rcx/16           r8/20   r9/24
              const TYPE *Y, const int incy, TYPE *dot)
 */
.text
.global  ATL_asmdecor(ATL_UDOT)
ATL_asmdecor(ATL_UDOT):
#ifdef ATL_GAS_x8632
        subl    $FSIZE, %esp
        movl    %edi, (%esp)
        movl    FSIZE+4(%esp), N
        movl    FSIZE+8(%esp), X
        movl    FSIZE+16(%esp), Y
#endif
        xorpd   rSr, rSr        /* zero running sum for real components */
        xorpd   rSi, rSi        /* zero running sum for imaginary comps */
        mov     N, II                   /* II = N */
        shl     $4, II                  /* II = N * sizeof */
        add     II, X                   /* X += N */
        add     II, Y                   /* Y += N */
        neg     II                      /* II = -N * sizeof */
        test    $0xF, X
        jnz     UNALIGNED
        test    $0xF, Y
        jnz     UNALIGNED
@beginproc dotloop lpname lpdone mov
        @(mov)  (X,II), rX              /* rX = {Xi, Xr} */
        pshufd  $0x4E, rX, rZ           /* rZ = {Xr, Xi} */
        @(mov)  (Y,II), rY              /* rY = {Yi, Yr} */
        add     $16, II
        jz      @(lpdone)
@skip .local @(lpname)
@(lpname):
        mulpd   rY, rX                /* rX = {Xi*Yi, Xr*Yr} */
        addpd   rX, rSr                /* real part of sum */
                @(mov)  (X,II), rX              /* rX = {Xi, Xr} */
        mulpd   rY, rZ                  /* rZ = {Xr*Yi, Xi*Yr} */
                @(mov)  (Y,II), rY              /* rY = {Yi, Yr} */
        addpd   rZ, rSi                 /* imag part of sum */
                pshufd  $0x4E, rX, rZ           /* rZ = {Xr, Xi} */
        add     $16, II
        jnz @(lpname)
@skip .local @(lpdone)
@(lpdone):
        mulpd   rY, rX                  /* rX = {Xi*Yi, Xr*Yr} */
        addpd   rX, rSr                 /* real part of sum */
        mulpd   rY, rZ                  /* rZ = {Xr*Yi, Xi*Yr} */
        addpd   rZ, rSi                 /* imag part of sum */
@endproc

@callproc dotloop LOOP1 LP1DONE MOVAPD

@beginskip
******
@beginproc dotloop lpname mov
@skip .local @(lpname)
@(lpname):
        @(mov)  (X,II), rX              /* rX = {Xi, Xr} */
        pshufd  $0x4E, rX, rXr          /* rXr= {Xr, Xi} */
        @(mov)  (Y,II), rY              /* rY = {Yi, Yr} */
        mulpd   rY, rX                  /* rX = {Xi*Yi, Xr*Yr} */
        addpd   rX, rSr                 /* real part of sum */
        mulpd   rY, rXr                 /* rXr= {Xr*Yi, Xi*Yr} */
        addpd   rXr, rSi                /* imag part of sum */
        add     $16, II
        jnz @(lpname)
@endproc
@callproc dotloop LOOP1 MOVAPD
******
@endskip
@skip .local DONE
DONE:
#ifdef ATL_SSE3                         /* rSr= {Xi*Yi, Xr*Yr} */
        hsubpd  rSr, rSr                /* rSr= {XXXXX, Xr*Yr-Xi*Yi} */
                                        /* rSi= {Xr*Yi, Xi*Yr} */
        haddpd  rSi, rSi                /* rSi= {XXXXX, Xi*Yr+Xr*Yi} */
#else                                   
        pshufd  $EE, rSr, rX            /* rX = {XXXXX, Xi*Yi} */
        subps   rX, rSr                 /* rSr= {XXXXX, Xr*Yr-Xi*Yi} */
        pushfd  $EE, rSi, rY            /* rY = {XXXXX, Xr*Yi} */
        addps   rY, rSi                 /* rSi= {XXXXX, Xi*Yr+Xr*Yi} */
#endif
#ifdef ATL_GAS_x8632
        movl    FSIZE+24(%esp), II
        movsd   rSr, (II)
        movsd   rSi, 8(II)
        movl    (%esp), %edi
        addl    $FSIZE, %esp
#else
        movsd  rSr, (%r9)
        movsd  rSi, 8(%r9)
#endif
        ret
/*
 *      Loop for when X or Y is not aligned to 16-byte boundary
 */
UNALIGNED:
@callproc dotloop ULOOP LPUDONE MOVUPD
        jmp DONE



@ROUT zaxpy_avx
@extract -b @(topd)/cw.inc lang=c -define cwdate 2011
#include "atlas_asm.h"

#ifndef ATL_AVX
   #error "This kernel requires AVX"
#endif

/*
 * vector registers
 */
#define ralp %ymm0
   #define ralp_ %xmm0
#define ialp %ymm1
   #define ialp_ %xmm1
#define y0   %ymm2
   #define y0_ %xmm2
#define x0   %ymm3
   #define x0_ %xmm3
#define x1   %ymm4
   #define x1_ %xmm4
/*
 * Integer registers
 */
#ifdef ATL_GAS_x8632
   #define N  %ebx
   #define X  %edx
   #define Y  %ecx
   #define II %eax
#elif defined(ATL_GAS_x8664)
   #define N       %rdi
   #define X       %rdx
   #define Y       %rcx
   #define II      %rax
#else
   #error "This routine requires x86 assembly!"
#endif
#define Y_b  %cl
#define X_b  %dl
#define II_b %al

#ifndef PFW
   #define PFW prefetchnta
#endif
#ifndef PFR
   #define PFR prefetchnta
#endif
#ifndef PFDIST
   #define PFDIST 768
#endif
/*
                    rdi/ 4              rsi/8         rdx/12          rcx/16
void ATL_UAXPY(const int N, const TYPE *alpha, const TYPE *X, const int incX,
                 r8/20          r9/24
               TYPE *Y, const int incY)
*/
.text
.globl ATL_asmdecor(ATL_UAXPY)
ATL_asmdecor(ATL_UAXPY):

#ifdef ATL_GAS_x8632
   #define FSIZE 16
   sub $FSIZE, %esp
   movl %ebx, (%esp)
   movl %esi, 4(%esp)
   movl FSIZE+4(%esp), N
   movl FSIZE+8(%esp), %esi
   movl FSIZE+12(%esp), %edx
   movl FSIZE+20(%esp), Y
   #define TMPOFF 8(%esp)
   #define rsi esi
#else
   mov %r8, Y
   #define TMPOFF -8(%rsp)
#endif
   fld1                                 /* ST = {1.0} */
   fldz                                 /* ST = {0.0, 1.0} */
   PFR (X)
   fsubp                                /* ST = {-1.0} */
   fmull 8(%rsi)                        /* ST = {-ai} */
   fstpl TMPOFF                         /* ST={}, store -ia to tmp */
   PFW (Y)
   vbroadcastsd 8(%rsi), ialp           /*  ai  ai  ai  ai */
   vbroadcastsd TMPOFF, ralp          /* -ia -ia -ia -ia */
   vblendpd $0x5, ralp, ialp, ialp      /*  ai -ai  ai -ai */
   vbroadcastsd (%rsi), ralp            /*  ar  ar  ar  ar */
/*
 * If Y is not 16-byte aligned, then it can never be 32-byte aligned
 */
   test $0x0F, Y_b
   jnz UNALIGNED
   test $0x1F, Y_b
   jz YALIGNED    /* jump to Y known to 32-byte aligned */
/*
 * If we reach here, Y is 16-byte aligned, so peel 1 iteration to make 32-byte
 */
   movupd (X), x0_              /* x0 = {xi, xr} */
   pshufd $0x4E, x0_, x1_       /* x1 = {xr, xi} */
   movapd (Y), y0_              /* y0 = {yi, yr} */
   mulpd ralp_, x0_             /* x0 = {ar*xi, ar*xr} */
   addpd x0_, y0_
   mulpd ialp_, x1_             /* x1 = {ai*xr,-ai*xi} */
   addpd x1_, y0_
   movapd y0_, (Y)
   add $16, X
   add $16, Y
   sub $1, N
   jz DONE
YALIGNED:   /* Y is known to be 32-byte aligned */
   cmp $4, N
   jb CLEANUP
   mov N, II
   andb $0xFE, II_b                     /* make II a multiple of veclen */
   sub II, N                            /* N now has how much must be cleaned */
   shl $4, II                           /* II = N*sizeof(DCPLX) */
   lea (X, II), X                       /* X += N */
   lea (Y, II), Y                       /* Y += N */
   neg II                               /* II = -II */
   test $0x1F, X_b                      /* if X not 32-byte aligned */
   jnz YAXULOOP                         /* jump to unaligned X loop */
   YAXALOOP:
      vmovapd (X,II), x0                /* x1i x1r x0i x0r */
      vshufpd $0x5, x0, x0, x1           /* x1r x1i x0r x0i */ 
      vmulpd ralp, x0, x0               /* ar*x1i, ar*x1r, ar*x0i, ar*x0r */
      vaddpd (Y,II), x0, y0       
      PFR PFDIST(X,II)
      vmulpd ialp, x1, x1               /* ai*x1r,-ai*x1i, ai*x0r,-ai*x0i */
      vaddpd x1, y0, y0
      PFW PFDIST(Y,II)
      vmovapd y0, (Y, II)
      add $32, II
   jnz YAXALOOP

   cmp $0, N
   jnz CLEANUP
DONE:
#ifdef ATL_GAS_x8632
   movl (%esp), %ebx
   movl 4(%esp), %esi
   add $FSIZE, %esp
#endif
   ret

   YAXULOOP:
      vmovupd (X,II), x0                /* x1i x1r x0i x0r */
      vshufpd $0x5, x0, x0, x1           /* x1r x1i x0r x0i */ 
      vmulpd ralp, x0, x0               /* ar*x1i, ar*x1r, ar*x0i, ar*x0r */
      vaddpd (Y,II), x0, y0       
      PFR PFDIST(X,II)
      vmulpd ialp, x1, x1               /* ai*x1r,-ai*x1i, ai*x0r,-ai*x0i */
      vaddpd x1, y0, y0
      PFW PFDIST(Y,II)
      vmovapd y0, (Y, II)
      add $32, II
   jnz YAXULOOP
   cmp $0, N
   jz DONE
   jmp CLEANUP
UNALIGNED:
   cmp $4, N
   jb CLEANUP
   mov N, II
   andb $0xFE, II_b                     /* make II a multiple of veclen */
   sub II, N                            /* N now has how much must be cleaned */
   shl $4, II                           /* II = N*sizeof(DCPLX) */
   lea (X, II), X                       /* X += N */
   lea (Y, II), Y                       /* Y += N */
   neg II                               /* II = -II */
   YUXULOOP:
      vmovupd (X,II), x0                /* x1i x1r x0i x0r */
      vshufpd  $0x5, x0, x0, x1         /* x1r x1i x0r x0i */ 
      vmovupd (Y,II), y0
      vmulpd ralp, x0, x0               /* ar*x1i, ar*x1r, ar*x0i, ar*x0r */
      vaddpd x0, y0, y0       
      PFR PFDIST(X,II)
      vmulpd ialp, x1, x1               /* ai*x1r,-ai*x1i, ai*x0r,-ai*x0i */
      vaddpd x1, y0, y0
      PFW PFDIST(Y,II)
      vmovupd y0, (Y, II)
      add $32, II
   jnz YUXULOOP
   cmp $0, N
   jz DONE

CLEANUP:
CULOOP:
   movupd (X), x0_              /* x0 = {xi, xr} */
   pshufd $0x4E, x0_, x1_       /* x1 = {xr, xi} */
   movupd (Y), y0_              /* y0 = {yi, yr} */
   mulpd ralp_, x0_             /* x0 = {ar*xi, ar*xr} */
   addpd x0_, y0_
   mulpd ialp_, x1_             /* x1 = {ai*xr,-ai*xi} */
   addpd x1_, y0_
   movupd y0_, (Y)
   add $16, X
   add $16, Y
   sub $1, N
jnz CULOOP
jmp DONE
@ROUT caxpy_sse3
#include "atlas_asm.h"

#ifndef ATL_SSE3
   #error "This kernel requires SSE3"
#endif
#ifdef ATL_GAS_x8632
   #define movq movl
   #define addq addl
   #define subq subl
   #define X    %eax
   #define Y    %edx
   #define N    %ecx
   #define Nr   %ebp
#elif defined(ATL_GAS_x8664)
   #define N    %rdi
   #define X    %rdx
   #define Y    %rcx
   #define Nr   %rax
#else
   #error "This kernel requires x86 assembly!"
#endif

#define alp1    %xmm0
#define alp2    %xmm1
#define rY0     %xmm2
#define rX0     %xmm3
#define rX1     %xmm4
#define salp    %xmm5   
#ifndef PFDIST
   #ifdef ATL_ARCH_P4E
      #define PFDIST 256   /* optimized for 32-bit P4E */
   #else
      #define PFDIST 512  /* opt for Athlon 64 X2 */
   #endif
#endif

# byte offset       %rdi   4          %rsi     8     %rdx    12      %rcx    16
# void ATL_UAXPY(const int N, const SCALAR alpha, const TYPE *X, const int incX,
#                TYPE *Y, const int incY)
#                %r8
        .text
.global ATL_asmdecor(ATL_UAXPY)
ATL_asmdecor(ATL_UAXPY):
#ifdef ATL_GAS_x8632
   #define OFF 8
        subl    $OFF, %esp
#
#       Put hi{1.0,-1.0}lo in rX0
#
        fld1
        fldz
        fsub    %st(1), %st
        fstps   0(%esp)
        fstps   4(%esp)
        movlps  (%esp), rX0        # rX0 = {XXX, XXX, 1.0, -1.0}
#
#       Store regs to stack and load parameters
#
        movl    %ebp, (%esp)
        movl    %ebx, 4(%esp)

        movl    OFF+4(%esp), N
        movl    OFF+8(%esp), Nr   # address of alpha
        movlps  (Nr),  alp1
        movl    OFF+12(%esp), X
        movl    OFF+20(%esp), Y
#else
        movq    %r8, Y
        movlps  (%rsi), alp1     # Load alpha
#
#       Put hi{1.0,-1.0}lo in rX0
#
        fld1
        fldz
        fsub    %st(1), %st
        fstps   -8(%rsp)
        fstps   -4(%rsp)
        movlps  -8(%rsp), rX0        # rX0 = {XXX, XXX, 1.0, -1.0}
#endif
        movlhps alp1, alp1             # alp1 = {ialpha, ralpha, ialpha, ralpha}
        prefetchw (Y)
        prefetchnta (X)
        movlhps rX0, rX0               # rX0  = {1.0   , -1.0  , 1.0   , -1.0  }
        pshufd  $0x11,alp1,alp2        # alp2 = {ralpha, ialpha, ralpha, ialpha}
        movaps  alp2, salp             # salp = {ralpha, ialpha, ralpha, ialpha}
        mulps   rX0, alp2              # alp2 = {ralpha, -ialph, ralpha, -ialph}
        mulss   rX0, salp              # salp = {ralpha, ialpha, ralpha, -ialph}
        pshufd  $0xE1,salp,salp        # salp = {ralpha, ialpha, -ialph, ralpha}
#
#       If X is only 4-byte aligned, it's alignment cannot be fixed, 
#       so go to crap code
#
        test    $0x7, X
        jnz     NOXALIGN
#
#       Force X to 16-byte boundary so we can use MOVSxDUP
#
        test    $0xF, X
        jz      XALIGNED
#
#       One peeled iteration to force X to 16-byte alignment
#
                                # salp = { ra,  ia, -ia,  ra}
        movlps  (X), rX0        # rX0  = { XX,  XX,  ix,  rx}
        xorps   rY0, rY0        # get rid of junk in top 64 bits
        movlhps rX0, rX0        # rX0  = { ix,  rx,  ix,  rx}
        movlps  (Y), rY0        # rY0  = {  0,   0,  iy,  ry}
        mulps   salp, rX0       # rX0  = {ra*ix, ia*rx, -ia*ix, ra*rx}
        haddps  rX0, rX0        # rX0  = {XX,XX, ra*ix+ia*rx, ra*rx-iaix}
        addps   rX0, rY0        # rY0  = {XX,XX, iyN, ryN}
        movlps  rY0, (Y)
        sub     $1, N
        add     $8, X
        add     $8, Y
XALIGNED:
        test    $0xF, Y
        jnz     YUNALIGNED

        mov     N, Nr
        shr     $1, N
        shl     $1, N
        lea     (X, N, 8), X
        lea     (Y, N, 8), Y
        neg     N
        add     N, Nr
        cmp     $0, N
        je      CLEANUP
        ALIGN16
NLOOP:
                                        # alp1 = {ia,   ra,  ia,  ra}
                                        # alp2 = {ra,  -ia,  ra, -ia}
        movsldup (X,N,8), rX0           # rX0  = {rx1, rx1, rx0, rx0}
        movshdup (X,N,8), rX1           # rX1  = {ix1, ix1, ix0, ix0}
        movaps  (Y,N,8), rY0            # rY0  = {iy1, ry1, iy0, ry0}
        mulps   alp1, rX0               # rX0  = {ia*rx1,ra*rx1,ia*rx0,ra*rx0}
        prefetchw      PFDIST(Y,N,8)
        addps   rX0, rY0                # rY0  gets 1st part of results
        mulps   alp2, rX1               # rX1  = {ra*ix1,-ia*ix1,ra*ix0,-ia*ix0}
        prefetcht0     PFDIST(X,N,8)
        addps   rX1, rY0                # rY0 gets last part of results
        movapd  rY0, (Y,N,8)
        addq    $2, N
        jnz     NLOOP
#
#       Do one more scalar iteration if there's a remainder
#
CLEANUP:
        cmp     $0, Nr
        je      DONE
                                # salp = { ra,  ia, -ia,  ra}
        movlps  (X), rX0        # rX0  = { XX,  XX,  ix,  rx}
        xorps   rY0, rY0        # get rid of junk in top 64 bits
        movlhps rX0, rX0        # rX0  = { ix,  rx,  ix,  rx}
        movlps  (Y), rY0        # rY0  = {  0,   0,  iy,  ry}
        mulps   salp, rX0       # rX0  = {ra*ix, ia*rx, -ia*ix, ra*rx}
        haddps  rX0, rX0        # rX0  = {XX,XX, ra*ix+ia*rx, ra*rx-iaix}
        addps   rX0, rY0        # rY0  = {XX,XX, iyN, ryN}
        movlps  rY0, (Y)
#
#       Epilogue
#
DONE:
#ifdef ATL_GAS_x8632
        movl    (%esp), %ebp
        movl    4(%esp), %ebx
        addl    $OFF, %esp
#endif
        ret
#
# This code assumes aligned X, but unaligned Y
#
YUNALIGNED:
        mov     N, Nr
        shr     $1, N
        shl     $1, N
        lea     (X,N,8), X
        lea     (Y,N,8), Y
        neg     N
        add     N, Nr
        cmp     $0, N
        je      CLEANUP
YUNLOOP:
                                        # alp1 = {ia,   ra,  ia,  ra}
                                        # alp2 = {ra,  -ia,  ra, -ia}
        movsldup (X,N,8), rX0           # rX0  = {rx1, rx1, rx0, rx0}
        movshdup (X,N,8), rX1           # rX1  = {ix1, ix1, ix0, ix0}
        movups  (Y,N,8), rY0            # rY0  = {iy1, ry1, iy0, ry0}
        mulps   alp1, rX0               # rX0  = {ia*rx1,ra*rx1,ia*rx0,ra*rx0}
        prefetchw      PFDIST(Y,N,8)
        addps   rX0, rY0                # rY0  gets 1st part of results
        mulps   alp2, rX1               # rX1  = {ra*ix1,-ia*ix1,ra*ix0,-ia*ix0}
        prefetcht0     PFDIST(X,N,8)
        addps   rX1, rY0                # rY0 gets last part of results
        movupd  rY0, (Y,N,8)
        addq    $2, N
        jnz     YUNLOOP
        jmp     CLEANUP
#
# X is not aligned even on 8-byte boundary, so cannot align it at all
# This shouldn't happen much, so just implement the unaligned Y case, 
# so this case implements neither vector aligned
#
NOXALIGN:
        mov     N, Nr
        shr     $1, N
        shl     $1, N
        lea     (X, N, 8), X
        lea     (Y, N, 8), Y
        neg     N
        add     N, Nr
        cmp     $0, N           # alp1 = { ia,  ra,  ia,  ra}
        je      CLEANUP         # salp = { ra,  ia, -ia,  ra}

        movsldup alp1, alp1     # alp1 = { ra,  ra,  ra,  ra}
        pshufd  $0x99,salp,alp2 # alp2 = { ia, -ia,  ia, -ia}
NOALOOP:                        
        movups  (X,N,8), rX0    # rX0  = {ix1, rx1, ix0, rx0}
        pshufd  $0xB1,rX0,rX1   # rX1  = {rx1, ix1, rx0, ix0}
        movups  (Y,N,8), rY0    # rY0  = {iy1, ry1, iy0, ry0}
        mulps   alp1, rX0       # rX0  = {ix1*ra, rx1*ra,ix0*ra, rx1*ra}
        prefetchw      PFDIST(Y,N,8)
        addps   rX0, rY0
        mulps   alp2, rX1       # rX1  = {rx1*ia,-ix1*ia,rx0*ia,-ix0*ia}
        prefetcht0     PFDIST(X,N,8)
        addps   rX1, rY0
        movups  rY0, (Y,N,8)
        add     $2, N
        jnz     NOALOOP
        jmp     CLEANUP
@ROUT zaxpy_sse3
#include "atlas_asm.h"

#ifndef ATL_SSE3
   #error "This kernel requires SSE3"
#endif
#ifdef ATL_GAS_x8632
   #define movq movl
   #define addq addl
   #define subq subl
   #define X    %eax
   #define Y    %edx
   #define N    %ecx
   #define Nr   %ebp
#elif defined(ATL_GAS_x8664)
   #define N    %rdi
   #define X    %rdx
   #define Y    %rcx
   #define Nr   %rax
#else
   #error "This kernel requires x86 assembly!"
#endif

#define alpha1  %xmm0
#define alpha2  %xmm1
#define rY0     %xmm2
#define rX0     %xmm3
#define rX1     %xmm4
#ifndef PFDIST
   #define PFDIST 512   /* optimized for 32-bit P4E/Athlon-64 X2 */
#endif

# byte offset        %rdi  4        %rsi       8     %rdx    12      %rcx    16
# void ATL_UAXPY(const int N, const SCALAR alpha, const TYPE *X, const int incX,
#                TYPE *Y, const int incY)
#                %r8
        .text
.global ATL_asmdecor(ATL_UAXPY)
ATL_asmdecor(ATL_UAXPY):
#ifdef ATL_GAS_x8632
   #define OFF 16
        subl    $OFF, %esp
#
#       Put hi{1.0,-1.0}lo in rX0
#
        fld1
        fldz
        fsub    %st(1), %st
        fstpl   0(%esp)
        fstpl   8(%esp)
        movupd  (%esp), rX0        # rX0 = {1.0, -1.0}
#
#       Store regs to stack and load parameters
#
        movl    %ebp, (%esp)
        movl    %ebx, 4(%esp)

        movl    OFF+4(%esp), N
        movl    OFF+8(%esp), Nr   # address of alpha
        movupd  (Nr),  alpha1
        movl    OFF+12(%esp), X
        movl    OFF+20(%esp), Y
#else
        movq    %r8, Y
        movupd  (%rsi), alpha1
#
#       Put hi{1.0,-1.0}lo in rX0
#
        fld1
        fldz
        fsub    %st(1), %st
        fstpl   -16(%rsp)
        fstpl   -8(%rsp)
        movupd  -16(%rsp), rX0         # rX0 = {1.0, -1.0}
#endif
                                       # alpha1 = {ialpha, ralpha}
        pshufd  $0x4E,alpha1,alpha2    # alpha2 = {ralpha, ialpha}
        mulsd   rX0, alpha2            # alpha2 = {ralpha, -ialpha}
#
#       Move to unaligned loop if alignment is not 16-byte
#
        test    $0xF, Y
        jnz     UNALIGNED

        add     N, N         # double N so we can use it to index by 8
        lea     (X,N,8), X
        lea     (Y,N,8), Y
        neg     N
NLOOP:
                                        # alp2 = {ralpha, -ialpha}
                                        # alp1 = {ialpha, ralpha}
        movddup (X,N,8), rX0            # rX0  = {rx,    rx}
        movddup 8(X,N,8), rX1           # rX1  = {ix,    ix}
        movapd  (Y,N,8), rY0            # rY0  = {iy,    ry}
        mulpd   alpha1, rX0             # rX0  = {rx*ia, rx*ra}
        prefetchw      PFDIST(Y,N,8)
        addpd   rX0, rY0                # rY0  = {iy+rx*ia, ry+rx*ra}
        mulpd   alpha2, rX1             # rX1  = {ra*ix, -ia*ix}
        addpd   rX1, rY0                # rY0 = {iy+rx*ia+ra*ix, ry+rx*ra-ia*ix}
        prefetchnta    PFDIST(X,N,8)
        movapd  rY0, (Y,N,8)
        addq    $2, N
        jnz     NLOOP
#
#       Epilogue
#
DONE:
#ifdef ATL_GAS_x8632
        movl    (%esp), %ebp
        movl    4(%esp), %ebx
        addl    $OFF, %esp
#endif
        ret
UNALIGNED:
        add     N, N
        lea     (X,N,8), X
        lea     (Y,N,8), Y
        neg     N
UNLOOP:
                                        # alp2 = {ralpha, -ialpha}
                                        # alp1 = {ialpha, ralpha}
        movddup (X,N,8), rX0            # rX0  = {rx,    rx}
        movddup 8(X,N,8), rX1           # rX1  = {ix,    ix}
        movupd  (Y,N,8), rY0            # rY0  = {iy,    ry}
        mulpd   alpha1, rX0             # rX0  = {rx*ia, rx*ra}
        prefetchw      PFDIST(Y,N,8)
        addpd   rX0, rY0                # rY0  = {iy+rx*ia, ry+rx*ra}
        mulpd   alpha2, rX1             # rX1  = {ra*ix, -ia*ix}
        addpd   rX1, rY0                # rY0 = {iy+rx*ia+ra*ix, ry+rx*ra-ia*ix}
        prefetchnta    PFDIST(X,N,8)
        movupd  rY0, (Y,N,8)
        addq    $2, N
        jnz     UNLOOP
        jmp     DONE
@ROUT saxpy_sse
#include "atlas_asm.h"

#ifndef ATL_SSE2
   #error "This kernel requires SSE2"
#endif
#ifdef ATL_GAS_x8632
   #define movq movl
   #define addq addl
   #define subq subl
   #define X    %ebp
   #define Y    %edx
   #define N    %ecx
   #define Nr   %eax
   #define Nr_b %al
   #define JTRG %ebx
#elif defined(ATL_GAS_x8664)
   #define N    %rdi
   #define X    %rsi
   #define Y    %rcx
   #define Nr   %rax
   #define Nr_b %al
   #define JTRG %rdx
#else
   #error "This kernel requires x86 assembly!"
#endif

#define alpha %xmm0
#define rY0   %xmm1
#define rX0   %xmm2

#ifndef PFDIST
   #ifdef ATL_ARCH_P4E
      #define PFDIST 192
   #else
      #define PFDIST 3072
   #endif
#endif

# byte offset              4                  8              12             16
# void ATL_UAXPY(const int N, const SCALAR alpha, const TYPE *X, const int incX,
#                TYPE *Y, const int incY)
        .text
.global ATL_asmdecor(ATL_UAXPY)
ATL_asmdecor(ATL_UAXPY):
#ifdef ATL_GAS_x8632
   #define OFF 12
        subl    $OFF, %esp
        movl    %ebp, (%esp)
        movl    %ebx, 4(%esp)

        movl    OFF+4(%esp), N
        movss   OFF+8(%esp),  alpha
        movl    OFF+12(%esp), X
        movl    OFF+20(%esp), Y
#endif
        prefetchw       (Y)
        prefetcht0      (X)
        shufps  $0x00, alpha, alpha   # alpha = {alpha,alpha,alpha,alpha}

        movq    N, Nr
@skip        movq    $DONE, JTRG
        xor     JTRG, JTRG
        cmp     $7, N
        jbe     SCALAR_TEST
#
#       Nr = (((char*)Y+15)/16)*16 - Y
#
@skip        movq    $YALIGNED, JTRG
        movq    $1, JTRG
        lea     15(Y), Nr
        andb    $0xF0, Nr_b
        subq    Y, Nr
        jnz     FORCE_ALIGN
YALIGNED:
        test    $0xF, X
        jnz     XUNALIGNED

        movq    N, Nr
        shr     $2, N
        shl     $2, N
        sub     N, Nr
        lea     (X,N,4), X
        lea     (Y,N,4), Y
        neg     N
NLOOP:
        movaps  (X,N,4), rX0
        movaps  (Y,N,4), rY0
        mulps   alpha, rX0
                                prefetchw      PFDIST(Y,N,8)
        addps   rX0, rY0
        movaps  rY0, (Y,N,4)
        addq    $4, N
        jnz     NLOOP

@skip        movq    $DONE, JTRG
        xor     JTRG, JTRG
        cmp     $0, Nr
        jne     SCALAR_TEST
#
#       Epilogue
#
DONE:
#ifdef ATL_GAS_x8632
        movl    (%esp), %ebp
        movl    4(%esp), %ebx
        addl    $OFF, %esp
#endif
        ret
XUNALIGNED:
        movq    N, Nr
        shr     $2, N
        shl     $2, N
        sub     N, Nr
        lea     (X,N,4), X
        lea     (Y,N,4), Y
        neg     N
UNLOOP:
        movups  (X,N,4), rX0
        movaps  (Y,N,4), rY0
        mulps   alpha, rX0
                                prefetchw      PFDIST(Y,N,8)
        addps   rX0, rY0
        movaps  rY0, (Y,N,4)
        addq    $4, N
        jnz     UNLOOP
@skip        movq    $DONE, JTRG
        xor     JTRG, JTRG
        jmp     SCALAR_TEST
#
#       Assumes Nr has number of bytes until aligned
#
FORCE_ALIGN:
        shr     $2, Nr    # Nr = (Ya-Y)/sizeof(float)
        cmp     N, Nr
        cmova   N, Nr     # Nr = MIN(N,Nr)
        sub     Nr, N
#
#  This loop assumes num of iterations is in Nr, return @ in JTRG
#  NOTE: to aid portability, changed JTRG to boolean, 0 means jump to DONE,
#        1 means jump to  YALIGNED
#
SCALAR_TEST:
        cmp     $0, Nr
        je      DONE
        lea     (X,Nr,4), X
        lea     (Y,Nr,4), Y
        neg     Nr
SLOOP:
        movss   (X,Nr,4), rX0
        mulss   alpha, rX0
        movss   (Y,Nr,4), rY0
        addss   rX0, rY0
        movss   rY0, (Y,Nr,4)
        addq    $1, Nr
        jnz     SLOOP
        cmp     $0, JTRG
        je      DONE
        jmp     YALIGNED
@skip        jmp     JTRG
@ROUT daxpy_sse2
#include "atlas_asm.h"

#ifndef ATL_SSE2
   #error "This kernel requires SSE2"
#endif
#ifdef ATL_GAS_x8632
   #define movq movl
   #define addq addl
   #define subq subl
   #define X    %eax
   #define Y    %edx
   #define N    %ecx
   #define Nr   %ebp
#elif defined(ATL_GAS_x8664)
   #define N    %rdi
   #define X    %rsi
   #define Y    %rcx
   #define Nr   %rdx
#else
   #error "This kernel requires x86 assembly!"
#endif

#define alpha %xmm0
#define rY0   %xmm1
#define rX0   %xmm2

#ifndef PFDIST
   #ifdef ATL_ARCH_P4E
      #define PFDIST 384
   #else
      #define PFDIST 416
   #endif
#endif

# byte offset              4                  8              16             20
# void ATL_UAXPY(const int N, const SCALAR alpha, const TYPE *X, const int incX,
#                TYPE *Y, const int incY)
        .text
.global ATL_asmdecor(ATL_UAXPY)
ATL_asmdecor(ATL_UAXPY):
#ifdef ATL_GAS_x8632
   #define OFF 8
        subl    $OFF, %esp
        movl    %ebp, (%esp)
        movl    %ebx, 4(%esp)

        movl    OFF+4(%esp), N
        movlpd  OFF+8(%esp),  alpha
        movl    OFF+16(%esp), X
        movl    OFF+24(%esp), Y
#endif
        unpcklpd       alpha, alpha

        movq    N, Nr
        cmp     $4, N
        jbe     SCALAR_TEST

        movq    Y, Nr
        shr     $4, Nr
        shl     $4, Nr
        cmp     Nr, Y
        je      YALIGNED
        movlpd  (X), rX0
        mulsd   alpha, rX0
        movlpd  (Y), rY0
        subq    $1, N
        addsd   rX0, rY0
        addq    $8, X
        movlpd  rY0, (Y)
        addq    $8, Y
YALIGNED:
        movq    X, Nr
        shr     $4, Nr
        shl     $4, Nr
        cmp     Nr, X
        jne     XUNALIGNED

        movq    N, Nr
        shr     $1, N
        shl     $1, N
        sub     N, Nr
        lea     (X, N, 8), X
        lea     (Y, N, 8), Y
        neg     N
NLOOP:
        movapd  (X,N,8), rX0
        movapd  (Y,N,8), rY0
        mulpd   alpha, rX0
                                        prefetchw       PFDIST(Y,N,8)
        addpd   rX0, rY0
        movapd  rY0, (Y,N,8)
                                        prefetchnta     PFDIST(X,N,8)
        addq    $2, N
        jnz     NLOOP
#
#  This loop assumes num of iterations is in Nr
#
SCALAR_TEST:
        cmp     $0, Nr
        je      DONE
SLOOP:
        movlpd  (X), rX0
        mulsd   alpha, rX0
        movlpd  (Y), rY0
        addsd   rX0, rY0
        addq    $8, X
        movlpd  rY0, (Y)
        addq    $8, Y
        subq    $1, Nr
        jnz     SLOOP
#
#       Epilogue
#
DONE:
#ifdef ATL_GAS_x8632
        movl    (%esp), %ebp
        movl    4(%esp), %ebx
        addl    $OFF, %esp
#endif
        ret
XUNALIGNED:
        movq    N, Nr
        shr     $1, N
        shl     $1, N
        sub     N, Nr
        lea     (X, N, 8), X
        lea     (Y, N, 8), Y
        neg     N
UNLOOP:
        movupd  (X,N,8), rX0
        movapd  (Y,N,8), rY0
        mulpd   alpha, rX0
        addpd   rX0, rY0
        movapd  rY0, (Y,N,8)
        addq    $2, N
        jnz     UNLOOP
        jmp     SCALAR_TEST
@ROUT axpy_p2CU axpy@(iu)_x1y1 axpy16p4x16_x1y1 axpy16p4m0_x1y1
#include "atlas_misc.h"
static void axpyCU(const int N, const SCALAR alpha0, const TYPE *X, TYPE *Y)
{
   const TYPE *stX;
   int nr = N;
   register TYPE alpha=alpha0;

   @define j @@(iu)@
   @iexp j 2 @(j) /
   @iwhile j > 0
   if (nr >= @(j))
   {
      *Y   += alpha * *X;
      @define i @1@
      @iwhile i < j
      Y[@(i)] += alpha * X[@(i)];
         @iexp i 1 @(i) +
      @endiwhile
      @undef i
      @iif j > 1
      X += @(j);
      Y += @(j);
      nr -= @(j);
      @endiif
   }
      @iexp j 2 @(j) /
   @endiwhile
}
@ROUT axpy4p40_x1y1
#include "atlas_misc.h"
#include "atlas_prefetch.h"

void ATL_UAXPY(const int N, const SCALAR alpha0, const TYPE *X, const int incX,
               TYPE *Y, const int incY)
{
   int n;
   const TYPE *stX, *stX0 = X + N;
   register TYPE alpha=alpha0;
   register TYPE x0, x1, y0, y1, y2, y3;

   n = ATL_AlignOffset(N, Y, ATL_sizeof, ATL_MulBySize(4));
   if (n)
   {
      stX = X + n;
      do *Y++ += alpha * *X++; while(X != stX);
      n = N - n;
   }
   else n = N;

   if (n >= 20)
   {
      stX = X + ((n>>2)<<2) - 10;
      y0 = *Y; y1 = Y[1]; y2 = Y[2]; y3 = Y[3];
      x0 = *X; x1 = X[1];
      y0 += alpha * x0;
      y1 += alpha * x1;
      x0 = X[2]; x1 = X[3];
      y2 += alpha * x0;
      y3 += alpha * x1;
      x0 = X[4]; x1 = X[5]; X += 6;
      do
      {
         ATL_pfl1R(X+40);
         ATL_pfl1W(Y+40);
         *Y = y0; Y[1] = y1; Y[2] = y2; Y[3] = y3;
         y0 = Y[4]; y1 = Y[5]; y2 = Y[6]; y3 = Y[7];
         y0 += alpha * x0; x0 = *X;
         y1 += alpha * x1; x1 = X[1];
         y2 += alpha * x0; x0 = X[2];
         y3 += alpha * x1; x1 = X[3];
         X += 4;
         Y += 4;
      }
      while (X != stX);
      *Y = y0; Y[1] = y1; Y[2] = y2; Y[3] = y3;
      y0 = Y[4]; y1 = Y[5]; y2 = Y[6]; y3 = Y[7];
      y0 += alpha * x0; x0 = *X;
      y1 += alpha * x1; x1 = X[1]; X += 2;
      y2 += alpha * x0;
      y3 += alpha * x1;
      Y += 4;
      *Y = y0; Y[1] = y1; Y[2] = y2; Y[3] = y3;
      Y += 4;
   }
   if (X != stX0) do *Y++ += alpha * *X++; while(X != stX0);
}
@ROUT axpy@(iu)_x1y1
void ATL_UAXPY(const int N, const SCALAR alpha0, const TYPE *X, const int incX,
               TYPE *Y, const int incY)
{
   const int n = (N/@(iu))*@(iu);
   const TYPE *stX;
   int nr = N-n;
   register TYPE alpha=alpha0;

   if (n)
   {
      stX = X + n;
      do
      {
         @define i @0@
         @iwhile i < @(iu)
         Y[@(i)] += alpha * X[@(i)];
            @iexp i 1 @(i) +
         @endiwhile
         @undef i
         X += @(iu);
         Y += @(iu);
      }
      while (X != stX);
   }
   if (nr) axpyCU(nr, alpha0, X, Y);
}
@ROUT axpy1_x0y0
#include "atlas_misc.h"
void ATL_UAXPY(const int N, const SCALAR alpha, const TYPE *X, const int incX,
               TYPE *Y, const int incY)
{
   int i;
   for (i=0; i < N; i++, X += incX, Y += incY) *Y += alpha * *X;
}
@ROUT axpy1_x1y1
#include "atlas_misc.h"
void ATL_UAXPY(const int N, const SCALAR alpha, const TYPE *X, const int incX,
               TYPE *Y, const int incY)
{
   int i;
   for (i=0; i < N; i++) Y[i] += alpha * X[i];
}
@ROUT axpy32p32_x1y1
#include "atlas_misc.h"
void ATL_UAXPY(const int N, const SCALAR alpha0, const TYPE *X, const int incX,
               TYPE *Y, const int incY)
{
   register TYPE x0, y0;
   const register TYPE alpha=alpha0;
   const TYPE *stX, *stXN = X+N;
   if (N >= 64)
   {
      stX = X + ((N>>6)<<6) - 32;
      x0 = *X;
      y0 = *Y;
      do
      {
         *Y = y0 + x0 * alpha; x0 = X[32]; y0 = Y[32];
         Y[ 1] += X[ 1] * alpha;
         Y[ 2] += X[ 2] * alpha;
         Y[ 3] += X[ 3] * alpha;
         Y[ 4] += X[ 4] * alpha;
         Y[ 5] += X[ 5] * alpha;
         Y[ 6] += X[ 6] * alpha;
         Y[ 7] += X[ 7] * alpha;
         Y[ 8] += X[ 8] * alpha;
         Y[ 9] += X[ 9] * alpha;
         Y[10] += X[10] * alpha;
         Y[11] += X[11] * alpha;
         Y[12] += X[12] * alpha;
         Y[13] += X[13] * alpha;
         Y[14] += X[14] * alpha;
         Y[15] += X[15] * alpha;
         Y[16] += X[16] * alpha;
         Y[17] += X[17] * alpha;
         Y[18] += X[18] * alpha;
         Y[19] += X[19] * alpha;
         Y[20] += X[20] * alpha;
         Y[21] += X[21] * alpha;
         Y[22] += X[22] * alpha;
         Y[23] += X[23] * alpha;
         Y[24] += X[24] * alpha;
         Y[25] += X[25] * alpha;
         Y[26] += X[26] * alpha;
         Y[27] += X[27] * alpha;
         Y[28] += X[28] * alpha;
         Y[29] += X[29] * alpha;
         Y[30] += X[30] * alpha;
         Y[31] += X[31] * alpha;
         X += 32; Y += 32;
      }
      while(X != stX);
      *Y = y0 + x0 * alpha;
      Y[ 1] += X[ 1] * alpha;
      Y[ 2] += X[ 2] * alpha;
      Y[ 3] += X[ 3] * alpha;
      Y[ 4] += X[ 4] * alpha;
      Y[ 5] += X[ 5] * alpha;
      Y[ 6] += X[ 6] * alpha;
      Y[ 7] += X[ 7] * alpha;
      Y[ 8] += X[ 8] * alpha;
      Y[ 9] += X[ 9] * alpha;
      Y[10] += X[10] * alpha;
      Y[11] += X[11] * alpha;
      Y[12] += X[12] * alpha;
      Y[13] += X[13] * alpha;
      Y[14] += X[14] * alpha;
      Y[15] += X[15] * alpha;
      Y[16] += X[16] * alpha;
      Y[17] += X[17] * alpha;
      Y[18] += X[18] * alpha;
      Y[19] += X[19] * alpha;
      Y[20] += X[20] * alpha;
      Y[21] += X[21] * alpha;
      Y[22] += X[22] * alpha;
      Y[23] += X[23] * alpha;
      Y[24] += X[24] * alpha;
      Y[25] += X[25] * alpha;
      Y[26] += X[26] * alpha;
      Y[27] += X[27] * alpha;
      Y[28] += X[28] * alpha;
      Y[29] += X[29] * alpha;
      Y[30] += X[30] * alpha;
      Y[31] += X[31] * alpha;
      X += 32; Y += 32;
   }
   if (X != stXN)
   {
      do *Y++ += *X++ * alpha; while (X != stXN);
   }
}
@ROUT axpy8p8m0_x1y1
#include "atlas_misc.h"

static TYPE *axpy8(const int N, const SCALAR alpha0, const TYPE *X, TYPE *Y)
/*
 * Uses 8-register prefetch along X and Y, 4 length pipeline for seperate
 * multiply and add
 */
{
   int i;
   const register TYPE alpha=alpha0;
   const TYPE *stX = X + N;
   register TYPE m0, m1, m2, m3, a0, a1, a2, a3;
   register TYPE x0, x1, x2, x3, x4, x5, x6, x7;
   register TYPE y0, y1, y2, y3, y4, y5, y6, y7;

   x0 = *X;   x1 = X[1]; x2 = X[2]; x3 = X[3];
   x4 = X[4]; x5 = X[5]; x6 = X[6]; x7 = X[7]; X += 8;
   y0 = *Y;   y1 = Y[1]; y2 = Y[2]; y3 = Y[3];
   y4 = Y[4]; y5 = Y[5]; y6 = Y[6]; y7 = Y[7];
   m0 = x0 * alpha; x0 = *X;
   m1 = x1 * alpha; x1 = X[1];
   m2 = x2 * alpha; x2 = X[2];
   m3 = x3 * alpha; x3 = X[3];
   a0 = y0 + m0; y0 = Y[ 8]; m0 = x4 * alpha; x4 = X[4];
   a1 = y1 + m1; y1 = Y[ 9]; m1 = x5 * alpha; x5 = X[5];
   a2 = y2 + m2; y2 = Y[10]; m2 = x6 * alpha; x6 = X[6];
   a3 = y3 + m3; y3 = Y[11]; m3 = x7 * alpha; x7 = X[7]; X += 8;
   do
   {
      *Y   = a0; a0 = y4 + m0; y4 = Y[12]; m0 = x0 * alpha; x0 = *X;
      Y[1] = a1; a1 = y5 + m1; y5 = Y[13]; m1 = x1 * alpha; x1 = X[1];
      Y[2] = a2; a2 = y6 + m2; y6 = Y[14]; m2 = x2 * alpha; x2 = X[2];
      Y[3] = a3; a3 = y7 + m3; y7 = Y[15]; m3 = x3 * alpha; x3 = X[3];
      Y[4] = a0; a0 = y0 + m0; y0 = Y[16]; m0 = x4 * alpha; x4 = X[4];
      Y[5] = a1; a1 = y1 + m1; y1 = Y[17]; m1 = x5 * alpha; x5 = X[5];
      Y[6] = a2; a2 = y2 + m2; y2 = Y[18]; m2 = x6 * alpha; x6 = X[6];
      Y[7] = a3; a3 = y3 + m3; y3 = Y[19]; m3 = x7 * alpha; x7 = X[7]; X += 8;
      Y += 8;
   }
   while (X != stX);
   *Y   = a0; a0 = y4 + m0; y4 = Y[12]; m0 = x0 * alpha;
   Y[1] = a1; a1 = y5 + m1; y5 = Y[13]; m1 = x1 * alpha;
   Y[2] = a2; a2 = y6 + m2; y6 = Y[14]; m2 = x2 * alpha;
   Y[3] = a3; a3 = y7 + m3; y7 = Y[15]; m3 = x3 * alpha;
   Y[4] = a0; a0 = y0 + m0; m0 = x4 * alpha;
   Y[5] = a1; a1 = y1 + m1; m1 = x5 * alpha;
   Y[6] = a2; a2 = y2 + m2; m2 = x6 * alpha;
   Y[7] = a3; a3 = y3 + m3; m3 = x7 * alpha; Y += 8;

   *Y   = a0; a0 = y4 + m0;
   Y[1] = a1; a1 = y5 + m1;
   Y[2] = a2; a2 = y6 + m2;
   Y[3] = a3; a3 = y7 + m3;
   Y[4] = a0;
   Y[5] = a1;
   Y[6] = a2;
   Y[7] = a3;
   return(Y+8);
}

void ATL_UAXPY(const int N, const SCALAR alpha, const TYPE *X, const int incX,
               TYPE *Y, const int incY)
{
   TYPE *y=Y, *stY = Y+N;
   if (N >= 24) y = axpy8((N>>3)<<3, alpha, X, Y);
   if (y != stY)
   {
      X += (y-Y);
      do *y++ += *X++ * alpha; while (y != stY);
   }
}
@ROUT axpy16p4m0_x1y1
static void axpy_16(const int N, const SCALAR alpha, const TYPE *x, TYPE *y)
/*
 * 8 register prefetch on X & Y, with 4 cycle multiply & 4 cycle add,
 * unrolled by 16 to ensure multiple cacheline usage for both singe & double
 */
{
   const register TYPE alp = alpha;
   register TYPE x0, x1, x2, x3, xx0, xx1, xx2, xx3;
   register TYPE y0, y1, y2, y3, yy0, yy1, yy2, yy3;
   register TYPE m0, m1, m2, m3, a0, a1, a2, a3;
   const TYPE *stX = x + N;

/*   ATL_assert( ((N>>4)<<4) == N  && N); */
   x0 = *x;    xx0 = x[8];
   x1 = x[1];  xx1 = x[9];
   x2 = x[2];  xx2 = x[10];
   x3 = x[3];  xx3 = x[11];
   y0 = *y;    yy0 = y[8];
   y1 = y[1];  yy1 = y[9];
   y2 = y[2];  yy2 = y[10];
   y3 = y[3];  yy3 = y[11];

   m0 = alp * x0;  x0 = x[4];
   m1 = alp * xx0; xx0 = x[12];
   m2 = alp * x1;  x1 = x[5];
   m3 = alp * xx1; xx1 = x[13];

   a0 = y0 + m0;  m0 = alp * x2;  y0 = y[4];   x2 = x[6];
   a1 = yy0 + m1; m1 = alp * xx2; yy0 = y[12]; xx2 = x[14];
   a2 = y1 + m2;  m2 = alp * x3;  y1 = y[5];   x3 = x[7];
   a3 = yy1 + m3; m3 = alp * xx3; yy1 = y[13]; xx3 = x[15];
   x += 16;
   if (N != 16)
   {
      do
      {
         *y    = a0; a0 =  y2 + m0;  y2 = y[ 6]; m0 = alp *  x0;  x0 = *x;
         y[ 8] = a1; a1 = yy2 + m1; yy2 = y[14]; m1 = alp * xx0; xx0 = x[ 8];
         y[ 1] = a2; a2 =  y3 + m2;  y3 = y[7];  m2 = alp *  x1;  x1 = x[ 1];
         y[ 9] = a3; a3 = yy3 + m3; yy3 = y[15]; m3 = alp * xx1; xx1 = x[ 9];
         y[ 2] = a0; a0 =  y0 + m0;  y0 = y[16]; m0 = alp *  x2;  x2 = x[ 2];
         y[10] = a1; a1 = yy0 + m1; yy0 = y[24]; m1 = alp * xx2; xx2 = x[10];
         y[ 3] = a2; a2 =  y1 + m2;  y1 = y[17]; m2 = alp *  x3;  x3 = x[ 3];
         y[11] = a3; a3 = yy1 + m3; yy1 = y[25]; m3 = alp * xx3; xx3 = x[11];

         y[ 4] = a0; a0 =  y2 + m0;  y2 = y[18]; m0 = alp *  x0;  x0 = x[ 4];
         y[12] = a1; a1 = yy2 + m1; yy2 = y[26]; m1 = alp * xx0; xx0 = x[12];
         y[ 5] = a2; a2 =  y3 + m2;  y3 = y[19]; m2 = alp *  x1;  x1 = x[ 5];
         y[13] = a3; a3 = yy3 + m3; yy3 = y[27]; m3 = alp * xx1; xx1 = x[13];
         y[ 6] = a0; a0 =  y0 + m0;  y0 = y[20]; m0 = alp *  x2;  x2 = x[ 6];
         y[14] = a1; a1 = yy0 + m1; yy0 = y[28]; m1 = alp * xx2; xx2 = x[14];
         y[ 7] = a2; a2 =  y1 + m2;  y1 = y[21]; m2 = alp *  x3;  x3 = x[ 7];
         y[15] = a3; a3 = yy1 + m3; yy1 = y[29]; m3 = alp * xx3; xx3 = x[15];
         x += 16;
         y += 16;
      }
      while (x != stX);
   }
/*
 * Drain pipes
 */
   *y    = a0; a0 =  y2 + m0;  y2 = y[ 6]; m0 = alp *  x0;
   y[ 8] = a1; a1 = yy2 + m1; yy2 = y[14]; m1 = alp * xx0;
   y[ 1] = a2; a2 =  y3 + m2;  y3 = y[7];  m2 = alp *  x1;
   y[ 9] = a3; a3 = yy3 + m3; yy3 = y[15]; m3 = alp * xx1;

   y[ 2] = a0; a0 =  y0 + m0;              m0 = alp *  x2;
   y[10] = a1; a1 = yy0 + m1;              m1 = alp * xx2;
   y[ 3] = a2; a2 =  y1 + m2;              m2 = alp *  x3;
   y[11] = a3; a3 = yy1 + m3;              m3 = alp * xx3;

   y[ 4] = a0; a0 =  y2 + m0;
   y[12] = a1; a1 = yy2 + m1;
   y[ 5] = a2; a2 =  y3 + m2;
   y[13] = a3; a3 = yy3 + m3;

   y[ 6] = a0;
   y[14] = a1;
   y[ 7] = a2;
   y[15] = a3;
}

void ATL_UAXPY(const int N, const SCALAR alpha, const TYPE *x, const int incX,
               TYPE *y, const int incY)
{
   const int inb = 
             ATL_DivBySize(((size_t)y)) - ((ATL_DivBySize(((size_t)y))>>4)<<4);
   int n16, nr;

   if (inb < N)
   {
      n16 = ((N - inb)>>4)<<4;
      nr = N - inb - n16;
      if (inb)
      {
         axpyCU(inb, alpha, x, y);
         x += inb; y += inb;
      }
      if (n16)
      {
         axpy_16(n16, alpha, x, y);
         x += n16; y += n16;
      }
      if (nr) axpyCU(nr, alpha, x, y);
   }
   else axpyCU(N, alpha, x, y);
}
@ROUT axpy16p4x16_x1y1
#include "atlas_misc.h"
void ATL_UAXPY(const int N, const SCALAR alpha, const TYPE *x, const int incX,
               TYPE *y, const int incY)
/*
 * 4 register prefetch on X (assumed to be in L1), 16 register prefetch on
 * Y (L2 or main), with 8-cycle muladd.  Unrolled by 16 to ensure multiple
 * cacheline usage for both single and double.  This kernel may blow for
 * axpy, but it'll rock for GER.
 */
{
   const int N16 = (N>>4)<<4;
   int i, j;
   const TYPE *stX = x + N16 - 32;
   const register TYPE alp = alpha;
   register TYPE m0, m1, m2, m3, m4, m5, m6, m7;
   register TYPE x0, x1, xx0, xx1;
   register TYPE y0, y1, y2, y3, y4, y5, y6, y7;
   register TYPE yy0, yy1, yy2, yy3, yy4, yy5, yy6, yy7;

   if (N16 > 16)
   {
      x0 = *x; xx0 = x[8]; 
      x1 = x[1]; xx1 = x[9];
      y0 = *y;   yy0 = y[8];
      y1 = y[1]; yy1 = y[9];
      y2 = y[2]; yy2 = y[10];
      y3 = y[3]; yy3 = y[11];
      y4 = y[4]; yy4 = y[12];
      y5 = y[5]; yy5 = y[13];
      y6 = y[6]; yy6 = y[14];
      y7 = y[7]; yy7 = y[15];
      m0 = y0  + alp * x0;   x0 = x[2];  y0  = y[16];
      m1 = yy0 + alp * xx0; xx0 = x[10]; yy0 = y[24];
      m2 = y1  + alp * x1;   x1 = x[3];  y1  = y[17];
      m3 = yy1 + alp * xx1; xx1 = x[11]; yy1 = y[25];
      m4 = y2  + alp * x0;   x0 = x[4];  y2  = y[18];
      m5 = yy2 + alp * xx0; xx0 = x[12]; yy2 = y[26];
      m6 = y3  + alp * x1;   x1 = x[5];  y3  = y[19];
      m7 = yy3 + alp * xx1; xx1 = x[13]; yy3 = y[27];
      if (N16 != 32)
      {
         do
         {
            *y    = m0; m0 =  y4 + alp *  x0;  x0 = x[ 6];  y4 = y[20];
            y[ 8] = m1; m1 = yy4 + alp * xx0; xx0 = x[14]; yy4 = y[28];
            y[ 1] = m2; m2 =  y5 + alp *  x1;  x1 = x[ 7];  y5 = y[21];
            y[ 9] = m3; m3 = yy5 + alp * xx1; xx1 = x[15]; yy5 = y[29]; x += 16;
            y[ 2] = m4; m4 =  y6 + alp *  x0;  x0 = *x;     y6 = y[22];
            y[10] = m5; m5 = yy6 + alp * xx0; xx0 = x[ 8]; yy6 = y[30];
            y[ 3] = m6; m6 =  y7 + alp *  x1;  x1 = x[ 1];  y7 = y[23];
            y[11] = m7; m7 = yy7 + alp * xx1; xx1 = x[ 9]; yy7 = y[31];
   
            y[ 4] = m0; m0 = y0  + alp * x0;   x0 = x[2];  y0  = y[32];
            y[12] = m1; m1 = yy0 + alp * xx0; xx0 = x[10]; yy0 = y[40];
            y[ 5] = m2; m2 = y1  + alp * x1;   x1 = x[3];  y1  = y[33];
            y[13] = m3; m3 = yy1 + alp * xx1; xx1 = x[11]; yy1 = y[41];
            y[ 6] = m4; m4 = y2  + alp * x0;   x0 = x[4];  y2  = y[34];
            y[14] = m5; m5 = yy2 + alp * xx0; xx0 = x[12]; yy2 = y[42];
            y[ 7] = m6; m6 = y3  + alp * x1;   x1 = x[5];  y3  = y[35];
            y[15] = m7; m7 = yy3 + alp * xx1; xx1 = x[13]; yy3 = y[43];
            y += 16;
         }
         while (x != stX);
      }
      *y    = m0; m0 =  y4 + alp *  x0;  x0 = x[ 6];  y4 = y[20];
      y[ 8] = m1; m1 = yy4 + alp * xx0; xx0 = x[14]; yy4 = y[28];
      y[ 1] = m2; m2 =  y5 + alp *  x1;  x1 = x[ 7];  y5 = y[21];
      y[ 9] = m3; m3 = yy5 + alp * xx1; xx1 = x[15]; yy5 = y[29]; x += 16;
      y[ 2] = m4; m4 =  y6 + alp *  x0;  x0 = *x;     y6 = y[22];
      y[10] = m5; m5 = yy6 + alp * xx0; xx0 = x[ 8]; yy6 = y[30];
      y[ 3] = m6; m6 =  y7 + alp *  x1;  x1 = x[ 1];  y7 = y[23];
      y[11] = m7; m7 = yy7 + alp * xx1; xx1 = x[ 9]; yy7 = y[31];

      y[ 4] = m0; m0 = y0  + alp * x0;   x0 = x[2];
      y[12] = m1; m1 = yy0 + alp * xx0; xx0 = x[10];
      y[ 5] = m2; m2 = y1  + alp * x1;   x1 = x[3];
      y[13] = m3; m3 = yy1 + alp * xx1; xx1 = x[11];
      y[ 6] = m4; m4 = y2  + alp * x0;   x0 = x[4];
      y[14] = m5; m5 = yy2 + alp * xx0; xx0 = x[12];
      y[ 7] = m6; m6 = y3  + alp * x1;   x1 = x[5];
      y[15] = m7; m7 = yy3 + alp * xx1; xx1 = x[13];
      y += 16;

      *y    = m0; m0 =  y4 + alp *  x0;  x0 = x[ 6];
      y[ 8] = m1; m1 = yy4 + alp * xx0; xx0 = x[14];
      y[ 1] = m2; m2 =  y5 + alp *  x1;  x1 = x[ 7];
      y[ 9] = m3; m3 = yy5 + alp * xx1; xx1 = x[15]; x += 16;
      y[ 2] = m4; m4 =  y6 + alp *  x0;
      y[10] = m5; m5 = yy6 + alp * xx0;
      y[ 3] = m6; m6 =  y7 + alp *  x1;
      y[11] = m7; m7 = yy7 + alp * xx1;

      y[ 4] = m0;
      y[12] = m1;
      y[ 5] = m2;
      y[13] = m3;
      y[ 6] = m4;
      y[14] = m5;
      y[ 7] = m6;
      y[15] = m7;
      y += 16;
      axpyCU(N-N16, alpha, x, y);
   }
   else axpyCU(N, alpha, x, y);
}
@ROUT caxpy2p32_x1y1
#include "atlas_misc.h"
#include "atlas_prefetch.h"

void ATL_UAXPY(const int N, const SCALAR alpha, const TYPE *X, const int incX,
               TYPE *Y, const int incY)
{
   int i;
   const register TYPE ra=(*alpha), ia=alpha[1];
   register TYPE rx, ix;
   const TYPE *stX, *stX0=X+(N<<1);

   stX = X + ((N>>1)<<2);
   if (X != stX)
   {
      do
      {
         rx = X[0]; ix = X[1];
         ATL_pfl1W(Y+64);
         ATL_pfl1R(X+64);
         *Y   += ra*rx - ia*ix;
         Y[1] += ra*ix + ia*rx;
         rx = X[2]; ix = X[3];
         Y[2] += ra*rx - ia*ix;
         Y[3] += ra*ix + ia*rx;
         X += 4; Y += 4;
      }
      while (X != stX);
   }
   while (X != stX0)
   {
      rx = X[0]; ix = X[1];
      *Y   += ra*rx - ia*ix; X += 2;
      Y[1] += ra*ix + ia*rx; Y += 2;
   }
}
@ROUT caxpy8p1_x1y1 caxpy8p4m0_x1y1
@undef iu
@define iu @8@
@ROUT caxpy_CU caxpy8p1_x1y1 caxpy8p4m0_x1y1
#include "atlas_misc.h"

static void axpyCU(const int N, const SCALAR alpha, const TYPE *x, TYPE *y)
/*
 *  For cleanup, see if we can get compiler to do the work, use constant loops
 */
{
   int i;
   const register TYPE ralpha = *alpha, ialpha = alpha[1];
   register TYPE xr, xi;
   switch(N)
   {
   case 1:
      xr = *x; xi = x[1];
      *y   += ralpha * xr - ialpha * xi;
      y[1] += ialpha * xr + ralpha * xi;
      break;
@define i @2@
@iwhile i < @(iu)
   case @(i):
      for (i=@(i); i; i--, x += 2, y += 2)
      {
         xr = *x; xi = x[1];
         *y   += ralpha * xr - ialpha *xi;
         y[1] += ialpha * xr + ralpha *xi;
      }
      break;
   @iexp i 1 @(i) +
@endiwhile
   default:
      for (i=N; i; i--, x += 2, y += 2)
      {
         xr = *x; xi = x[1];
         *y   += ralpha * xr - ialpha *xi;
         y[1] += ialpha * xr + ralpha *xi;
      }
   }
}
@ROUT caxpy8p1_x1y1

void ATL_UAXPY(const int N, const SCALAR alpha, const TYPE *x, const int incX,
               TYPE *y, const int incY)
/*
 * OK, this guy may look a little complicated.  It's for a combined muladd
 * arch, and the big trick is that it splits both X and Y in fourths, then
 * does 4 parallel AXPYs on the fourths.  This is to utilize up to eight
 * prefetch units/streams.  We then unroll the loop by 2 for each axpy,
 * and prefetch one iteration ahead.  I wrote this routine, and I gotta admit
 * my head aches when I look at it . . .
 */
{
   const int n4 = N >> 2, N2 = (n4>>1)<<1, nr = n4 - N2, nn4 = n4<<1;
   TYPE *u = y+nn4, *v = u+nn4, *z = v+nn4;
   const TYPE *X1 = x + nn4, *X2 = X1 + nn4, *X3 = X2 + nn4;
   const TYPE *stX = x + ((N2-2)<<1);
   const register TYPE ralpha = *alpha, ialpha = alpha[1];
   register TYPE yr0, yi0, yr1, yi1;
   register TYPE ur0, ui0, ur1, ui1;
   register TYPE vr0, vi0, vr1, vi1;
   register TYPE zr0, zi0, zr1, zi1;
   register TYPE xr0, xi0, xr1, xi1;
   register TYPE xr2, xi2, xr3, xi3;

   if (N2)
   {
      yr0 = *y; ur0 = *u; vr0 = *v; zr0 = *z;
      yi0 = y[1]; ui0 = u[1]; vi0 = v[1]; zi0 = z[1];
      xr0 = *x; xr1 = *X1; xr2 = *X2; xr3 = *X3;

      yr0 += xr0 * ralpha; xi0 = x[1];
      ur0 += xr1 * ralpha; xi1 = X1[1];
      vr0 += xr2 * ralpha; xi2 = X2[1];
      zr0 += xr3 * ralpha; xi3 = X3[1];

      yi0 += xr0 * ialpha; yr1 = y[2];
      ui0 += xr1 * ialpha; ur1 = u[2];
      vi0 += xr2 * ialpha; vr1 = v[2];
      zi0 += xr3 * ialpha; zr1 = z[2];

      yr0 -= xi0 * ialpha; yi1 = y[3];
      ur0 -= xi1 * ialpha; ui1 = u[3];
      vr0 -= xi2 * ialpha; vi1 = v[3];
      zr0 -= xi3 * ialpha; zi1 = z[3];

      yi0 += xi0 * ralpha; xr0 = x[2];
      ui0 += xi1 * ralpha; xr1 = X1[2];
      vi0 += xi2 * ralpha; xr2 = X2[2];
      zi0 += xi3 * ralpha; xr3 = X3[2];

      if (N2 != 2)
      {
         do
         {
            *y = yr0; yr1 += xr0 * ralpha; xi0 = x[3]; x += 4;
            *u = ur0; ur1 += xr1 * ralpha; xi1 = X1[3]; X1 += 4;
            *v = vr0; vr1 += xr2 * ralpha; xi2 = X2[3]; X2 += 4;
            *z = zr0; zr1 += xr3 * ralpha; xi3 = X3[3]; X3 += 4;

            y[1] = yi0; yi1 += xr0 * ialpha; yr0 = y[4];
            u[1] = ui0; ui1 += xr1 * ialpha; ur0 = u[4];
            v[1] = vi0; vi1 += xr2 * ialpha; vr0 = v[4];
            z[1] = zi0; zi1 += xr3 * ialpha; zr0 = z[4];

            yr1 -= xi0 * ialpha; yi0 = y[5];
            ur1 -= xi1 * ialpha; ui0 = u[5];
            vr1 -= xi2 * ialpha; vi0 = v[5];
            zr1 -= xi3 * ialpha; zi0 = z[5];

            yi1 += xi0 * ralpha; xr0 = *x;
            ui1 += xi1 * ralpha; xr1 = *X1;
            vi1 += xi2 * ralpha; xr2 = *X2;
            zi1 += xi3 * ralpha; xr3 = *X3;

            y[2] = yr1; yr0 += xr0 * ralpha; xi0 = x[1];
            u[2] = ur1; ur0 += xr1 * ralpha; xi1 = X1[1];
            v[2] = vr1; vr0 += xr2 * ralpha; xi2 = X2[1];
            z[2] = zr1; zr0 += xr3 * ralpha; xi3 = X3[1];

            y[3] = yi1; yi0 += xr0 * ialpha; yr1 = y[6];
            u[3] = ui1; ui0 += xr1 * ialpha; ur1 = u[6];
            v[3] = vi1; vi0 += xr2 * ialpha; vr1 = v[6];
            z[3] = zi1; zi0 += xr3 * ialpha; zr1 = z[6];

            yr0 -= xi0 * ialpha; yi1 = y[7];
            ur0 -= xi1 * ialpha; ui1 = u[7]; y += 4;
            vr0 -= xi2 * ialpha; vi1 = v[7];
            zr0 -= xi3 * ialpha; zi1 = z[7]; u += 4;

            yi0 += xi0 * ralpha; xr0 = x[2]; v += 4;
            ui0 += xi1 * ralpha; xr1 = X1[2];
            vi0 += xi2 * ralpha; xr2 = X2[2]; z += 4;
            zi0 += xi3 * ralpha; xr3 = X3[2];
         }
         while (x != stX);
      }
      if (!nr) /* finish off this iteratation only */
      {
            *y = yr0; yr1 += xr0 * ralpha; xi0 = x[3];
            *u = ur0; ur1 += xr1 * ralpha; xi1 = X1[3];
            *v = vr0; vr1 += xr2 * ralpha; xi2 = X2[3];
            *z = zr0; zr1 += xr3 * ralpha; xi3 = X3[3]; X3 += 4;

            y[1] = yi0; yi1 += xr0 * ialpha;
            u[1] = ui0; ui1 += xr1 * ialpha;
            v[1] = vi0; vi1 += xr2 * ialpha;
            z[1] = zi0; zi1 += xr3 * ialpha;

            yr1 -= xi0 * ialpha;
            ur1 -= xi1 * ialpha;
            vr1 -= xi2 * ialpha;
            zr1 -= xi3 * ialpha;

            yi1 += xi0 * ralpha;
            ui1 += xi1 * ralpha;
            vi1 += xi2 * ralpha;
            zi1 += xi3 * ralpha;

            y[2] = yr1;
            u[2] = ur1;
            v[2] = vr1;
            z[2] = zr1;

            y[3] = yi1;
            u[3] = ui1;
            v[3] = vi1;
            z[3] = zi1; z += 4;
      }
      else     /* one iteration to do besides finishing off one from loop */
      {
            *y = yr0; yr1 += xr0 * ralpha; xi0 = x[3]; x += 4;
            *u = ur0; ur1 += xr1 * ralpha; xi1 = X1[3]; X1 += 4;
            *v = vr0; vr1 += xr2 * ralpha; xi2 = X2[3]; X2 += 4;
            *z = zr0; zr1 += xr3 * ralpha; xi3 = X3[3]; X3 += 4;

            y[1] = yi0; yi1 += xr0 * ialpha; yr0 = y[4];
            u[1] = ui0; ui1 += xr1 * ialpha; ur0 = u[4];
            v[1] = vi0; vi1 += xr2 * ialpha; vr0 = v[4];
            z[1] = zi0; zi1 += xr3 * ialpha; zr0 = z[4];

            yr1 -= xi0 * ialpha; yi0 = y[5];
            ur1 -= xi1 * ialpha; ui0 = u[5];
            vr1 -= xi2 * ialpha; vi0 = v[5];
            zr1 -= xi3 * ialpha; zi0 = z[5];

            yi1 += xi0 * ralpha; xr0 = *x;
            ui1 += xi1 * ralpha; xr1 = *X1;
            vi1 += xi2 * ralpha; xr2 = *X2;
            zi1 += xi3 * ralpha; xr3 = *X3;

            y[2] = yr1; yr0 += xr0 * ralpha; xi0 = x[1];
            u[2] = ur1; ur0 += xr1 * ralpha; xi1 = X1[1];
            v[2] = vr1; vr0 += xr2 * ralpha; xi2 = X2[1];
            z[2] = zr1; zr0 += xr3 * ralpha; xi3 = X3[1]; X3 += 2;

            y[3] = yi1; yi0 += xr0 * ialpha;
            u[3] = ui1; ui0 += xr1 * ialpha;
            v[3] = vi1; vi0 += xr2 * ialpha;
            z[3] = zi1; zi0 += xr3 * ialpha;

            yr0 -= xi0 * ialpha; y += 4;
            ur0 -= xi1 * ialpha; u += 4;
            vr0 -= xi2 * ialpha; v += 4;
            zr0 -= xi3 * ialpha; z += 4;

            yi0 += xi0 * ralpha;
            ui0 += xi1 * ralpha;
            vi0 += xi2 * ralpha;
            zi0 += xi3 * ralpha;

            *y = yr0;
            *u = ur0;
            *v = vr0;
            *z = zr0;

            y[1] = yi0;
            u[1] = ui0;
            v[1] = vi0;
            z[1] = zi0; z += 2;
      }
      if (N-(n4<<2)) axpyCU(N-(n4<<2), alpha, X3, z);
   }
   else axpyCU(N, alpha, x, y);
}
@ROUT caxpy8p4m0_x1y1
static void axpy_8(const int N, const SCALAR alpha, const TYPE *x, TYPE *y)
/*
 * 8 register prefetch on X & Y, with 4 cycle multiply & 4 cycle add,
 * unrolled by 16 to ensure multiple cacheline usage for both singe & double
 */
{
   const register TYPE ralpha = *alpha, ialpha = alpha[1];
   register TYPE xr0, xi0, xr1, xi1, xxr0, xxi0, xxr1, xxi1;
   register TYPE yr0, yi0, yr1, yi1, yyr0, yyi0, yyr1, yyi1;
   register TYPE m0, m1, m2, m3, a0, a1, a2, a3;
   const TYPE *stX = x + (N<<1) - 16;

/*   ATL_assert( (N == (N>>3)<<3) && N ); */

   xr0  = *x;   xxr0 = x[8];
   xi0  = x[1]; xxi0 = x[9];
   xr1  = x[2]; xxr1 = x[10];
   xi1  = x[3]; xxi1 = x[11];

   yr0  = *y;   yyr0 = y[8];
   yi0  = y[1]; yyi0 = y[9];
   yr1  = y[2]; yyr1 = y[10];
   yi1  = y[3]; yyi1 = y[11];

   m0 = ralpha * xr0;
   m1 = ralpha * xxr0;
   m2 = ialpha * xr0; xr0  = x[4];
   m3 = ialpha *xxr0; xxr0 = x[12];

   a0 = yr0  + m0; m0 = ialpha *  xi0; yr0  = y[4];
   a1 = yyr0 + m1; m1 = ialpha * xxi0; yyr0 = y[12];
   a2 = yi0  + m2; m2 = ralpha *  xi0;  xi0  = x[5]; yi0  = y[5];
   a3 = yyi0 + m3; m3 = ralpha * xxi0; xxi0 = x[13]; yyi0 = y[13];

   a0 -= m0; m0 = ralpha * xr1;
   a1 -= m1; m1 = ralpha * xxr1;
   a2 += m2; m2 = ialpha *  xr1; xr1  = x[6];
   a3 += m3; m3 = ialpha * xxr1; xxr1 = x[14];
   if (N != 8)
   {
      do
      {
         *y   = a0; a0 =  yr1 + m0; m0 = ialpha *  xi1;  yr1 = y[6];
         y[8] = a1; a1 = yyr1 + m1; m1 = ialpha * xxi1; yyr1 = y[14];
         y[1] = a2; a2 =  yi1 + m2; m2 = ralpha *  xi1;  xi1 = x[7]; 
                    yi1  = y[7];
         y[9] = a3; a3 = yyi1 + m3; m3 = ralpha * xxi1; xxi1 = x[15];
                    yyi1 = y[15]; x += 16;
         a0 -= m0; m0 = ralpha *  xr0;
         a1 -= m1; m1 = ralpha * xxr0;
         a2 += m2; m2 = ialpha *  xr0; xr0 = *x;
         a3 += m3; m3 = ialpha * xxr0; xxr0 = x[8];
         y[ 2] = a0; a0 =  yr0 + m0; m0 = ialpha *  xi0; yr0  = y[16];
         y[10] = a1; a1 = yyr0 + m1; m1 = ialpha * xxi0; yyr0 = y[24];
         y[ 3] = a2; a2 = yi0  + m2; m2 = ralpha *  xi0; xi0  = x[1]; 
                     yi0  = y[17];
         y[11] = a3; a3 = yyi0 + m3; m3 = ralpha * xxi0; xxi0 = x[9];
                     yyi0 = y[25];

         a0 -= m0; m0 = ralpha *  xr1;
         a1 -= m1; m1 = ralpha * xxr1;
         a2 += m2; m2 = ialpha *  xr1; xr1  = x[2];
         a3 += m3; m3 = ialpha * xxr1; xxr1 = x[10];
         y[ 4] = a0; a0 =  yr1 + m0; m0 = ialpha *  xi1; yr1  = y[18];
         y[12] = a1; a1 = yyr1 + m1; m1 = ialpha * xxi1; yyr1 = y[26];
         y[ 5] = a2; a2 = yi1  + m2; m2 = ralpha *  xi1; xi1  = x[3]; 
                     yi1  = y[19];
         y[13] = a3; a3 = yyi1 + m3; m3 = ralpha * xxi1; xxi1 = x[11];
                     yyi1 = y[27];
         a0 -= m0; m0 = ralpha *  xr0;
         a1 -= m1; m1 = ralpha * xxr0;
         a2 += m2; m2 = ialpha *  xr0; xr0 = x[4];
         a3 += m3; m3 = ialpha * xxr0; xxr0 = x[12];
         y[ 6] = a0; a0 =  yr0 + m0; m0 = ialpha *  xi0; yr0  = y[20];
         y[14] = a1; a1 = yyr0 + m1; m1 = ialpha * xxi0; yyr0 = y[28];
         y[ 7] = a2; a2 = yi0  + m2; m2 = ralpha *  xi0; xi0  = x[5]; 
                     yi0  = y[21];
         y[15] = a3; a3 = yyi0 + m3; m3 = ralpha * xxi0; xxi0 = x[13];
                     yyi0 = y[29];
         y += 16;
         a0 -= m0; m0 = ralpha *  xr1;
         a1 -= m1; m1 = ralpha * xxr1;
         a2 += m2; m2 = ialpha *  xr1; xr1  = x[6];
         a3 += m3; m3 = ialpha * xxr1; xxr1 = x[14];
      }
      while (x != stX);
   }
/*
 * Drain pipe, store last 8 elts of Y
 */
   *y   = a0; a0 =  yr1 + m0; m0 = ialpha *  xi1;  yr1 = y[6];
   y[8] = a1; a1 = yyr1 + m1; m1 = ialpha * xxi1; yyr1 = y[14];
   y[1] = a2; a2 =  yi1 + m2; m2 = ralpha *  xi1;  xi1 = x[7]; yi1  = y[7];
   y[9] = a3; a3 = yyi1 + m3; m3 = ralpha * xxi1; xxi1 = x[15]; yyi1 = y[15];
   a0 -= m0; m0 = ralpha *  xr0;
   a1 -= m1; m1 = ralpha * xxr0;
   a2 += m2; m2 = ialpha *  xr0;
   a3 += m3; m3 = ialpha * xxr0;
   y[ 2] = a0; a0 =  yr0 + m0; m0 = ialpha *  xi0;
   y[10] = a1; a1 = yyr0 + m1; m1 = ialpha * xxi0;
   y[ 3] = a2; a2 = yi0  + m2; m2 = ralpha *  xi0;
   y[11] = a3; a3 = yyi0 + m3; m3 = ralpha * xxi0;

   a0 -= m0; m0 = ralpha *  xr1;
   a1 -= m1; m1 = ralpha * xxr1;
   a2 += m2; m2 = ialpha *  xr1;
   a3 += m3; m3 = ialpha * xxr1;
   y[ 4] = a0; a0 =  yr1 + m0; m0 = ialpha *  xi1;
   y[12] = a1; a1 = yyr1 + m1; m1 = ialpha * xxi1;
   y[ 5] = a2; a2 = yi1  + m2; m2 = ralpha *  xi1;
   y[13] = a3; a3 = yyi1 + m3; m3 = ralpha * xxi1;
   a0 -= m0;
   a1 -= m1;
   a2 += m2;
   a3 += m3;
   y[ 6] = a0;
   y[14] = a1;
   y[ 7] = a2;
   y[15] = a3;
}

void ATL_UAXPY(const int N, const SCALAR alpha, const TYPE *X, const int incX,
               TYPE *Y, const int incY)
{
   const int n8 = (N>>3)<<3, nr = N - n8;

   if (n8)
   {
      axpy_8(n8, alpha, X, Y);
      X += n8<<1;
      Y += n8<<1;
   }
   if (nr) axpyCU(nr, alpha, X, Y);
}
@ROUT caxpy1_a0x0y0
#include "atlas_misc.h"
void ATL_UAXPY(const int N, const SCALAR alpha, const TYPE *X, const int incX,
               TYPE *Y, const int incY)
/*
 * Assumes alpha is real
 */
{
   int i;
   const int incx=incX+incX, incy=incY+incY;
   const register TYPE ra=(*alpha);
   register TYPE rx, ix;

   for (i=N; i; i--, X += incx, Y += incy)
   {
      rx = X[0]; ix = X[1];
      *Y   += ra*rx;
      Y[1] += ra*ix;
   }
}
@ROUT caxpy1_x0y0
#include "atlas_misc.h"
void ATL_UAXPY(const int N, const SCALAR alpha, const TYPE *X, const int incX,
               TYPE *Y, const int incY)
{
   int i;
   const int incx=incX+incX, incy=incY+incY;
   const register TYPE ra=(*alpha), ia=alpha[1];
   register TYPE rx, ix;

   for (i=N; i; i--, X += incx, Y += incy)
   {
      rx = X[0]; ix = X[1];
      *Y   += ra*rx - ia*ix;
      Y[1] += ra*ix + ia*rx;
   }
}
@ROUT caxpy1_x1y1
#include "atlas_misc.h"
void ATL_UAXPY(const int N, const SCALAR alpha, const TYPE *X, const int incX,
               TYPE *Y, const int incY)
{
   int i;
   const register TYPE ra=(*alpha), ia=alpha[1];
   register TYPE rx, ix;

   for (i=N; i; i--, X += 2, Y += 2)
   {
      rx = X[0]; ix = X[1];
      *Y   += ra*rx - ia*ix;
      Y[1] += ra*ix + ia*rx;
   }
}
@ROUT copy_std
#include "atlas_misc.h"
#include <string.h>
void ATL_UCOPY(const int N, const TYPE *X, const int incX,
               TYPE *Y, const int incY)
{
   memcpy(Y, X, ATL_MulBySize((size_t)N));
}
@ROUT copy8p_x1y1
#include "atlas_misc.h"
#include "atlas_prefetch.h"

void ATL_UCOPY(const int N, const TYPE *X, const int incX,
               TYPE *Y, const int incY)
{
   int n;
   register TYPE x0, x1, x2, x3, x4, x5, x6, x7;
   const TYPE *stX, *stX0 = X + N;

   if (N >= 16)
   {
      stX = X + ((N>>3)<<3);
      x0 = *X; x1 = X[1]; x2 = X[2]; x3 = X[3];
      x4 = X[4]; x5 = X[5]; x6 = X[6]; x7 = X[7]; X += 8;
      do
      {
         ATL_pfl1R(X+16);
         #ifdef DREAL
            ATL_pfl1R(X+20);
         #endif
         *Y = x0;   x0 = *X;
         Y[1] = x1; x1 = X[1];
         Y[2] = x2; x2 = X[2];
         Y[3] = x3; x3 = X[3];
         ATL_pfl1W(Y+ 8);
         #ifdef DREAL
            ATL_pfl1W(Y+12);
         #endif
         Y[4] = x4; x4 = X[4];
         Y[5] = x5; x5 = X[5];
         Y[6] = x6; x6 = X[6];
         Y[7] = x7; x7 = X[7];
         X += 8;
         Y += 8;
      }
      while (X != stX);
      *Y = x0; Y[1] = x1; Y[2] = x2; Y[3] = x3;
      Y[4] = x4; Y[5] = x5; Y[6] = x6; Y[7] = x7;
      Y += 8;
   }
   if (X != stX0) do *Y++ = *X++; while (X != stX0);
}
@ROUT copy32p168_x1y1
#include "atlas_misc.h"
#include "atlas_prefetch.h"
void ATL_UCOPY(const int N, const TYPE *X, const int incX,
               TYPE *Y, const int incY)
{
   int i, n;
   const TYPE *stX, *stX0 = X + N;

   stX = X + ((N>>5)<<5);
   if (X != stX)
   {
      do
      {
         ATL_pfl1R(X+168);
         ATL_pfl1W(Y+168);
         *Y = *X;
         Y[ 1] = X[ 1];
         Y[ 2] = X[ 2];
         Y[ 3] = X[ 3];
         Y[ 4] = X[ 4];
         Y[ 5] = X[ 5];
         Y[ 6] = X[ 6];
         Y[ 7] = X[ 7];
         Y[ 8] = X[ 8];
         Y[ 9] = X[ 9];
         Y[10] = X[10];
         Y[11] = X[11];
         Y[12] = X[12];
         Y[13] = X[13];
         Y[14] = X[14];
         Y[15] = X[15];
         Y[16] = X[16];
         Y[17] = X[17];
         Y[18] = X[18];
         Y[19] = X[19];
         Y[20] = X[20];
         Y[21] = X[21];
         Y[22] = X[22];
         Y[23] = X[23];
         Y[24] = X[24];
         Y[25] = X[25];
         Y[26] = X[26];
         Y[27] = X[27];
         Y[28] = X[28];
         Y[29] = X[29];
         Y[30] = X[30];
         Y[31] = X[31];
         X += 32; Y += 32;
      }
      while (X != stX);
   }
   if (X != stX0) do *Y++ = *X++; while (X != stX0);
}
@ROUT copy1_x0y0
#include "atlas_misc.h"
void ATL_UCOPY(const int N, const TYPE *X, const int incX,
               TYPE *Y, const int incY)
{
   int i;
   for (i=0; i < N; i++, X += incX, Y += incY) *Y = *X;
}
@ROUT copy_x86
#include "atlas_asm.h"

#ifdef ATL_GAS_x8632
   #define movQ movl
   #define addq addl
   #define subq subl
   #define rsp  esp
#elif !defined(ATL_GAS_x8664)
   #error "This kernel requires a gas x86 assembler!"
#endif

#ifdef ATL_GAS_x8632
   #define nblk	%ebx
   #define N	%eax
   #define X	%esi
   #define Y	%ecx
   #define stX	%edx
   #define stXF	%edi
#else
   #define movQ movq
   #define nblk	%r8
   #define N	%rax
   #define X	%rsi
   #define Y	%rcx
   #define stX	%rdx
   #define stXF	%rdi
#endif
#define NB 512
#ifndef NB
   #error "Undefined NB!"
#endif

#if NB == 8192
    #define SH 13
#elif NB == 4096
    #define SH 12
#elif NB == 2048
    #define SH 11
#elif NB == 1024
    #define SH 10
#elif NB == 512
    #define SH 9
#elif (NB == 256)
    #define SH 8
#endif
#                %edi     %rsi      %rdx     %rcx       %r8
#void ATL_UCOPY(int N, TYPE *X, int incX, TYPE *Y, int incY)
#
        .text
.global	ATL_asmdecor(ATL_UCOPY)
ATL_asmdecor(ATL_UCOPY):
#ifdef ATL_GAS_x8632
        subl    $16, %esp
        movl    %ebx, (%esp)
        movl    %esi, 4(%esp)
        movl    %edi, 8(%esp)
        movl    %ebp, 12(%esp)
        movl    20(%esp), N
        movl    24(%esp), X
        movl    32(%esp), Y
#else
	movq	%rbp, %r11
	movslq	%edi, N
#endif
	movQ	N, stXF
	shl	$3, stXF
	addq	X, stXF
#
#       Find how many NB-size chunks we have got, bail if 0
#
	movQ	N, nblk
	shr	$SH, nblk
	jz	LOOP1

LOOPB:
#
#	Burst load X
#
	movQ	X, stX
	addq	$NB*8, stX
	ALIGN16
BURST:
	movl	-64(stX), %ebp
	movl	-128(stX), %ebp
	subq	$128, stX
	cmp	X, stX
	jne	BURST

	addq	$NB*8, stX
	ALIGN16
LOOP8:
#	prefetchnta	1024(X)
	movq	(X), %mm0
	movq	8(X), %mm1
	movq	16(X), %mm2
	movq	24(X), %mm3
	movq	32(X), %mm4
	movq	40(X), %mm5
	movq	48(X), %mm6
	movq	56(X), %mm7

	movntq	%mm0, (Y)
	movntq	%mm1, 8(Y)
	movntq	%mm2, 16(Y)
	movntq	%mm3, 24(Y)
	movntq	%mm4, 32(Y)
	movntq	%mm5, 40(Y)
	movntq	%mm6, 48(Y)
	movntq	%mm7, 56(Y)

	addq	$64, Y
	addq	$64, X
	cmp	X, stX
	jne	LOOP8
#
#       Keep going until out of blocks
#
	subq	$1, nblk
	jnz	LOOPB

	cmp X, stXF
	je	DONE
LOOP1:
	movq	(X), %mm0
	movntq	%mm0, (Y)
	addq	$8, Y
	addq	$8, X
	cmp	X, stXF
	jne	LOOP1
DONE:
	sfence
	emms
#ifdef ATL_GAS_x8632
        movl    (%esp), %ebx
        movl    4(%esp), %esi
        movl    8(%esp), %edi
        movl    12(%esp), %ebp
        addl    $16, %esp
#else
	movq	%r11, %rbp
#endif
	ret
@ROUT ccopy1_x0y0
#include "atlas_misc.h"
void ATL_UCOPY(const int N, const TYPE *X, const int incX,
               TYPE *Y, const int incY)
{
   int i;
   int incy=incY+incY, incx=incX+incX;
   for (i=N; i; i--, X += incx, Y += incy)
   {
      *Y = *X;
      Y[1] = X[1];
   }
}
@ROUT dcases.copy
5
@ROUT scases.copy
4
@ROUT dcases.copy scases.copy
1 0 0 copy1_x0y0.c       "R. Clint Whaley"
2 1 1 copy_std.c         "R. Clint Whaley"
3 1 1 copy32p168_x1y1.c  "R. Clint Whaley"
4 1 1 copy8p_x1y1.c      "R. Clint Whaley"
@ROUT dcases.copy
5 1 1 copy_x86.c         "R. Clint Whaley" \
gcc
-x assembler-with-cpp
@ROUT ccases.copy zcases.copy
1
1 0 0 ccopy1_x0y0.c       "R. Clint Whaley"
@ROUT dcases.copy scases.copy zcases.copy ccases.copy

<ID> <incX> <incY> <rout> <auth>
@ROUT scases.scal dcases.scal
3
 1  2  0  scal1_x0.c          "R. Clint Whaley"
 2  2  1  scal1_x1.c          "R. Clint Whaley"
 3  2  1  scal4p48_x1.c       "R. Clint Whaley"
@ROUT zcases.scal ccases.scal
2
 1  2  0  cscal1_x0.c         "R. Clint Whaley"
 2  2  1  cscal2p28_x1.c      "R. Clint Whaley"
@ROUT scases.scal dcases.scal zcases.scal ccases.scal
<ID> <alpha> <incX> <rout> <auth>
@ROUT scal1_x0
#include "atlas_misc.h"
void ATL_USCAL(const int N, const SCALAR alpha, TYPE *X, const int incX)
{
   int i;
   for (i=N; i; i--, X += incX) *X *= alpha;
}
@ROUT scal1_x1
#include "atlas_misc.h"
void ATL_USCAL(const int N, const SCALAR alpha, TYPE *X, const int incX)
{
   int i;
   for (i=0; i < N; i++) X[i] *= alpha;
}
@ROUT scal4p48_x1
#include "atlas_misc.h"
#include "atlas_prefetch.h"

void ATL_USCAL(const int N, const SCALAR alpha0, TYPE *X, const int incX)
{
   int n;
   TYPE *stX, *stX0 = X+N;
   const register TYPE alpha=alpha0;

   n = ATL_AlignOffset(N, X, ATL_sizeof, ATL_MulBySize(4));
   if (n)  /* not aligned */
   {
      stX = X + n;
      do *X++ *= alpha; while (X != stX);
   }
   n = N - n;

   stX = X + ((n>>2)<<2);
   if (X != stX)
   {
      do
      {
         ATL_pfl1W(X+48);
         *X *= alpha;
         X[1] *= alpha;
         X[2] *= alpha;
         X[3] *= alpha;
         X += 4;
      }
      while(X != stX);
   }
   if (X != stX0) do *X++ *= alpha; while (X != stX0);
}
@ROUT cscal1_x0
#include "atlas_misc.h"
void ATL_USCAL(const int N, const SCALAR alpha, TYPE *X, const int incX)
{
   int i;
   const int incx = incX+incX;
   const register TYPE ra=(*alpha), ia=alpha[1];
   register TYPE rx, ix;
   for (i=N; i; i--, X += incx)
   {
      rx = *X; ix = X[1];
      *X   = rx*ra - ix*ia;
      X[1] = rx*ia + ix*ra;
   }
}
@ROUT cscal2p28_x1
#include "atlas_misc.h"
#include "atlas_prefetch.h"

void ATL_USCAL(const int N, const SCALAR alpha, TYPE *X, const int incX)
{
   int n;
   const int incx = incX+incX;
   const register TYPE ra=(*alpha), ia=alpha[1];
   register TYPE rx, ix, rx1, ix1;
   TYPE *stX, *stX0 = X + N + N;

   n = ATL_AlignOffset(N, X, ATL_sizeof, ATL_MulBySize(2));
   if (n==1)  /* not aligned */
   {
      rx = *X; ix = X[1];
      *X   = rx*ra - ix*ia;
      X[1] = rx*ia + ix*ra;
      X += 2;
      n = N - 1;
   }
   else n = N;

   stX = X + ((n>>1)<<2);
   if (X != stX)
   {
      do
      {
         ATL_pfl1W(X+56);
         rx = *X; ix = X[1];
         rx1 = X[2]; ix1 = X[3];
         *X   = rx*ra - ix*ia;
         X[1] = rx*ia + ix*ra;
         X[2] = rx1*ra - ix1*ia;
         X[3] = rx1*ia + ix1*ra;
         X += 4;
      }
      while(X != stX);
   }
   if (X != stX0)
   {
      rx = *X; ix = X[1];
      *X   = rx*ra - ix*ia;
      X[1] = rx*ia + ix*ra;
   }
}
@ROUT swap1_x0y0
#include "atlas_misc.h"
void ATL_USWAP(const int N, TYPE *X, const int incX, TYPE *Y, const int incY)
{
   int i;
   TYPE tmp;
   for (i=N; i; i--, X += incX, Y += incY)
   {
      tmp = *Y;
      *Y = *X;
      *X = tmp;
   }
}
@ROUT swap4_x0y0
#include "atlas_misc.h"
void ATL_USWAP(const int N, TYPE *X, const int incX, TYPE *Y, const int incY)
{
   int i;
   const int incx=incX<<2, incy=incY<<2;
   TYPE t0, t1, t2, t3;
   TYPE *x0=X, *x1=X+incX, *x2=x1+incX, *x3=x2+incX;
   TYPE *y0=Y, *y1=Y+incY, *y2=y1+incY, *y3=y2+incY;

   for (i=N>>2; i; i--)
   {
      t0 = *y0;
      t1 = *y1;
      t2 = *y2;
      t3 = *y3;
      *y0 = *x0; y0 += incy;
      *y1 = *x1; y1 += incy;
      *y2 = *x2; y2 += incy;
      *y3 = *x3; y3 += incy;
      *x0 = t0;  x0 += incx;
      *x1 = t1;  x1 += incx;
      *x2 = t2;  x2 += incx;
      *x3 = t3;  x3 += incx;
   }
   for (i=N-((N>>2)<<2); i; i--, x0 += incX, y0 += incY)
   {
      t0 = *y0;
      *y0 = *x0;
      *x0 = t0;
   }
}
@ROUT cswap1_x0y0
#include "atlas_misc.h"
void ATL_USWAP(const int N, TYPE *X, const int incx, TYPE *Y, const int incy)
{
   int i;
   const int incX=incx+incx, incY=incy+incy;
   TYPE rtmp, itmp;
   for (i=N; i; i--, X += incX, Y += incY)
   {
      rtmp = *Y;
      itmp = Y[1];
      *Y = *X;
      Y[1] = X[1];
      *X   = rtmp;
      X[1] = itmp;
   }
}
@ROUT scases.swap dcases.swap
2
1 0 0 swap1_x0y0.c       "R. Clint Whaley"
2 0 0 swap4_x0y0.c       "R. Clint Whaley"
@ROUT ccases.swap zcases.swap
1
1 0 0 cswap1_x0y0.c       "R. Clint Whaley"
@ROUT scases.swap dcases.swap ccases.swap zcases.swap
<ID> <incX> <incY> <rout> <auth>
@ROUT dot1_x1y1
#include "atlas_misc.h"
TYPE ATL_UDOT(const int N, const TYPE *X, const int incX, 
             const TYPE *Y, const int incY)
{
   register TYPE dot=ATL_rzero;
   int i;
   for (i=0; i < N; i++) dot += X[i] * Y[i];
   return(dot);
}
@ROUT dot1_x0y0
#include "atlas_misc.h"
TYPE ATL_UDOT(const int N, const TYPE *X, const int incX, 
             const TYPE *Y, const int incY)
{
   register TYPE dot=ATL_rzero;
   int i;
   for (i=N; i; i--, X += incX, Y += incY) dot += *X * *Y;
   return(dot);
}
@ROUT dot8p8_x1y1
#include "atlas_misc.h"
TYPE ATL_UDOT(const int N, const TYPE *X, const int incX, 
             const TYPE *Y, const int incY)
{
   int nr;
   const TYPE *stX, *stX0 = X + N;
   register TYPE m0, m1, m2, m3;
   register TYPE dot0=ATL_rzero, dot1=ATL_rzero, dot2=ATL_rzero, dot3=ATL_rzero;
   register TYPE x0, x1, x2, x3, x4, x5, x6, x7, x8;
   register TYPE y0, y1, y2, y3, y4, y5, y6, y7, y8;

   if (N >= 20)
   {
      nr = N - 12;
      stX = X + 12 + ((nr>>3)<<3);
      x0 =   *X; x1 = X[1]; x2 = X[2]; x3 = X[3];
      y0 =   *Y; y1 = Y[1]; y2 = Y[2]; y3 = Y[3];
      x4 = X[4]; x5 = X[5]; x6 = X[6]; x7 = X[7];
      y4 = Y[4]; y5 = Y[5]; y6 = Y[6]; y7 = Y[7];
      m0 = x0 * y0; x0 = X[ 8]; y0 = Y[ 8];
      m1 = x1 * y1; x1 = X[ 9]; y1 = Y[ 9];
      m2 = x2 * y2; x2 = X[10]; y2 = Y[10];
      m3 = x3 * y3; x3 = X[11]; y3 = Y[11]; X += 12; Y += 12;
      do
      {
         dot0 += m0; m0 = x4 * y4; x4 =   *X; y4 =   *Y;
         dot1 += m1; m1 = x5 * y5; x5 = X[1]; y5 = Y[1];
         dot2 += m2; m2 = x6 * y6; x6 = X[2]; y6 = Y[2];
         dot3 += m3; m3 = x7 * y7; x7 = X[3]; y7 = Y[3];

         dot0 += m0; m0 = x0 * y0; x0 = X[4]; y0 = Y[4];
         dot1 += m1; m1 = x1 * y1; x1 = X[5]; y1 = Y[5];
         dot2 += m2; m2 = x2 * y2; x2 = X[6]; y2 = Y[6];
         dot3 += m3; m3 = x3 * y3; x3 = X[7]; y3 = Y[7]; X += 8; Y += 8;
      }
      while (X != stX);
      dot0 += m0; m0 = x4 * y4; x4 =   *X; y4 =   *Y;
      dot1 += m1; m1 = x5 * y5; x5 = X[1]; y5 = Y[1];
      dot2 += m2; m2 = x6 * y6; x6 = X[2]; y6 = Y[2];
      dot3 += m3; m3 = x7 * y7; x7 = X[3]; y7 = Y[3]; 

      dot0 += m0; m0 = x0 * y0;
      dot1 += m1; m1 = x1 * y1;
      dot2 += m2; m2 = x2 * y2;
      dot3 += m3; m3 = x3 * y3;

      dot0 += m0;
      dot1 += m1;
      dot2 += m2;
      dot3 += m3;

      dot0 += dot1;
      dot2 += dot3;

      dot0 += dot2;
   }
   if (X != stX0)
   {
      do
      {
         dot0 += *X++ * *Y++;
      }
      while(X != stX0);
   }
   return(dot0);
}
@ROUT dot4p80_x1y1
#include "atlas_misc.h"
#include "atlas_prefetch.h"

TYPE ATL_UDOT(const int N, const TYPE *X, const int incX, 
             const TYPE *Y, const int incY)
{
   register TYPE dot0=ATL_rzero, dot1=ATL_rzero, dot2=ATL_rzero, dot3=ATL_rzero;
   const TYPE *stX, *stX0=X+N;
   int i;
   int cwrd = ATL_MulBySize(N)>>4;

   stX = X + ((N>>2)<<2);
   if (X != stX)
   {
      #ifdef ATL_AltiVec
         if (cwrd >= 64) 
         {  
            cwrd = (cwrd+31)>>5;
            cwrd = ATL_GetCtrl(512, cwrd <= 255 ? cwrd : 0, 0);
         }
         else cwrd = ATL_GetCtrl(64, (cwrd+3)>>2, 4);
         ATL_pfavR(X, cwrd, 0);
         ATL_pfavR(Y, cwrd, 1);
      #endif
      do
      {
         ATL_pfl1R(X+80);
         dot0 += *X * *Y;
         dot1 += X[1] * Y[1];
         dot2 += X[2] * Y[2];
         dot3 += X[3] * Y[3];
         X += 4;
         Y += 4;
      }
      while (X != stX);
      dot0 += dot1;
      dot2 += dot3;
      dot0 += dot2;
   }
   while (X != stX0) dot0 += *X++ * *Y++;
   return(dot0);
}
@ROUT cdot1_x0y0
#include "atlas_misc.h"
void ATL_UDOT(const int N, const TYPE *X, const int incx, 
              const TYPE *Y, const int incy, SCALAR dot)
{
   register TYPE rx, ix, ry, iy, rdot=ATL_rzero, idot=ATL_rzero;
   const int incX=incx+incx, incY=incy+incy;
   int i;
   for (i=N; i; i--, X += incX, Y += incY)
   {
      rx = *X; ix = X[1];
      ry = *Y; iy = Y[1];
      #ifndef Conj_
         rdot += rx*ry - ix*iy;
         idot += rx*iy + ix*ry;
      #else
         rdot += rx*ry + ix*iy;
         idot += rx*iy - ix*ry;
      #endif
   }
   dot[0] = rdot;
   dot[1] = idot;
}
@ROUT cdot2p24_x1y1
#include "atlas_misc.h"
#define ATL_NoFakePF
#include "atlas_prefetch.h"

void ATL_UDOT(const int N, const TYPE *X, const int incx, 
              const TYPE *Y, const int incy, SCALAR dot)
{
   register TYPE rx, ix, ry, iy, rdot=ATL_rzero, idot=ATL_rzero;
   const int incX=incx+incx, incY=incy+incy;
   const TYPE *stX=X+((N>>1)<<2), *stX0 = X + N + N;
   #ifdef ATL_AltiVec
      int cwrd = ATL_MulBySize(N)>>4;
   #endif

   if (X != stX)
   {
      #ifdef ATL_AltiVec
         if (cwrd >= 64)
         {
            cwrd = (cwrd+31)>>5;
            if (cwrd <= 256) cwrd = ATL_GetCtrl(512, cwrd <= 255 ? cwrd : 0, 0);
            else /* use all pipes */
            {
               cwrd >>= 1;
               cwrd = ATL_GetCtrl(1024, cwrd <= 255 ? cwrd : 0, 0);
               ATL_pfavR(X+128, cwrd, 2);
               ATL_pfavR(Y+128, cwrd, 3);
            }
         }
         else cwrd = ATL_GetCtrl(64, (cwrd+3)>>2, 4);
         ATL_pfavR(X, cwrd, 0);
         ATL_pfavR(Y, cwrd, 1);
      #endif
      do
      {
         ATL_pfl1R(X+48);
         ATL_pfl1R(Y+48);
         rx = *X; ix = X[1];
         ry = *Y; iy = Y[1];
         #ifndef Conj_
            rdot += rx*ry - ix*iy;
            idot += rx*iy + ix*ry;
         #else
            rdot += rx*ry + ix*iy;
            idot += rx*iy - ix*ry;
         #endif
         rx = X[2]; ix = X[3];
         ry = Y[2]; iy = Y[3];
         #ifndef Conj_
            rdot += rx*ry - ix*iy;
            idot += rx*iy + ix*ry;
         #else
            rdot += rx*ry + ix*iy;
            idot += rx*iy - ix*ry;
         #endif
         X += 4;
         Y += 4;
      }
      while (X != stX);
   }
   while (X != stX0)
   {
      rx = *X; ix = X[1];
      ry = *Y; iy = Y[1];
      #ifndef Conj_
         rdot += rx*ry - ix*iy;
         idot += rx*iy + ix*ry;
      #else
         rdot += rx*ry + ix*iy;
         idot += rx*iy - ix*ry;
      #endif
      X += 2; Y += 2;
   }
   dot[0] = rdot;
   dot[1] = idot;
}
@ROUT cdot_av
#include "atlas_misc.h"
#include "atlas_prefetch.h"
static void ATL_dot(const int N, const float *X, const float *Y, float *dot)
{
   int i;
   register float rd=(*dot), id=dot[1], ry, iy, rx, ix;
   switch(N)
   {
   case 3:
      *dot += X[4]*Y[4] - X[5]*Y[5];
      dot[1] += X[4]*Y[5] + X[5]*Y[4];
   case 2:
      *dot += X[2]*Y[2] - X[3]*Y[3];
      dot[1] += X[2]*Y[3] + X[3]*Y[2];
   case 1:
      *dot += *X * *Y - X[1]*Y[1];
      dot[1] += *X * Y[1] + X[1] * *Y;
      return;
   default:;
   }
   for (i=N; i; i--) 
   {
      rx = *X; ix = X[1];
      ry = *Y; iy = Y[1];
      rd += rx*ry - ix*iy; X += 2;
      id += rx*iy + ix*ry; Y += 2;
   }
   *dot = rd;
   dot[1] = id;
}
static void ATL_dot_av(const int N, const float *X, const float *Y, float *dot)
{
   vector float v0, v1, v2;
   vector float vdotr=(vector float)(-0.0f, -0.0f, -0.0f, -0.0f);
   vector float vdoti=(vector float)(-0.0f, -0.0f, -0.0f, -0.0f);
   const vector unsigned char vp = (vector unsigned char)
      (4,5,6,7, 0,1,2,3, 12,13,14,15, 8,9,10,11);
   const float *stX = X + N+N;
   char ln[64];
   float *vt;

   do
   {
      v0 = vec_ld(0, X);
      v1 = vec_ld(0, Y);
      vdotr = vec_madd(v0, v1, vdotr); X += 4;
      v2 = vec_perm(v1, v1, vp);
      vdoti = vec_madd(v0, v2, vdoti); Y += 4;
   }
   while (X != stX);
   vt = (float*) (16 + ((((size_t) ln)>>4)<<4));
   vec_st(vdotr, 0, vt);
   vec_st(vdoti, 0, vt+4);
   *dot += vt[0] - vt[1] + vt[2] - vt[3];
   dot[1] += vt[4] + vt[5] + vt[6] + vt[7];
}

void ATL_UDOT(const int N, const TYPE *X, const int incx, 
              const TYPE *Y, const int incy, SCALAR dot)
{
   int cwrd = ATL_MulBySize(N)>>4;
   int i, n;

   *dot = dot[1] = ATL_rzero;
   if (N >= 16)
   {
      if (cwrd >= 64)
      {
         cwrd = (cwrd+31)>>5;
         if (cwrd <= 256) cwrd = ATL_GetCtrl(512, cwrd <= 255 ? cwrd : 0, 0);
         else /* use all pipes */
         {
            cwrd >>= 1;
            cwrd = ATL_GetCtrl(1024, cwrd <= 255 ? cwrd : 0, 0);
            ATL_pfavR(X+128, cwrd, 2);
            ATL_pfavR(Y+128, cwrd, 3);
         }
      }
      else cwrd = ATL_GetCtrl(64, (cwrd+3)>>2, 4);
      ATL_pfavR(X, cwrd, 0);
      ATL_pfavR(Y, cwrd, 1);
      n = ATL_AlignOffset(N, X, ATL_sizeof, ATL_MulBySize(2));
      if (n) 
      {
         ATL_dot(n, X, Y, dot);
         X += n+n;
         Y += n+n;
      }
      n = N - n;
      if ( (i=((n>>2)<<2)) )
      {
         ATL_dot_av(i, X, Y, dot);
         X += i+i;
         Y += i+i;
         n -= i;
      }
      if (n) ATL_dot(n, X, Y, dot);
   }
   else ATL_dot(N, X, Y, dot);
}
@ROUT scases.dot dcases.dot
4
1 0 0 dot1_x0y0.c        "R. Clint Whaley"
2 1 1 dot1_x1y1.c        "R. Clint Whaley"
3 1 1 dot8p8_x1y1.c      "R. Clint Whaley"
4 1 1 dot4p80_x1y1.c     "R. Clint Whaley"
@ROUT ccases.dot zcases.dot ccasesc.dot zcasesc.dot
2
1 0 0 cdot1_x0y0.c       "R. Clint Whaley"
2 1 1 cdot2p24_x1y1.c    "R. Clint Whaley"
@ROUT scases.dot dcases.dot ccases.dot zcases.dot ccasesc.dot zcasesc.dot
<ID> <incX> <incY> <rout> <auth>
@ROUT asum_fabs1_x0 asum_fabs1_x1 casum_fabs1_x0
#include "atlas_misc.h"
#include "math.h"
#define myabs fabs
@ROUT asum_Mabs1_x0 asum_Mabs1_x1 casum_mabs1_x0
#include "atlas_misc.h"
#define myabs(x) ( (x) >= ATL_rzero ? (x) : -(x) )
@ROUT asum_fabs1_x0 asum_fabs1_x1 asum_Mabs1_x0 asum_Mabs1_x1 
TYPE ATL_UASUM(const int N, const TYPE *X, const int incX)
{
   int i;
   register TYPE t0=ATL_rzero;
@ROUT asum_fabs1_x0 asum_mabs1_x0
   for (i=N; i; i--, X += incX) t0 += myabs(*X);
@ROUT asum_fabs1_x1 asum_mabs1_x1
   for (i=0; i < N; i++) t0 += myabs(X[i]);
@ROUT asum_fabs1_x0 asum_fabs1_x1 asum_Mabs1_x0 asum_Mabs1_x1
   return(t0);
}
@ROUT asum_sse_x1
#include "atlas_asm.h"

#ifdef SREAL

#ifndef ATL_SSE1
   #error "This kernel requires SSE1"
#endif
#ifdef ATL_GAS_x8632
   #define movq movl
   #define addq addl
   #define subq subl
   #define rsp  esp
   #define rax  eax
#elif !defined(ATL_GAS_x8664)
   #error "This kernel requires a gas x86 assembler!"
#endif
#ifdef ATL_GAS_x8632
   #define N    %eax
   #define X    %edx
   #define stX  %ecx
   #define stXF %ebx
#else
   #define N	%rax
   #define X	%rsi
   #define stX	%rdi
   #define stXF	%rdx
#endif

#define absval  %xmm0
#define rX0     %xmm1
#define rX1     %xmm2
#define rX2     %xmm3
#define rX3     %xmm4
#define sum0    %xmm5
#define sum1    %xmm6
#define sum2    %xmm7

# BYTE:                    4              8
# TYPE ATL_UASUM(const int N, const TYPE *X, const int incX)
        .text
.global	ATL_asmdecor(ATL_UASUM)
ATL_asmdecor(ATL_UASUM):
#ifdef ATL_GAS_x8632
	subl	$16, %esp
   #define OFF 0
#else
   #define OFF -16
#endif
#
#       Temporarily store 1.0 and -1.0 to stack
#
	fld1	
	fldz
	fsub 	%st(1), %st
	fstps	OFF(%rsp)
	fstps	OFF+4(%rsp)
#
#	absval = (-1.0 ^ 1.0) = sign bit
#
	movss	OFF(%rsp), absval
	movss	OFF+4(%rsp), rX1
	xorps	rX1, absval
#
#       eax = all bits set
#
	xorl 	%eax, %eax
	notl	%eax
	movl	%eax, OFF(%rsp)
	movss	OFF(%rsp), rX1
	andnps	rX1, absval
	shufps	$0x00, absval, absval
#ifdef ATL_GAS_x8632
#
#       Save iregs
#
	movl	%ebx, (%esp)
#
#       N = N, X = X, stXF = X + N
#
	movl	20(%esp), N
	movl	24(%esp), X
#else
	movl	%edi, %eax
	cltq
#endif
	movq	N, stXF
	shl	$2, stXF
	addq	X, stXF
#
#	Get X aligned to 16 byte boundary
#
        xorps   sum0, sum0
	movq	X, stX
	shr	$4, stX
	shl	$4, stX
	cmp	X, stX
	jne	FORCE_ALIGN
ALIGNED_START:
	movq	N, stX
	shr	$4, stX
	jz	UNALIGNED
	shl	$6, stX
	addq	X, stX
	xorps	sum1, sum1
	xorps	sum2, sum2
ALIGNED_LOOP:
	movaps	(X), rX0
	movaps	16(X), rX1
	movaps	32(X), rX2
	movaps	48(X), rX3
	andps	absval, rX0
   #if defined(ATL_ARCH_HAMMER64) || defined(ATL_ARCH_HAMMER32)
	        prefetchnta 396(X)
   #else
	        prefetchnta 296(X)
   #endif
	andps	absval, rX1
	addps	rX0, sum0
	andps	absval, rX2
	addps	rX1, sum1
	andps	absval, rX3
	addps	rX2, sum2
        addps   rX3, sum0
	addq	$64, X
	cmp	X, stX
	jne	ALIGNED_LOOP
#
	addps	sum1, sum0
        addps   sum2, sum0
	movhlps	sum0, sum1
	addps	sum1, sum0
	movss	sum0, sum1
	shufps	$0x55, sum0, sum0
	addss	sum1, sum0
        cmp     X, stXF
        jne     UNALIGNED_LOOP
#
#	Restore iregs, return value
#
DONE:
#ifdef ATL_GAS_x8632
	movl	(%esp), %ebx
	movss	sum0, (%esp)
	flds	(%esp)
	addl	$16, %esp
#else
	movss	sum0, %xmm0
#endif
	ret
FORCE_ALIGN:
	movss	(X), rX0
	andps	absval, rX0
	addss	rX0, sum0
	addq	$4, X
	movq	X, stX
	shr	$4, stX
	shl	$4, stX
	dec	N
	cmp	X, stX
	je	ALIGNED_START
	cmp	X, stXF
	jne	FORCE_ALIGN
	jmp	DONE
UNALIGNED:
	cmp	X, stXF
	je	DONE
UNALIGNED_LOOP:
	movss	(X), rX0
	andps	absval, rX0
	addss	rX0, sum0
	addq	$4, X
	cmp	X, stXF
	jne	UNALIGNED_LOOP
        jmp     DONE

#else

#ifndef ATL_SSE2
   #error "This kernel requires SSE2"
#endif
#ifdef ATL_GAS_x8632
   #define movq movl
   #define addq addl
   #define subq subl
   #define rsp  esp
   #define rax  eax
#elif !defined(ATL_GAS_x8664)
   #error "This kernel requires a gas x86 assembler!"
#endif
#ifdef ATL_GAS_x8632
   #define N    %eax
   #define X    %edx
   #define stX  %ecx
   #define stXF %ebx
#else
   #define N	%rax
   #define X	%rsi
   #define stX	%rdi
   #define stXF	%rdx
#endif

#define absval  %xmm0
#define rX0     %xmm1
#define rX1     %xmm2
#define rX2     %xmm3
#define rX3     %xmm4
#define sum0    %xmm5
#define sum1    %xmm6
#define sum2    %xmm7

# BYTE:                    4              8
# TYPE ATL_UASUM(const int N, const TYPE *X, const int incX)
        .text
.global	ATL_asmdecor(ATL_UASUM)
ATL_asmdecor(ATL_UASUM):
#ifdef ATL_GAS_x8632
	subl	$16, %esp
   #define OFF 0
#else
   #define OFF -16
#endif
#
#       Temporarily store 1.0 and -1.0 to stack
#
	fld1	
	fldz
	fsub 	%st(1), %st
	fstpl	OFF(%rsp)
	fstpl	OFF+8(%rsp)
#
#	absval = (-1.0 ^ 1.0) = sign bit
#
	movlpd	OFF(%rsp), absval
	movlpd	OFF+8(%rsp), rX1
	xorpd	rX1, absval
#
#       eax = all bits set
#
	xorl 	%eax, %eax
	notl	%eax
	movl	%eax, OFF(%rsp)
	movl	%eax, OFF+4(%rsp)
	movlpd	OFF(%rsp), rX1
	andnpd	rX1, absval
	unpcklpd	absval, absval
#ifdef ATL_GAS_x8632
#
#       Save iregs
#
	movl	%ebx, (%esp)
#
#       N = N, X = X, stXF = X + N
#
	movl	20(%esp), N
	movl	24(%esp), X
#else
	movl	%edi, %eax
	cltq
#endif
	movq	N, stXF
	shl	$3, stXF
	addq	X, stXF
#
#	If X is not aligned to 16 byte boundary, peel 1 iteration
#
        xorpd   sum0, sum0
	movq	X, stX
	shr	$4, stX
	shl	$4, stX
	cmp	X, stX
	je	ALIGNED_START
	movlpd	(X), sum0
	andpd	absval, sum0
	addq	$8, X
	dec	N
	jz	DONE
#
#       If still not aligned after peeling, go to unaligned loop
#
	movq	X, stX
	shr	$4, stX
	shl	$4, stX
	cmp	X, stX
	jne	UNALIGNED_LOOP
ALIGNED_START:
	movq	N, stX
	shr	$3, stX
	jz	UNALIGNED_LOOP
	shl	$6, stX
	addq	X, stX
	xorpd	sum1, sum1
	xorpd	sum2, sum2
ALIGNED_LOOP:
	movapd	(X), rX0
	movapd	16(X), rX1
	movapd	32(X), rX2
	movapd	48(X), rX3
	andpd	absval, rX0
   #if defined(ATL_ARCH_HAMMER64) || defined(ATL_ARCH_HAMMER32)
	        prefetchnta 640(X)
   #else
	        prefetchnta 1024(X)
   #endif
	andpd	absval, rX1
	addpd	rX0, sum0
	andpd	absval, rX2
	addpd	rX1, sum1
	andpd	absval, rX3
	addpd	rX2, sum2
        addpd   rX3, sum0
	addq	$64, X
	cmp	X, stX
	jne	ALIGNED_LOOP
#
	addpd	sum1, sum0
        addpd   sum2, sum0
	movapd	sum0, sum1
	unpckhpd	sum1, sum1
	addsd	sum1, sum0
        cmp     X, stXF
        jne     UNALIGNED_LOOP
#
#	Restore iregs, return value
#
DONE:
#ifdef ATL_GAS_x8632
	movl	(%esp), %ebx
	movlpd	sum0, (%esp)
	fldl	(%esp)
	addl	$16, %esp
#else
	movsd	sum0, %xmm0
#endif
	ret
UNALIGNED_LOOP:
	movlpd	(X), rX0
	andpd	absval, rX0
	addsd	rX0, sum0
	addq	$8, X
	cmp	X, stXF
	jne	UNALIGNED_LOOP
        jmp     DONE

#endif
@ROUT asum_fabs4p120_x1
#include "atlas_misc.h"
#include "atlas_prefetch.h"
#include <math.h>
#define myabs fabs
TYPE ATL_UASUM(const int N, const TYPE *X, const int incX)
{
   int n;
   register TYPE t0=ATL_rzero, t1=ATL_rzero, t2=ATL_rzero, t3=ATL_rzero;
   const TYPE *stX, *stX0 = X+N;

   n = ATL_AlignOffset(N, X, ATL_sizeof, ATL_MulBySize(4));
   if (n)  /* not aligned */
   {
      stX = X + n;
      do t0 += myabs(*X); while(++X != stX);
   }
   n = N - n;
   
   stX = X + ((n>>2)<<2);
   if (X != stX)
   {
      do
      {
          ATL_pfl1R(X+120);  
          t0 += myabs(*X);
          t1 += myabs(X[1]);
          t2 += myabs(X[2]);
          t3 += myabs(X[3]);
          X += 4;
      }
      while (X != stX);
      t0 += t1;
      t2 += t3;
      t0 += t2;
   }
   if (X != stX0)
   {
      do t0 += myabs(*X); while(++X != stX0);
   }
   return(t0);
}
@ROUT casum_fabs1_x0 casum_mabs1_x0
TYPE ATL_UASUM(const int N, const TYPE *X, const int incx)
{
   const int incX = incx+incx;
   int i;
   register TYPE t0=ATL_rzero;
   for (i=N; i; i--, X += incX) t0 += myabs(*X) + myabs(X[1]);
   return(t0);
}
@ROUT scases.asum dcases.asum
6
  1   0   asum_fabs1_x0.c        "R. Clint Whaley"
  2   1   asum_fabs1_x1.c        "R. Clint Whaley"
  3   0   asum_mabs1_x0.c        "R. Clint Whaley"
  4   1   asum_mabs1_x1.c        "R. Clint Whaley"
  5   1   asum_fabs4p120_x1.c    "R. Clint Whaley"
  6   1   asum_sse_x1.c          "R. Clint Whaley" \
gcc
-x assembler-with-cpp
@ROUT ccases.asum zcases.asum
2
  1   0   casum_fabs1_x0.c    "R. Clint Whaley"
  2   0   casum_mabs1_x0.c    "R. Clint Whaley"
@ROUT scases.asum dcases.asum ccases.asum zcases.asum
<ID> <incX> <rout> <auth>
@ROUT nrm21_x0 nrm21_x1
#include "atlas_misc.h"
#include <math.h>
TYPE ATL_UNRM2(const int N, const TYPE *X, const int incX)
/*
 * Only machines like x86 with extended precision (both arithmetic and sqrt)
 * will be able to use this kernel.  On machines with standard 64/32 bit 
 * precision, this will fail the overflow/underflow tests.
 */
{
   int i;
   #if defined(SREAL) || defined(SCPLX) || defined(ATL_OS_WinNT) || \
       defined(ATL_OS_Win64)
      double t0=ATL_rzero;
   #else
      #define sqrt sqrtl
      long double t0=ATL_rzero;
   #endif
@ROUT nrm21_x0
   for (i=N; i; i--, X += incX) t0 += *X * *X;
@ROUT nrm21_x1
   for (i=0; i < N; i++) t0 += X[i]*X[i];
@ROUT nrm21_x1 nrm21_x0
   t0 = sqrt(t0);
   return(t0);
}
@ROUT nrm24p120_x1
#include "atlas_misc.h"
#include "atlas_prefetch.h"
#include <math.h>
TYPE ATL_UNRM2(const int N, const TYPE *X, const int incX)
/*
 * Only machines like x86 with extended precision (both arithmetic and sqrt)
 * will be able to use this kernel.  On machines with standard 64/32 bit 
 * precision, this will fail the overflow/underflow tests.
 */
{
   int n;
   #if defined(SREAL) || defined(SCPLX) || defined(ATL_OS_WinNT) || \
       defined(ATL_OS_Win64)
      register double t0=0.0, t1=0.0, t2=0.0, t3=0.0;
   #else
      #define sqrt sqrtl
      register long double t0=0.0, t1=0.0, t2=0.0, t3=0.0;
   #endif
   const TYPE *stX, *stX0 = X+N;

   n = ATL_AlignOffset(N, X, ATL_sizeof, ATL_MulBySize(4));
   if (n)  /* not aligned */
   {
      stX = X + n;
      do t0 += *X * *X; while(++X != stX);
   }
   n = N - n;
   
   stX = X + ((n>>2)<<2);
   if (X != stX)
   {
      do
      {
          ATL_pfl1R(X+120); 
          t0 += *X   * *X;
          t1 += X[1] * X[1];
          t2 += X[2] * X[2];
          t3 += X[3] * X[3];
          X += 4;
      }
      while (X != stX);
      t0 += t1;
      t2 += t3;
      t0 += t2;
   }
   if (X != stX0)
   {
      do t0 += *X * *X; while(++X != stX0);
   }
   t0 = sqrt(t0);
   return(t0);
}
@ROUT cnrm21_x0
#include "atlas_misc.h"
#include <math.h>
TYPE ATL_UNRM2(const int N, const TYPE *X, const int incx)
{
   const int incX=incx+incx;
   register TYPE t0=ATL_rzero;
   int i;

   for (i=N; i; i--, X += incX) t0 += *X * *X + X[1]*X[1];
   t0 = sqrt(t0);
   return(t0);
}
@ROUT nrm2_ssq1_x0_old
#include "atlas_misc.h"
#include <math.h>
TYPE ATL_UNRM2(const int N, const TYPE *X, const int incX)
{
   int i;
   TYPE ssq=ATL_rone, scal=ATL_rzero, ax, t0;

   for (i=N; i; i--, X += incX)
   {
      ax = *X;
      if (ax != ATL_rzero)
      {
         ax = Mabs(ax);
         if (scal < ax)
         {
            t0 = scal / ax;
            t0 *= t0;
            ssq = ATL_rone + ssq * t0;
            scal = ax;
         }
         else
         {
            t0 = ax / scal;
            ssq += t0*t0;
         }
      }
   }
   return(scal * sqrt(ssq));
}
@ROUT nrm2_ssq1_x0
#include "atlas_misc.h"
#include <math.h>
static void SSQ(const int N, const TYPE *X, const int incX, 
                TYPE *scal0, TYPE *ssq0)
{
   TYPE t0, ax, ssq=(*ssq0), scal=(*scal0);
   const TYPE *stX = X + N*incX;

   if (scal == ATL_rzero) /* need to start ops */
   {
      while (X != stX && *X == ATL_rzero) X += incX;
      if (X != stX)
      {
         scal = fabs(*X);
         ssq = ATL_rone;
         X += incX;
      }
      else return;
   }

   if (X != stX)
   {
      do
      {
         ax = fabs(*X);
         X += incX;
         if (scal >= ax)
         {
            t0 = ax / scal;
            ssq += t0*t0;
         }
         else
         {
            t0 = scal / ax;
            t0 *= t0;
            ssq = ATL_rone + ssq * t0;
            scal = ax;
         }
      }
      while (X != stX);
   }
   *ssq0 = ssq;
   *scal0 = scal;
}
@ROUT nrm2_ssq1_x1 nrm2_ssqr1_x1 nrm2_ssqr4_x1
#include "atlas_misc.h"
#include <math.h>
static void SSQ(const int N, const TYPE *X, const int incX, 
                TYPE *scal0, TYPE *ssq0)
{
   TYPE t0, ax, ssq=(*ssq0), scal=(*scal0);
   int i;

   if (scal == ATL_rzero) /* need to start ops */
   {
      for (i=0; i < N && X[i] == ATL_rzero; i++);
      if (i < N)
      {
         scal = fabs(X[i]);
         ssq = ATL_rone;
         i++;
      }
      else return;
   }
   else i = 0;
   for (; i < N; i++)
   {
      ax = fabs(X[i]);
      if (scal >= ax)
      {
         t0 = ax / scal;
         ssq += t0*t0;
      }
      else
      {
         t0 = scal / ax;
         t0 *= t0;
         ssq = ATL_rone + ssq * t0;
         scal = ax;
      }
   }
   *ssq0 = ssq;
   *scal0 = scal;
}
@ROUT nrm2_ssqr1_x1 nrm2_ssqr4_x1
#include <float.h>
#if FLT_RADIX != 2
   #define SSQr SSQ
#else  /* SSQr depends on using power of 2 storage */

   #ifdef SREAL
      #define ATL_MIN_EXP FLT_MIN_EXP
      #define ATL_MAX_EXP FLT_MAX_EXP
   #else
      #define ATL_MIN_EXP DBL_MIN_EXP
      #define ATL_MAX_EXP DBL_MAX_EXP
   #endif
static TYPE RecipScal(TYPE scal)
/*
 * We guarantee this function never called with scal of 0, so returning
 * zero indicates it is not safe to recipricate the number scal.  Otherwise,
 * the function returns 1 / scal
 */
{
/*
 * Use smallest max exponent so that it can be reciprocated in both directions
 */
   static const int maxexp = Mmin(ATL_MAX_EXP, -ATL_MIN_EXP);
   TYPE mant, rscal=ATL_rzero;
   int iexp, j;

   mant = frexp(scal, &iexp);
   mant = 0.5 / mant;
   mant = frexp(mant, &j);
   iexp = 1 + j - iexp;
   if (Mabs(iexp) < maxexp) rscal = ldexp(mant, iexp);
   return(rscal);
}

@ROUT nrm2_ssqr4_x1
#include "atlas_prefetch.h"
#ifndef PFDIST
   #ifdef SREAL
      #define PFDIST 112
   #else
      #define PFDIST 56
   #endif
#endif
static void SSQr(const int N, const TYPE *X, const int incX, 
                 TYPE *scal0, TYPE *ssq0)
{
   const TYPE *stX, *stX0=X+N;
   TYPE x0, x1, x2, x3, t0, rscal, scal=(*scal0), ssq=(*ssq0);
   int nr;

   if (scal == ATL_rzero) /* need to start ops */
   {
      while(X != stX0 && *X == ATL_rzero) X++;
      if (X != stX0)
      {
         scal = fabs(*X);
         ssq = ATL_rone;
         X++;
      }
      else return;
   }

   rscal = RecipScal(scal);
   if (rscal == ATL_rzero) /* not safe to reciprocate, call non-rec SSQ */
   {
      *scal0 = scal; *ssq0 = ssq;
      SSQ((int)(stX0-X), X, 1, scal0, ssq0);
      return;
   }

   nr = (int) (stX0 - X);
   nr = (nr>>2)<<2;
   stX = X + nr;
   if (nr)
   {
      do
      {
         x0 = fabs(*X); x1 = fabs(X[1]); x2 = fabs(X[2]); x3 = fabs(X[3]);
         if (x0 <= scal && x1 <= scal && x2 <= scal && x3 <= scal)
         {
            x0 *= rscal; x1 *= rscal; x2 *= rscal; x3 *= rscal;
            ATL_pfl1R(X+PFDIST);
            ssq += x0*x0 + x1*x1 + x2*x2 + x3*x3;
            X += 4;
            continue;
         }
         else if (x0 >= x1 && x0 >= x2 && x0 >= x3)
         {
            rscal = RecipScal(x0);
            ATL_pfl1R(X+PFDIST);
            if (rscal != ATL_rzero)
            {
               x1 *= rscal; x2 *= rscal; x3 *= rscal;
               t0 = scal * rscal;
               t0 *= t0;
               ssq = ATL_rone + ssq * t0 + x1*x1 + x2*x2 + x3*x3;
               scal = x0;
            }
            else
            {
               *scal0 = scal; *ssq0 = ssq;
               SSQ((int)(stX0-X), X, 1, scal0, ssq0);
               return;
            }
         }
         else if (x1 >= x2 && x1 >= x3)
         {
            x0 *= rscal;
            ssq += x0 * x0;
            ATL_pfl1R(X+PFDIST);
            rscal = RecipScal(x1);
            if (rscal != ATL_rzero)
            {
               x2 *= rscal; x3 *= rscal;
               t0 = scal * rscal;
               t0 *= t0;
               ssq = ATL_rone + ssq * t0 + x2*x2 + x3*x3;
               scal = x1;
            }
            else
            {
               *scal0 = scal; *ssq0 = ssq;
               SSQ((int)(stX0-X-1), X+1, 1, scal0, ssq0);
               return;
            }
         }
         else if (x2 > x3)
         {
            x0 *= rscal; x1 *= rscal;
            ssq += x0*x0 + x1*x1;
            ATL_pfl1R(X+PFDIST);
            rscal = RecipScal(x2);
            if (rscal != ATL_rzero)
            {
               x3 *= rscal;
               t0 = scal * rscal;
               t0 *= t0;
               ssq = ATL_rone + ssq * t0 + x3*x3;
               scal = x2;
            }
            else
            {
               *scal0 = scal; *ssq0 = ssq;
               SSQ((int)(stX0-X-2), X+2, 1, scal0, ssq0);
               return;
            }
         }
         else
         {
            x0 *= rscal; x1 *= rscal; x2 *= rscal;
            ssq += x0*x0 + x1*x1 + x2*x2;
            ATL_pfl1R(X+PFDIST);
            rscal = RecipScal(x3);
            if (rscal != ATL_rzero)
            {
               t0 = scal * rscal;
               t0 *= t0;
               ssq = ATL_rone + ssq * t0;
               scal = x3;
            }
            else
            {
               *scal0 = scal; *ssq0 = ssq;
               SSQ((int)(stX0-X-3), X+3, 1, scal0, ssq0);
               return;
            }
         }
         X += 4;
      }
      while (X != stX);
   }
   if (X != stX0) SSQ((int)(stX0-X), X, 1, &scal, &ssq);
   *scal0 = scal;
   *ssq0 = ssq;
}
#endif
@ROUT nrm2_ssqr1_x1
static void SSQr(const int N, const TYPE *X, const int incX, 
                 TYPE *scal0, TYPE *ssq0)
{
   TYPE t0, ax, ssq=(*ssq0), scal=(*scal0), rscal;
   int i, iexp;

   if (scal == ATL_rzero) /* need to start ops */
   {
      for (i=0; i < N && X[i] == ATL_rzero; i++);
      if (i < N)
      {
         scal = fabs(X[i]);
         ssq = ATL_rone;
         i++;
      }
      else return;
   }
   else i = 0;

   rscal = RecipScal(scal);
   if (rscal == ATL_rzero) /* not safe to reciprocate, call non-rec SSQ */
   {
      *scal0 = scal;
      *ssq0 = ssq;
      SSQ(N-i, X+i, 1, scal0, ssq0);
      return;
   }

   for (; i < N; i++)
   {
      ax = fabs(X[i]);
      if (scal >= ax)
      {
         t0 = ax * rscal;
         ssq += t0*t0;
      }
      else  /* getting new scal */
      {
         rscal = RecipScal(ax);
         if (rscal != ATL_rzero)
         {
            t0 = scal * rscal;
            t0 *= t0;
            ssq = ATL_rone + ssq * t0;
            scal = ax;
         }
         else /* need to use non-rec SSQ */
         {
            *scal0 = scal;
            *ssq0 = ssq;
            SSQ(N-i, X+i, incX, scal0, ssq0);
            return;
         }
      }
   }
   *ssq0 = ssq;
   *scal0 = scal;
}
#endif
@ROUT nrm2_ssq1_x1 nrm2_ssqr1_x1 nrm2_ssqr4_x1 nrm2_ssq1_x0
TYPE ATL_UNRM2(const int N, const TYPE *X, const int incX)
{
   TYPE ssq=ATL_rone, scal=ATL_rzero;
@ROUT nrm2_ssq1_x1 nrm2_ssq1_x0 `   if (N > 1) SSQ(N, X, incX, &scal, &ssq);`
@ROUT nrm2_ssqr1_x1 nrm2_ssqr4_x1 `   if (N > 1) SSQr(N, X, incX, &scal, &ssq);`
   else if (N == 1) return(fabs(*X));
   return(scal * sqrt(ssq));
}
@ROUT sdnrm216p_x1
#include "atlas_misc.h"
#include "atlas_prefetch.h"
#include <math.h>
float ATL_UNRM2(const int N, const float *X, const int incX)
/*
 * uses double arithmetic so ddot-like algorithm can safely be employed
 */
{
   int n;
   register double t0=ATL_rzero, t1=ATL_rzero, t2=ATL_rzero, t3=ATL_rzero;
   register double x0, x1, x2, x3, x4, x5, x6, x7;
   register double x8, x9, x10, x11, x12, x13, x14, x15;
   const float *stX, *stX0 = X+N;

   n = ATL_AlignOffset(N, X, ATL_sizeof, ATL_MulBySize(16));
   if (n)  /* not aligned */
   {
      stX = X + n;
      do
      {
         x0 = *X++;
         t0 += x0*x0;
      }
      while (X != stX);
   }
   n = N - n;
   
   if (n >= 32)
   {
      stX = X + ((n>>4)<<4);
      x0 = *X; x1 = X[1]; x2 = X[2]; x3 = X[3];
      x4 = X[4]; x5 = X[5]; x6 = X[6]; x7 = X[7]; 
      x8 = X[8]; x9 = X[9]; x10 = X[10]; x11 = X[11]; 
      x12 = X[12]; x13 = X[13]; x14 = X[14]; x15 = X[15]; X += 16;
      do
      {
         ATL_pfl1R(X+256); 
         t0 += x0*x0; x0 = *X;
         t1 += x1*x1; x1 = X[1];
         t2 += x2*x2; x2 = X[2];
         t3 += x3*x3; x3 = X[3];
         t0 += x4*x4; x4 = X[4];
         t1 += x5*x5; x5 = X[5];
         t2 += x6*x6; x6 = X[6];
         t3 += x7*x7; x7 = X[7];

         t0 += x8 *x8;  x8  = X[ 8];
         t1 += x9 *x9;  x9  = X[ 9];
         t2 += x10*x10; x10 = X[10];
         t3 += x11*x11; x11 = X[11];
         t0 += x12*x12; x12 = X[12];
         t1 += x13*x13; x13 = X[13];
         t2 += x14*x14; x14 = X[14];
         t3 += x15*x15; x15 = X[15];
         X += 16;
      }
      while (X != stX);
      t0 += x0*x0;
      t1 += x1*x1;
      t2 += x2*x2;
      t3 += x3*x3;
      t0 += x4*x4;
      t1 += x5*x5;
      t2 += x6*x6;
      t3 += x7*x7;
      t0 += x8 *x8;
      t1 += x9 *x9;
      t2 += x10*x10;
      t3 += x11*x11;
      t0 += x12*x12;
      t1 += x13*x13;
      t2 += x14*x14;
      t3 += x15*x15;
      t0 += t1;
      t2 += t3;
      t0 += t2;
   }
   if (X != stX0)
   {
      do
      {
         x0 = *X++;
         t0 += x0*x0;
      }
      while (X != stX0);
   }
   t0 = sqrt(t0);
   return(t0);
}
@ROUT cnrm2_ssq1_x0
#include "atlas_misc.h"
#include <math.h>
static void SSQ(const int N, const TYPE *X, const int incX0,
                TYPE *scal0, TYPE *ssq0)
{
   const int incX = incX0+incX0;
   TYPE t0, ar, ai, ssq=(*ssq0), scal=(*scal0);
   const TYPE *stX = X + N*incX;

   if (scal == ATL_rzero) /* need to start ops */
   {
      while (X != stX && *X == ATL_rzero && X[1] == ATL_rzero) X += incX;
      if (X != stX)
      {
         ar = fabs(*X); 
         ai = fabs(X[1]);
         if (ar != ATL_rzero && ai != ATL_rzero)
         {
            if (ar < ai) { t0 = ai; ai = ar; ar = t0; }
            t0 = ai / ar;
            scal = ar;
            ssq = ATL_rone + t0*t0;
         }
         else if (ai == ATL_rzero)
         {
            scal = ar;
            ssq = ATL_rone;
         }
         else
         {
            scal = ai;
            ssq = ATL_rone;
         }
         X += incX;
      }
      else return;
   }

   if (X != stX)
   {
      do
      {
         ar = fabs(*X); ai = fabs(X[1]);
         X += incX;
         if (scal >= ar && scal >= ai)
         {
            ar /= scal;
            ssq += ar*ar;
            ai /= scal;
            ssq += ai*ai;
         }
         else if (ar >= ai)
         {
            t0 = scal / ar;
            t0 *= t0;
            ssq = ATL_rone + ssq * t0;
            scal = ar;
            ai /= ar;
            ssq += ai * ai;
         }
         else
         {
            t0 = scal / ai;
            t0 *= t0;
            ssq = ATL_rone + ssq * t0;
            scal = ai;
            ar /= ai;
            ssq += ar * ar;
         }
      }
      while (X != stX);
   }
   *ssq0 = ssq;
   *scal0 = scal;
}
TYPE ATL_UNRM2(const int N, const TYPE *X, const int incX)
{
   TYPE ssq=ATL_rone, scal=ATL_rzero;
   SSQ(N, X, incX, &scal, &ssq);
   return(scal * sqrt(ssq));
}
@ROUT dnrm2_ssqmax_avx_x1
#include "atlas_misc.h"
#include "math.h"
#include <immintrin.h>


@ROUT nrm2_ssqmax1_x1
#include "atlas_misc.h"
#include "math.h"
static void SSQ(ATL_CINT N, const TYPE *X, ATL_CINT incX, 
                TYPE *scal0, TYPE *ssq0)
{
   register TYPE scal = *scal0, ssq = *ssq0, ax;
   register int i, in, n4;
   register __m256d vax;
   const register __m256d vone = {ATL_rone, ATL_rone, ATL_rone, ATL_rone};

/*
 * Align vector to 32-byte boundary
 */
   for (in=0; in < N && (((size_t)(X+in))&0x1F); in++);
   for (i=0; i < in; i++)
   {
      register TYPE t0;
      ax = fabs(X[i]);
      if (scal >= ax)
      {
         t0 = ax / scal; 
         ssq += t0 * t0;
      }
      else
      {
         t0 = scal / ax;
         t0 *= t0;
         ssq = ATL_rone + ssq * t0;
         scal = ax;
      }
   }
   n4 = ((N-in)>>3)<<3;
   if (n4)
   {
      register __m256d vscal = {scal, scal, scal, scal};
      register __m256d vssq  = {ssq, ATL_rzero, ATL_rzero, ATL_rzero};
      register __m256d vabs  = {-0.0,-0.0,-0.0,-0.0};
      X += in;
      for (i=0; i < N4; i += 4)
      {
         register __m256d v0, vcmp;
         vax = _mm256_load_pd(X+i);
         vax = _mm256_andnot_pd(vabs, vax);   /* vax = fabs(x) */

         vcmp = _mm256_cmp_pd(vax, vscal,14); /* vcmp = (vax > vscal */
         RESCALE = _mm_movemask_ps(vcmp);
         if (RESCALE) goto LRESCALE;
         v0 = _mm256_div_pd(vax, scal); 
         v0 = _mm256_mul_pd(v0, v0);
         vssq = _mm256_add_pd(vssq, v0);
LEOL:;
      }
      X -= in;
   }
   for (i=in+n8; i < N; i++)
   {
      register TYPE t0;
      ax = fabs(X[i]);
      if (scal >= ax)
      {
         t0 = ax / scal; 
         ssq += t0 * t0;
      }
      else
      {
         t0 = scal / ax;
         t0 *= t0;
         ssq = ATL_rone + ssq * t0;
         scal = ax;
      }
   }
   *scal0 = scal;
   *ssq0 = ssq;
   return;
LRESCAL:
   {
      TYPE v[4];
      register __m256d v0;
      register TYPE x0, x1, x2, x3, t0;
      TYPE oscal;
      _mm256_store_pd(v, vax);
      x0 = *v; x1 = v[1]; x2 = v[2]; x3 = v[3];
      x0 = Mmax(x0,x1);
      x2 = Mmax(x2,x3);
      x0 = Mmax(x0,x2);
      *v = x0;
      vscal = _mm256_broadcast_sd(v);
      _mm_store_sd(&oscal, (__m128d)vscal);
      t0 = oscal / x0;
      t0 *= t0;
      *v = t0;
      v0 = _mm256_broadcast_sd(v);
      vssq = _mm256_mul_pd(ssq, v0);
      vssq = _mm256_add_pd(ssq, vone);
      goto LEOL;
   }
}

#define GetMax8(ptr_, xmax_) \
{ \
   const TYPE *x = (ptr_); \
   register TYPE r0=fabs(*x),r1=fabs(x[1]),r2=fabs(x[2]),r3=fabs(x[3]), \
                 r4=fabs(x[4]),r5=fabs(x[5]),r6=fabs(x[6]),r7=fabs(x[7]); \
   r0 = Mmax(r0,r1); \
   r2 = Mmax(r2,r3); \
   r4 = Mmax(r4,r5); \
   r6 = Mmax(r6,r7); \
   r0 = Mmax(r0,r2); \
   r4 = Mmax(r4,r6); \
   xmax_ = Mmax(r0,r4); \
}

TYPE ATL_UNRM2(ATL_CINT N, const TYPE *X, ATL_CINT incX)
{
   TYPE ssq=ATL_rzero, scal=ATL_rzero;
/*
 * Find a non-zero initial scale from beginning of vector
 */
   if (N <= 24)
   {
      register int i;
      if (N == 1) 
         return(fabs(*X));
      else if (N < 1)
         return(ATL_rzero);
      for (i=0; i < N; i++)
      {
         const register TYPE ax = fabs(X[i]);
         scal = (scal >= ax) ? scal : ax;
      }
      if (scal == ATL_rzero)
         return(ATL_rzero);
      for (i=0; i < N; i++)
      {
         const register TYPE ax = fabs(X[i]);
         register TYPE t0 = ax / scal;
         ssq += t0 * t0;
      }
      return(scal * sqrt(ssq));
   }
   else
   {
      TYPE s2;
      register int i=0;
/*
 *    Find a non-zero scale factor from start of vector
 */
      do
      {
         GetMax8(X+i, scal);
         i += 8;
      }
      while (scal == ATL_rzero && N-i >= 8);
/* 
 *    Even with only 0-7 elts left, everything was zero
 */
      if (scal == ATL_rzero)
      {
         const int i0 = i;
         for (; i < N; i++)
         {
            s2 = fabs(X[i]);
            scal = Mmax(scal, s2);
         }
         if (scal == ATL_rzero)
            return(ATL_rzero);
         for (i=i0; i < N; i++)
         {
            const register TYPE ax = fabs(X[i]);
            register TYPE t0 = ax / scal;
            ssq += t0 * t0;
         }
         return(scal * sqrt(ssq));
      }
/*
 *    Scope end of vector to improve scaling bet for structured data
 */
      GetMax8(X+N-8, s2);
      scal = Mmax(scal, s2);
      SSQ(N, X, incX, &scal, &ssq);
      return(scal * sqrt(ssq));
   }
}
@ROUT cnrm2_ssq1_x0_old
#include "atlas_misc.h"
#include <math.h>
TYPE ATL_UNRM2(const int N, const TYPE *X, const int incX)
{
   int i;
   const int incx = incX+incX;
   TYPE t0, ax, ssq=ATL_rone, scal=ATL_rzero;
   if (N > 0)
   {
      for (i=N; i; i--, X += incx)
      {
         ax = *X;
         if (ax != ATL_rzero)
         {
            ax = Mabs(ax);
            if (scal < ax)
            {
               t0 = scal / ax;
               t0 *= t0;
               scal = ax;
               ssq = ATL_rone + ssq * t0;
            }
            else
            {
               t0 = ax / scal;
               ssq += t0*t0;
            }
         }
         ax = X[1];
         if (ax != ATL_rzero)
         {
            ax = Mabs(ax);
            if (scal < ax)
            {
               t0 = scal / ax;
               t0 *= t0;
               scal = ax;
               ssq = ATL_rone + ssq * t0;
            }
            else
            {
               t0 = ax / scal;
               ssq += t0*t0;
            }
         }
      }
   }
   return(scal * sqrt(ssq));
}
@ROUT nrm2_x87_x1
#include "atlas_asm.h"
#if !defined(ATL_GAS_x8632) && !defined(ATL_GAS_x8664)
   #error "This kernel requires x86 gas 32 or 64 bit x86 assembler!"
#endif

#ifdef ATL_GAS_x8664
   #define N            %rdi
   #define X            %rsi
#else
   #define N            %eax
   #define X            %edx
#endif

#define pref(mem)       prefetcht0 mem
#if defined(ATL_ARCH_HAMMER) && !defined(SREAL)
   #define PFDIST 72
#else
   #define PFDIST 192
#endif

/*                  rdi/ 4         rsi/ 8          rdx/12
TYPE ATL_UNRM2(const int N, const TYPE *X, const int incX) 
*/
        .text
.global ATL_asmdecor(ATL_UNRM2)
ATL_asmdecor(ATL_UNRM2):
   #ifdef ATL_GAS_x8632
#
#       Load operands to registers
#
        movl    4(%esp), N
        movl    8(%esp), X
   #endif

        fldz
   #ifdef SREAL
        #define fldl flds
        shl     $2, N
   #else
        shl     $3, N
   #endif
        add     N, X
        neg     N
ALIGN4
LOOP1:
        fldl    (X, N)
        fmul    %st, %st
        faddp
        pref(PFDIST(X,N))
   #ifdef SREAL
        add     $4, N
   #else
        add     $8, N
   #endif
ALIGN4
        jnz     LOOP1

        fsqrt
#
#       Put return val in right register and return
#
#ifdef ATL_GAS_x8664
   #ifdef SREAL
        fstps   -4(%rsp)
        movss   -4(%rsp), %xmm0
   #else
        fstpl   -8(%rsp)
        movsd   -8(%rsp), %xmm0
   #endif
#endif
        ret
@ROUT nrm2_x87_x0
#include "atlas_asm.h"
#if !defined(ATL_GAS_x8632) && !defined(ATL_GAS_x8664)
   #error "This kernel requires x86 gas 32 or 64 bit x86 assembler!"
#endif

#ifdef ATL_GAS_x8664
   #define N            %rdi
   #define X            %rsi
   #define incX         %rdx
#else
   #define N            %eax
   #define X            %edx
   #define incX         %ecx
   #define movq         movl
#endif

#define pref(mem) prefetcht0        mem

/*                  rdi/ 4         rsi/ 8          rdx/12
TYPE ATL_UNRM2(const int N, const TYPE *X, const int incX) 
*/
        .text
.global ATL_asmdecor(ATL_UNRM2)
ATL_asmdecor(ATL_UNRM2):
   #ifdef ATL_GAS_x8664
#
#       Since incX might be negative, must convert it to 64 bit
#
        movl    %edx, %eax
        cltq
        movq    %rax, incX
   #else
#
#       Load operands to regs
#
        movl    4(%esp), N
        movl    8(%esp), X
        movl    12(%esp), incX
   #endif

   #if SREAL
        #define fldl flds
        shl     $2, incX        # incX *= sizeof(float)
   #else
        shl     $3, incX        # incX *= sizeof(double)
   #endif
        fldz
ALIGN4
LOOP1:
        pref((X,incX,8))
        fldl    (X)
        fmul    %st, %st
        faddp
        add     incX, X
        sub     $1, N
        jnz     LOOP1
        fsqrt
#
#       Put return val in right reg, and return
#
#ifdef ATL_GAS_x8664
   #ifdef SREAL
        fstps   -4(%rsp)
        movss   -4(%rsp), %xmm0
   #else
        fstpl   -8(%rsp)
        movsd   -8(%rsp), %xmm0
   #endif
#endif
        ret
@ROUT cnrm2_x87_x0
#include "atlas_asm.h"
#if !defined(ATL_GAS_x8632) && !defined(ATL_GAS_x8664)
   #error "This kernel requires x86 gas 32 or 64 bit x86 assembler!"
#endif

#ifdef ATL_GAS_x8664
   #define N            %rdi
   #define X            %rsi
   #define incX         %rdx
#else
   #define N            %eax
   #define X            %edx
   #define incX         %ecx
   #define movq movl
#endif

#define pref(mem) prefetcht0        mem

/*                  rdi/ 4         rsi/ 8          rdx/12
TYPE ATL_UNRM2(const int N, const TYPE *X, const int incX) 
*/
        .text
.global ATL_asmdecor(ATL_UNRM2)
ATL_asmdecor(ATL_UNRM2):
   #ifdef ATL_GAS_x8664
#
#       Since incX might be negative, must convert it to 64 bit
#
        movl    %edx, %eax
        cltq
        movq    %rax, incX
   #else
#
#       Load operands to regs
#
        movl    4(%esp), N
        movl    8(%esp), X
        movl    12(%esp), incX
   #endif

#ifdef SCPLX
        #define fldl    flds
        #define INDX(i_) 4*(i_)
        shl     $3, incX        # incX *= sizeof(doublecplx)
#else
        #define INDX(i_) 8*(i_)
        shl     $4, incX        # incX *= sizeof(doublecplx)
#endif
        fldz
ALIGN4
LOOP1:
        fldl    (X)
        fmul    %st, %st
        faddp
        fldl    INDX(1)(X)
        fmul    %st, %st
        faddp
        add     incX, X
        sub     $1, N
        pref((X,incX,8))
ALIGN4
        jnz     LOOP1
        fsqrt
#
#       Put return val in right reg, and return
#
#ifdef ATL_GAS_x8664
   #ifdef SCPLX
        fstps   -4(%rsp)
        movss   -4(%rsp), %xmm0
   #else
        fstpl   -8(%rsp)
        movsd   -8(%rsp), %xmm0
   #endif
#endif
        ret
@ROUT scases.nrm2
10
@ROUT dcases.nrm2
9
@ROUT scases.nrm2 dcases.nrm2
1 0 nrm21_x0.c        "R. Clint Whaley" \
gcc
-fomit-frame-pointer -mfpmath=387 -O2
2 1 nrm21_x1.c        "R. Clint Whaley" \
gcc
-fomit-frame-pointer -mfpmath=387 -O2
3 1 nrm24p120_x1.c    "R. Clint Whaley" \
gcc
-fomit-frame-pointer -mfpmath=387 -O2
4 0 nrm2_ssq1_x0.c    "R. Clint Whaley"
5 1 nrm2_ssq1_x1.c    "R. Clint Whaley"
6 1 nrm2_ssqr1_x1.c   "R. Clint Whaley"
7 1 nrm2_ssqr4_x1.c   "R. Clint Whaley"
@ROUT scases.nrm2
8 1 sdnrm216p_x1.c    "R. Clint Whaley"
@ROUT dcases.nrm2 scases.nrm2
9 1 nrm2_x87_x1.c    "R. Clint Whaley" \
gcc
-x assembler-with-cpp
10 0 nrm2_x87_x0.c   "R. Clint Whaley" \
gcc
-x assembler-with-cpp
@ROUT zcases.nrm2 ccases.nrm2
3
@ROUT ccases.nrm2 zcases.nrm2
1 0 cnrm2_ssq1_x0.c   "R. Clint Whaley"
2 0 cnrm21_x0.c       "R. Clint Whaley" \
gcc
-fomit-frame-pointer -mfpmath=387 -O2
3 0 cnrm2_x87_x0.c    "R. Clint Whaley" \
gcc
-x assembler-with-cpp
@ROUT scases.nrm2 dcases.nrm2 ccases.nrm2 zcases.nrm2
<ID> <incX> <rout> <auth>
@ROUT cpsc1_x1y1
#include "atlas_misc.h"
void ATL_UCPSC(const int N, const SCALAR alpha, const TYPE *X, const int incX,
               TYPE *Y, const int incY)
{
   int i;
   for (i=0; i < N; i++) Y[i] = alpha * X[i];
}
@ROUT cpsc1_x0y0
#include "atlas_misc.h"
void ATL_UCPSC(const int N, const SCALAR alpha, const TYPE *X, const int incX,
               TYPE *Y, const int incY)
{
   int i;
   for (i=N; i; i--, X += incX, Y += incY) *Y = alpha * *X;
}
@ROUT ccpsc1_x0y0
#include "atlas_misc.h"
void ATL_UCPSC(const int N, const SCALAR alpha, const TYPE *X, const int incx,
               TYPE *Y, const int incy)
{
   const int incX=incx+incx, incY=incy+incy;
   const register TYPE ra=(*alpha), ia=alpha[1];
   register TYPE rx, ix;
   int i;
   for (i=N; i; i--, X += incX, Y += incY)
   {
      rx = *X; ix = X[1];
      *Y   = ra*rx - ia*ix;
      Y[1] = ra*ix + ia*rx;
   }
}
@ROUT scases.cpsc dcases.cpsc
2
1 2 0 0 cpsc1_x0y0.c       "R. Clint Whaley"
2 2 1 1 cpsc1_x1y1.c       "R. Clint Whaley"
@ROUT ccases.cpsc zcases.cpsc
1
1 2 0 0 ccpsc1_x0y0.c       "R. Clint Whaley"
@ROUT scases.cpsc dcases.cpsc ccases.cpsc zcases.cpsc
<ID> <alpha> <incX> <incY> <rout> <author> 
@ROUT set1_x0
#include "atlas_misc.h"
void ATL_USET(const int N, const SCALAR alpha, TYPE *X, const int incX)
{
   int i;
   for (i=N; i; i--, X += incX) *X = alpha;
}
@ROUT set1_x1
#include "atlas_misc.h"
void ATL_USET(const int N, const SCALAR alpha, TYPE *X, const int incX)
{
   int i;
   for (i=0; i < N; i++) X[i] = alpha;
}
@ROUT set32_x1
#include "atlas_misc.h" 
void ATL_USET(const int N, const SCALAR alpha0, TYPE *X, const int incx)
{
   int i, n = N;
   const register TYPE alpha=alpha0;
   i = n >> 5;
   if (i)
   {
      n -= (i << 5);
      do
      {
         *X = X[1] = X[2] = X[3] = X[4] = X[5] = X[6] = X[7] = X[8] = X[9] =
         X[10] = X[11] = X[12] = X[13] = X[14] = X[15] = X[16] = X[17] =
         X[18] = X[19] = X[20] = X[21] = X[22] = X[23] = X[24] = X[25] =
         X[26] = X[27] = X[28] = X[29] = X[30] = X[31] = alpha;
         X += 32;
      }
      while(--i);
   }
   if (n >> 4) /* >= 16 */
   {
      *X = X[1] = X[2] = X[3] = X[4] = X[5] = X[6] = X[7] = X[8] = X[9] =
      X[10] = X[11] = X[12] = X[13] = X[14] = X[15] = alpha;
      X += 16;
      n -= 16;
   }
   if (n >> 3) /* >= 8 */
   {
      *X = X[1] = X[2] = X[3] = X[4] = X[5] = X[6] = X[7] = alpha;
      X += 8;
      n -= 8;
   }
   switch(n)
   {
      case 1:
         *X = alpha;
         break;
      case 2:
         *X = X[1] = alpha;
         break;
      case 3:
         *X = X[1] = X[2] = alpha;
         break;
      case 4:
         *X = X[1] = X[2] = X[3] = alpha;
         break;
      case 5:
         *X = X[1] = X[2] = X[3] = X[4] = alpha;
         break;
      case 6:
         *X = X[1] = X[2] = X[3] = X[4] = X[5] = alpha;
         break;
      case 7:
         *X = X[1] = X[2] = X[3] = X[4] = X[5] = X[6] = alpha;
         break;
      default:;
   }
}
@ROUT set_x86
#include "atlas_asm.h"

#ifdef SREAL

#ifndef ATL_SSE1
   #error "This routine requires SSE1"
#endif

#ifdef ATL_GAS_x8632
   #define X	%edx
   #define N	%ecx
   #define N2   %eax
   #define rsp  esp
#elif defined(ATL_GAS_x8664)
   #define X	%rsi
   #define N	%edi
   #define N2   %eax
#else
   #error "This kernel requires a gas x86 assembler!"
#endif


#                %edi         %xmm0     %rsi
# void ATL_USET(int N, float alpha, float *X, int incX)
#
        .text
.global	ATL_asmdecor(ATL_USET)
ATL_asmdecor(ATL_USET):
#ifdef ATL_GAS_x8632
        subl    $8, %esp
	movl	12(%esp), N
	movl	16(%esp), N2
	movl	20(%esp), X
        movl    N2, (%esp)
        movl    N2, 4(%esp)
        movq    (%esp), %mm0
   #define OFF 0
#else
	movss	%xmm0, -8(%rsp)
	movss	%xmm0, -4(%rsp)
	movq	-8(%rsp), %mm0
   #define OFF -8
#endif
#
#       If N is not divisable by two, peal first iteration
#
        movl    N, N2
        shr     $1, N2
        shl     $1, N2
        cmp     N, N2
        je      GOGO
        movl    OFF(%rsp), N2
        movl    N2, (X)
        add     $4, X
GOGO:
        shr     $1, N
        jz      DONE
	ALIGN16
LOOP1:
	movntq	%mm0, (X)
	add 	$8, X
	dec 	N
	jnz LOOP1
#
#	All done here
#
DONE:
	sfence
	emms
#ifdef ATL_GAS_x8632
        addl    $8, %esp
#endif
	ret

#else

#ifdef ATL_GAS_x8632
   #define X	%edx
   #define N	%ecx
#elif defined(ATL_GAS_x8664)
   #define X	%rsi
   #define N	%edi
#else
   #error "This kernel requires a gas x86 assembler!"
#endif
#ifndef ATL_SSE1
   #error "This routine requires SSE1"
#endif

#                %edi         %xmm0       %rsi
# void ATL_USET(int N, double alpha, double *X, int incX)
#
        .text
.global	ATL_asmdecor(ATL_USET)
ATL_asmdecor(ATL_USET):
#ifdef ATL_GAS_x8632
	movl	4(%esp), N
	movq	8(%esp), %mm0
	movl	16(%esp), X
#else
	movlpd	%xmm0, -8(%rsp)
	movq	-8(%rsp), %mm0
#endif
	ALIGN16
LOOP1:
	movntq	%mm0, (X)
	add 	$8, X
	decl	N
	jnz LOOP1
#
#	All done here
#
	sfence
	emms
	ret

#endif
@ROUT cset1_x0
#include "atlas_misc.h"
void ATL_USET(const int N, const SCALAR alpha, TYPE *X, const int incx)
{
   int i;
   const register TYPE ra=(*alpha), ia=alpha[1];
   const int incX=incx+incx;

   for (i=N; i; i--, X += incX)
   {
      *X = ra;
      X[1] = ia;
   }
}
@ROUT dcases.set scases.set
4
 1  2  0  set1_x0.c          "R. Clint Whaley"
 2  2  1  set1_x1.c          "R. Clint Whaley"
 3  2  1  set32_x1.c         "R. Clint Whaley"
 4  2  1  set_x86.c          "R. Clint Whaley" \
gcc
-x assembler-with-cpp
@ROUT zcases.set ccases.set
1
 1  2  0  cset1_x0.c         "R. Clint Whaley"
@ROUT scases.set dcases.set zcases.set ccases.set
<ID> <alpha> <incX> <rout> <auth>
@ROUT axpby32_a1bXx1y1
#include "atlas_misc.h"
void ATL_UAXPBY(const int N, const SCALAR alpha, const TYPE *X, const int incX,
                const SCALAR beta, TYPE *Y, const int incY)
{
   const TYPE *stX=X+((N>>5)<<5), *stX0 = X+N;
   if (X != stX)
   {
      do
      {
         *Y = beta * *Y + *X;
      @define i @1@
      @iwhile i < @(iu)
         Y[@2r@(i)] = beta * Y[@2r@(i)] + X[@2r@(i)];
         @iexp i 1 @(i) +
      @endiwhile
         X += 32;
         Y += 32;
      }
      while (X != stX);
   }
   while (X != stX0)
   {
      *Y = beta * *Y + *X++;
      Y++;
   }
}
@ROUT axpby1_a1bXx1y1
#include "atlas_misc.h"
void ATL_UAXPBY(const int N, const SCALAR alpha, const TYPE *X, const int incX,
                const SCALAR beta, TYPE *Y, const int incY)
{
   int i;
   for (i=0; i < N; i++) Y[i] = X[i] + beta * Y[i];
}
@ROUT axpby1_x0y0
#include "atlas_misc.h"
void ATL_UAXPBY(const int N, const SCALAR alpha, const TYPE *X, const int incX,
                const SCALAR beta, TYPE *Y, const int incY)
{
   int i;
   for (i=N; i; i--, X += incX, Y += incY) *Y = alpha * *X + beta * *Y;
}
@ROUT caxpby1_x0y0
#include "atlas_misc.h"
void ATL_UAXPBY(const int N, const SCALAR alpha, const TYPE *X, const int incx,
                const SCALAR beta, TYPE *Y, const int incy)
{
   int i;
   const int incX=incx+incx, incY=incy+incy;
   const register TYPE ra=(*alpha), ia=alpha[1], rb=(*beta), ib=beta[1];
   register TYPE rx, ix, ry, iy;
   for (i=N; i; i--, X += incX, Y += incY) 
   {
      rx = *X; ix = X[1]; ry = *Y; iy = Y[1];
      *Y   = ra*rx - ia*ix + rb*ry - ib*iy;
      Y[1] = ra*ix + ia*rx + rb*iy + ib*ry;
   }
}
@ROUT scases.axpby dcases.axpby
3
 1  2  2  0  0  axpby1_x0y0.c          "R. Clint Whaley"
 2  1  2  1  1  axpby1_a1bXx1y1.c      "R. Clint Whaley"
 3  1  2  1  1  axpby32_a1bXx1y1.c     "R. Clint Whaley"
@ROUT zcases.axpby ccases.axpby
1
 1  2  2  0  0  caxpby1_x0y0.c         "R. Clint Whaley"
@ROUT scases.axpby dcases.axpby ccases.axpby zcases.axpby
<ID> <alpha> <beta> <incX> <incY> <rout> <auth>
@ROUT iamax_stub
#include "atlas_misc.h"

int ATL_IAMAX(const int N, const TYPE *X, const int incX)
{
   int ATL_UIAMAX(const int N, const TYPE *X, const int incX);
   return(ATL_UIAMAX(N, X, incX));
}
@ROUT iamax_abs4_x1
#include "atlas_misc.h"
#include "atlas_prefetch.h"
#include <math.h>

int ATL_UIAMAX(const int N, const TYPE *X, const int incX)
{
   register TYPE xmax, x0, x1, x2, x3;
   const TYPE *stX=X+N, *x, *xp=X;
   int nr;
   if (N > 0)
   {
      xmax = *X;
      xmax = fabs(xmax);
      nr = N-1;
      nr = nr - ((nr>>2)<<2);
      if (nr)
      {
         x0 = X[1];
         x0 = fabs(x0);
         if (x0 > xmax) { xmax = x0; xp++; }
         if (nr != 1)
         {
            x0 = X[2];
            x0 = fabs(x0);
            if (x0 > xmax) { xmax = x0; xp = X + 2; }
            x = X + 3;
            if (nr == 3)
            {
               x0 = X[3];
               x0 = fabs(x0);
               if (x0 > xmax) { xmax = x0; xp = X + 3; }
               x = X + 4;
            }
         }
         else x = X + 2;
      }
      else x = X + 1;
      if (N > 4)
      {
         do
         {
         ATL_pfl1R(x+12);
            x0 = *x; x1 = x[1]; x2 = x[2]; x3 = x[3]; x += 4;
            x0 = fabs(x0); x1 = fabs(x1); x2 = fabs(x2); x3 = fabs(x3);
            if (xmax >= x0 && xmax >= x1 && xmax >= x2 && xmax >= x3) continue;
            else if (x0 >= x1 && x0 >= x2 && x0 >= x3)
            { 
               xmax = x0; 
               xp = x - 4; 
            }
            else if (x1 >= x2 && x1 >= x3)
            {
               xmax = x1; 
               xp = x - 3; 
            }
            else if (x2 >= x3)
            {
               xmax = x2; 
               xp = x - 2; 
            }
            else
            {
               xmax = x3; 
               xp = x - 1; 
            }
         }
         while (x != stX);
      }
   }
   return((int)(xp-X));
}
@ROUT ciamax_avx
@extract -b @(topd)/cw.inc lang=c -define cwdate 2011
#ifndef ATL_AVX
   #error "This kernel requires AVX!"
#endif
#ifdef ATL_GAS_x8632
   #define NN %edi
   #define N  %esi
   #define N_w %si
   #define XX  %ebp
   #define X   %edx
   #define X_b %dl
   #define Imax %eax
   #define bitreg %ecx
   #define bitreg_b %cl
#else
   #define NN      %rdi
   #define N       %rsi
   #define N_w     %si
   #define XX      %r8
   #define X       %rdx
   #define X_b     %dl
   #define Imax    %rax
   #define bitreg  %rcx
   #define bitreg_b %cl
#endif

#define maxval  %ymm0
#define maxval_ %xmm0
#define absval  %ymm1
#define absval_ %xmm1
#define x0      %ymm2
#define x0_     %xmm2
#define x1      %ymm3
#define x1_     %xmm3
#define up      %ymm4
#define up_     %xmm4
#include "atlas_asm.h"
/*                   rdi/4          rsi/8
int ATL_UIAMAX(const int N, const TYPE *X, const int incX) */
.text
.globl ATL_asmdecor(ATL_UIAMAX)
ATL_asmdecor(ATL_UIAMAX):
#ifdef ATL_GAS_x8632
   #define FSIZE 12
   sub $FSIZE, %esp
   mov $0x7FFFFFFF, %eax   /* all 1s except sign bit 0 */
   movl %eax, (%esp)
   vbroadcastss (%esp), absval
/*
 * Save registers then load input arguments
 */
   movl %edi, (%esp)
   movl %esi, 4(%esp)
   movl %ebp, 8(%esp)
   movl FSIZE+4(%esp), NN
   movl FSIZE+8(%esp), X
   mov X, XX
#else
/*
 * Construct 32 bit constant with 0 in 31st bit, 1s elsewhere; can AND floats
 * with this value to get absolute value
 */
   mov $0x7FFFFFFF, %eax
   movl %eax, -8(%rsp)
   vbroadcastss -8(%rsp), absval

   mov %rsi, X
   mov %rsi, XX
#endif
/*
 * Start out assuming 1st elt is max, move ptr and dec N
 */
   mov X, Imax
   movss (X), maxval_
   andps absval_, maxval_
   movss 4(X), x1_
   andps absval_, x1_
   addps x1_, maxval_
   shufps $0x00, maxval_, maxval_   /* maxval, maxval, maxval, maxval */
   vinsertf128 $1, maxval_, maxval, maxval /* maxval in all 8 entries */
   add $8, X
   sub $1, NN
   jz DONE
/*
 * Don't even start vector loops unless we have at least 2 full iterations left
 */
   cmp $16, NN
   jb CLEANUP
/*
 * If X is only 4-byte aligned, then it cannot be aligned
 */
   test $0x3, X
   jnz UNALIGNED
/*
 * Find the first 32-byte aligned X address, and do scalar ops until we reach it
 */
   lea 31(X), N
   andw $0xFFE0, N_w  /* N = ((X+31)/32)*32 */
   cmp X, N
   jne FORCE_ALIGN
/*
 * After any peeling, X is aligned and remaining vector length in NN
 */
XALIGNED:
   mov NN, N
   and $0xFFFFFF8, N       /* make N a multiple of 8 */
   jz CLEANUP
   sub N, NN
   shl $3, N            /* N *= sizeof */
   lea (X,N), X
   neg N
   ALOOP:
      vandps (X,N), absval, x0 		/* abs(x3i) ... abs(x0r) */
      vandps 32(X,N), absval, x1 	/* abs(x7i) ... abs(x4r) */
      vhaddps x1, x0, x0   		/* abs(x7i)+abs(x7r) ... abs(x0i)+abs(x0r) */
      prefetchnta 1024(X,N)
      vcmpLEps maxval, x0, x1  		/* all 1s if maxval already has max */
      vmovmskps x1, bitreg
      cmp $0xFF, bitreg_b
      jnz VNEWMAX
AGOTMAX:
      add $64, N
   jnz ALOOP
   cmp $0, NN
   jnz CLEANUP

DONE:
   sub XX, Imax  /* # of bytes away from start */
   shr $3, Imax  /* # of elts (index) where max was found */
#ifdef ATL_GAS_x8632
   movl (%esp), %edi
   movl 4(%esp), %esi
   movl 8(%esp), %ebp
   add $FSIZE, %esp
#endif
   ret

UNALIGNED:
   mov NN, N
   shr $3, N          /* N/8 */
   jz  CLEANUP
   shl $3, N
   sub N, NN
   lea (X,N,8), X     /* X += N */
   shl $3, N          /* N *= sizeof */
   neg N
   UALOOP:
      vmovups (X,N), x0
      vandps absval, x0, x0
      vmovups 32(X,N), x1
      vandps absval, x1, x1
      prefetchnta 1024(X,N)
      vhaddps x1, x0, x0   /* abs(x7i)+abs(x7r) ... abs(x0i)+abs(x0r) */
      vcmpLEps maxval, x0, x1  /* all 1s if maxval already has max */
      vmovmskps x1, bitreg
      cmp $0xFF, bitreg_b
      jnz VNEWMAX
      UGOTMAX:
      add $64, N
   jnz UALOOP
   cmp $0, NN
   jnz CLEANUP
   jmp DONE


/*
 * When we jump to this label, we know that a new max can be found somewhere
 * in the sums stored in x0 in the following order:
 *   {x7, x6, x3, x2, x5, x4, x1, x0}
 * So, ignore old max, and just find the max of these 8 elts
 */
VNEWMAX:                                /* x7, x6, x3, x2, x5, x4, x1, x0 */
   vextractf128 $1, x0, up_             /* XX XX XX XX x7 x6 x3 x2 */
   movss x0_, maxval_
   lea (X,N), Imax
   vshufps $0x01, x0, x0, x1
   vcomiss x1_, maxval_  /* newmax if ZF=PF=0, CF=1 */
   jnc DONE1
   movss x1_, maxval_
   lea 8(X,N), Imax
DONE1:
   vcomiss up_, maxval_
   jnc DONE2
   movss up_, maxval_
   lea 16(X,N), Imax
DONE2:
   vshufps $0x01, up, up, x1
   vcomiss x1_, maxval_   /* newmax if ZF=PF=0, CF=1 */
   jnc DONE3
   movss x1_, maxval_
   lea 24(X,N), Imax
DONE3:                                /* x7, x6, x3, x2, x5, x4, x1, x0 */
   vshufps $0x02, x0, x0, x1
   vcomiss x1_, maxval_   /* newmax if ZF=PF=0, CF=1 */
   jnc DONE4
   movss x1_, maxval_
   lea 32(X,N), Imax
DONE4:                                /* x7, x6, x3, x2, x5, x4, x1, x0 */
   vshufps $0x03, x0, x0, x1
   vcomiss x1_, maxval_   /* newmax if ZF=PF=0, CF=1 */
   jnc DONE5
   movss x1_, maxval_
   lea 40(X,N), Imax
DONE5:                                  /* XX XX XX XX x7 x6 x3 x2 */
   vshufps $0x02, up, up, x1
   vcomiss x1_, maxval_   /* newmax if ZF=PF=0, CF=1 */
   jnc DONE6
   movss x1_, maxval_
   lea 48(X,N), Imax
DONE6:
   vshufps $0x03, up, up, x1
   vcomiss x1_, maxval_   /* newmax if ZF=PF=0, CF=1 */
   jnc DONE7
   movss x1_, maxval_
   lea 56(X,N), Imax
DONE7:
   vshufps $0x00, maxval, maxval, maxval
   vinsertf128 $1, maxval_, maxval, maxval
   test $0x1F, X
   jz AGOTMAX
   jmp UGOTMAX

CLEANUP:
   lea (X,NN,8), X
   neg NN
   CULOOP:
      movss (X,NN,8), x0_
      andps absval_, x0_
      movss 4(X,NN,8), x1_
      andps absval_, x1_
      addss x1_, x0_
      comiss x0_, maxval_   /* need new max if ZF=PF=0, CF=1 */
      jc SNEWMAX
      add $1, NN
   jnz CULOOP
   jmp DONE
SNEWMAX:
   movss x0_, maxval_
   lea (X,NN,8), Imax
   add $1, NN
   jnz CULOOP
   jmp DONE
/*
 * N must hold aligned X value
 */
FORCE_ALIGN:
   movss (X), x0_
   andps absval_, x0_
   movss 4(X), x1_
   andps absval_, x1_
   addss x1_, x0_
   comiss x0_, maxval_   /* need new max if ZF=PF=0, CF=1 */
   jc FA_NEWMAX
   sub $1, NN
   add $8, X
   cmp X, N
jnz FORCE_ALIGN
   vshufps $0x00, maxval, maxval, maxval  /* XX,XX,XX,XX, max,max,max,max */
   vinsertf128 $1, maxval_, maxval, maxval /* max in all 8 values */
   cmp $0, NN
   jnz XALIGNED
   jmp DONE
FA_NEWMAX:
   movss x0_, maxval_
   mov X, Imax
   sub $1, NN
   add $8, X
   cmp X, N
   jnz FORCE_ALIGN
   vshufps $0x00, maxval, maxval, maxval  /* XX,XX,XX,XX, max,max,max,max */
   vinsertf128 $1, maxval_, maxval, maxval /* max in all 8 values */
   cmp $0, NN
   jnz XALIGNED
   jmp DONE
@ROUT iamax_abs2p36_x1
#include "atlas_misc.h"
#include "atlas_prefetch.h"
#include <math.h>

#define fabs fabs
int ATL_UIAMAX(const int N, const TYPE *X, const int incX)
{
   register TYPE xmax=0, x0, x1;
   const TYPE *stX=X+N, *x, *xp=X, *xn;
   int nr;
   if (N > 0)
   {
      nr = ATL_AlignOffset(N, X, ATL_sizeof, ATL_MulBySize(4));
      if (nr) /* not aligned */
      {
         xmax = fabs(*X);
         x = X + 1;
         if (nr > 1)
         {
            stX = X + nr;
            do
            {
               x0 = *x;
               x0 = fabs(x0);
               if (x0 > xmax) { xmax = x0; xp = x; }
            }
            while(++x != stX);
         }
         nr = N - nr;
      }
      else { x = X; nr = N; }

      if (nr > 4)
      {
         stX = x + ((nr>>2)<<2);
         do
         {
            ATL_pfl1R(x+36);
            x0 = *x; x1 = x[1];
            x0 = fabs(x0); x1 = fabs(x1);
            if (xmax >= x0 && xmax >= x1) goto L1;
            else if (x0 >= x1) { xmax = x0; xp = x; }
            else { xmax = x1; xp = x + 1; }

L1:         x0 = x[2]; x1 = x[3];
            x0 = fabs(x0); x1 = fabs(x1);
            if (xmax >= x0 && xmax >= x1) goto L2;
            else if (x0 >= x1) { xmax = x0; xp = x + 2; }
            else { xmax = x1; xp = x + 3; }
L2:         x += 4;
         }
         while (x != stX);
         nr -= (nr>>2)<<2;
      }
      if (nr)
      {
         stX = x + nr;
         do
         {
            x0 = *x;
            x0 = fabs(x0);
            if (xmax >= x0) continue;
            else { xmax = x0; xp = x; }
         }
         while(++x != stX);
      }
   }
   return((int)(xp-X));
}
@ROUT iamax_abs2p24_x1
#include "atlas_misc.h"
#include "atlas_prefetch.h"
#include <math.h>

#define fabs fabs
int ATL_UIAMAX(const int N, const TYPE *X, const int incX)
{
   register TYPE xmax=0, x0, x1;
   const TYPE *stX=X+N, *x, *xp=X, *xn;
   int nr;

   if (N > 0)
   {
      nr = ATL_AlignOffset(N, X, ATL_sizeof, ATL_MulBySize(4));
      if (nr) /* not aligned */
      {
         xmax = fabs(*X);
         x = X + 1;
         if (nr > 1)
         {
            stX = X + nr;
            do
            {
               x0 = *x;
               x0 = fabs(x0);
               if (x0 > xmax) { xmax = x0; xp = x; }
            }
            while(++x != stX);
         }
         nr = N - nr;
      }
      else { x = X; nr = N; }

      if (nr > 4)
      {
         stX = x + ((nr>>2)<<2);
         do
         {
            ATL_pfl1R((x+24)); 
            x0 = *x; x1 = x[1];
            x0 = fabs(x0); x1 = fabs(x1);
            if (xmax >= x0 && xmax >= x1) goto L1;
            else if (x0 >= x1) { xmax = x0; xp = x; }
            else { xmax = x1; xp = x + 1; }

L1:         x0 = x[2]; x1 = x[3];
            x0 = fabs(x0); x1 = fabs(x1);
            if (xmax >= x0 && xmax >= x1) goto L2;
            else if (x0 >= x1) { xmax = x0; xp = x + 2; }
            else { xmax = x1; xp = x + 3; }
L2:         x += 4;
         }
         while (x != stX);
         nr -= (nr>>2)<<2;
      }
      if (nr)
      {
         stX = x + nr;
         do
         {
            x0 = *x;
            x0 = fabs(x0);
            if (xmax >= x0) continue;
            else { xmax = x0; xp = x; }
         }
         while(++x != stX);
      }
   }
   return((int)(xp-X));
}
@ROUT iamax_noabs1_x0
#include "atlas_misc.h"

int ATL_UIAMAX(const int N, const TYPE *X, const int incX)
{
   int i, imax=N;
   register TYPE pmax=0.0, nmax=0.0, x0;

   if (N < 2) return(0);
   for(i=N; i; i--, X += incX)
   {
      x0 = *X;
      if (x0 <= pmax && x0 >= nmax) continue;
      if (x0 > pmax)
      {
         nmax = -x0;
         pmax =  x0;
         imax = i;
      }
      else   /* if (x0 < nmax) */
      {
         nmax =  x0;
         pmax = -x0;
         imax = i;
      }
   }
   return(N-imax);
}
@ROUT iamax_noabs4_x1
#include "atlas_misc.h"
#include "atlas_level1.h"

int ATL_UIAMAX(const int N, const TYPE *X, const int incX)
{
   const int n = (N >> 2)<<2;
   const int nr = N - n;
   const TYPE *x=X, *stX = X + n, *xmax;
   register TYPE pmax=0.0, nmax=0.0, x0, x1, x2, x3;

   if (N < 2) return(0);
   if (n)
   {
      x0 = *x;
      x1 = x[1];
      x2 = x[2];
      x3 = x[3];
      x += 4;
      xmax = x;
      if (n != 4)
      {
         do
         {
            if (x0 <= pmax && x0 >= nmax) goto L10;
            if (x0 > pmax)
            {
               nmax = -x0;
               pmax =  x0;
               xmax = x;
            }
            else /* if (x0 < nmax) */
            {
               pmax = -x0;
               nmax =  x0;
               xmax = x;
            }
L10 :        x0 = *x;
            if (x1 <= pmax && x1 >= nmax) goto L20;
            if (x1 > pmax)
            {
               nmax = -x1;
               pmax =  x1;
               xmax = x+1;
            }
            else /* if (x1 < nmax) */
            {
               pmax = -x1;
               nmax =  x1;
               xmax = x+1;
            }
L20 :        x1 = x[1];
            if (x2 <= pmax && x2 >= nmax) goto L30;
            if (x2 > pmax)
            {
               nmax = -x2;
               pmax =  x2;
               xmax = x+2;
            }
            else /* if (x2 < nmax) */
            {
               pmax = -x2;
               nmax =  x2;
               xmax = x+2;
            }
L30 :        x2 = x[2];
            if (x3 <= pmax && x3 >= nmax) goto L40;
            if (x3 > pmax)
            {
               nmax = -x3;
               pmax =  x3;
               xmax = x+3;
            }
            else /* if (x3 < nmax) */
            {
               pmax = -x3;
               nmax =  x3;
               xmax = x+3;
            }
L40 :        x3 = x[3];
            x += 4;
         }
         while (x != stX);
      }
      if (x0 <= pmax && x0 >= nmax) goto L15;
      if (x0 > pmax)
      {
         nmax = -x0;
         pmax =  x0;
         xmax = x;
      }
      else /* if (x0 < nmax) */
      {
         pmax = -x0;
         nmax =  x0;
         xmax = x;
      }
L15 :
      if (x1 <= pmax && x1 >= nmax) goto L25;
      if (x1 > pmax)
      {
         nmax = -x1;
         pmax =  x1;
         xmax = x+1;
      }
      else /* if (x1 < nmax) */
      {
         pmax = -x1;
         nmax =  x1;
         xmax = x+1;
      }
L25 :
      if (x2 <= pmax && x2 >= nmax) goto L35;
      if (x2 > pmax)
      {
         nmax = -x2;
         pmax =  x2;
         xmax = x+2;
      }
      else /* if (x2 < nmax) */
      {
         pmax = -x2;
         nmax =  x2;
         xmax = x+2;
      }
L35 :
      if (x3 <= pmax && x3 >= nmax) goto L45;
      if (x3 > pmax)
      {
         nmax = -x3;
         pmax =  x3;
         xmax = x+3;
      }
      else /* if (x3 < nmax) */
      {
         pmax = -x3;
         nmax =  x3;
         xmax = x+3;
      }
L45 :
      xmax -= 4;
   }
   else xmax = X+1;
   if (nr)
   {
      stX = x + nr;
      do
      {
         x0 = *x++;
         if (x0 <= pmax && x0 >= nmax) continue;
         if (x0 > pmax)
         {
            nmax = -x0;
            pmax =  x0;
            xmax = x-1;
         }
         else /* if (x0 < nmax) */
         {
            pmax = -x0;
            nmax =  x0;
            xmax = x-1;
         }
      }
      while (x != stX);
   }
   if (pmax == 0.0 || nmax == 0.0) return(0);
   return(xmax-X);
}
@ROUT iamax_abs1_x0
#include "atlas_misc.h"
#include <math.h>

int ATL_UIAMAX(const int N, const TYPE *X, const int incX)
{
   register TYPE xmax, x0;
   int i, iret=0;
   if (N > 0)
   {
      xmax = *X;
      xmax = fabs(xmax); X += incX;
      for (i=1; i < N; i++, X += incX)
      {
         x0 = *X;
         x0 = fabs(x0);
         if (x0 <= xmax) continue;
         else
         {
            xmax = x0;
            iret = i;
         }
      }
   }
   return(iret);
}
@ROUT iamax_abs3_x1
#include "atlas_misc.h"
#include "atlas_prefetch.h"
#include <math.h>

int ATL_UIAMAX(const int N, const TYPE *X, const int incX)
{
   register TYPE xmax, x0, x1, x2;
   const TYPE *stX=X+N, *x, *xp=X;
   int nr;
   #ifdef ATL_AltiVec
      int cwrd;
   #endif
   if (N > 0)
   {
      #ifdef ATL_AltiVec
         cwrd = ATL_MulBySize(N)>>4;
         if (cwrd >= 64) cwrd = ATL_GetCtrl(512, (cwrd+31)>>5, 0);
         else cwrd = ATL_GetCtrl(64, (cwrd+3)>>2, 4);
         ATL_pfavR(X, cwrd, 0);
      #endif
      xmax = *X;
      xmax = fabs(xmax);
      nr = N-1;
      nr = nr - (nr/3)*3;
      if (nr)
      {
         x0 = X[1];
         x0 = fabs(x0);
         if (x0 > xmax) { xmax = x0; xp++; }
         if (nr == 2)
         {
            x0 = X[2];
            x0 = fabs(x0);
            if (x0 > xmax) { xmax = x0; xp = X + 2; }
            x = X + 3;
         }
         else x = X + 2;
      }
      else x = X + 1;
      if (N > 3)
      {
         do
         {
            x0 = *x; x1 = x[1]; x2 = x[2]; x += 3;
            x0 = fabs(x0); x1 = fabs(x1); x2 = fabs(x2);
            if (xmax >= x0 && xmax >= x1 && xmax >= x2) continue;
            else if (x0 >= x1 && x0 >= x2) { xmax = x0; xp = x - 3; }
            else if (x1 >= x2) { xmax = x1; xp = x - 2; }
            else { xmax = x2; xp = x - 1; }
         }
         while (x != stX);
      }
   }
   return((int)(xp-X));
}
@ROUT iamax_abs2_x1
#include "atlas_misc.h"
#include <math.h>

#undef Mabs
/* #define Mabs(x) ( ((x) >= 0.0) ? (x) : -(x) ) */
#define Mabs fabs
int ATL_UIAMAX(const int N, const TYPE *X, const int incX)
{
   register TYPE xmax, x0, x1;
   const TYPE *stX=X+N, *x, *xp=X;
   if (N > 0)
   {
      xmax = *X;
      xmax = Mabs(xmax);
      if ((N>>1)<<1 == N)
      {
         x0 = X[1];
         x0 = Mabs(x0);
         if (x0 > xmax) { xmax = x0; xp++; };
         x = X + 2;
      }
      else x = X + 1;
      if (N > 2)
      {
         do
         {
            x0 = *x; x1 = x[1]; x += 2;
            x0 = Mabs(x0); x1 = Mabs(x1);
            if (xmax >= x0 && xmax >= x1) continue;
            else if (x0 >= x1) { xmax = x0; xp = x - 2; }
            else { xmax = x1; xp = x - 1; }
         }
         while (x != stX);
      }
   }
   return((int)(xp-X));
}
@ROUT iamax_abs1_x1
#include "atlas_misc.h"
#include <math.h>
#include "atlas_prefetch.h"

#if defined(ATL_AltiVec) && defined(SREAL)

int ATL_UIAMAX(const int N, const TYPE *X, const int incX)
/*
 * Special code for AltiVec, using vector instructions
 */
{
   register TYPE xmax, x0, x1, x2, x3;
   const TYPE *stX=X, *x, *xp=X, *vxp;
   int i, nr;
   vector float v0, v1, v2, vmax = VECTOR_INIT(0.0f, 0.0f, 0.0f, 0.0f);
   void *vp;
   float *tp;
   int cwrd = ATL_MulBySize(N)>>4;
   char ch[64];

   if (N > 0)
   {
      if (cwrd >= 64)
      {
         cwrd = (cwrd+31)>>5;
         if (cwrd <= 256) cwrd = ATL_GetCtrl(512, cwrd <= 255 ? cwrd : 0, 0);
         else /* use all pipes */
         {
            cwrd >>= 2;
            cwrd = ATL_GetCtrl(2048, cwrd <= 255 ? cwrd : 0, 0);
            ATL_pfavR(X+128, cwrd, 1);
            ATL_pfavR(X+256, cwrd, 2);
            ATL_pfavR(X+384, cwrd, 3);
         }
      }
      else cwrd = ATL_GetCtrl(64, (cwrd+3)>>2, 4);
      ATL_pfavR(X, cwrd, 0);

      nr = ATL_AlignOffset(N, X, ATL_sizeof, ATL_MulBySize(4));
      if (nr)
      {
         x0 = *X;
         xmax = fabs(x0);
         for (i=1; i < nr; i++)
         {
            x0 = fabs(X[i]);
            if (x0 > xmax) { xmax = x0; xp = X+i; }
         }
         x = X + i;
         nr = ((N - nr)>>2)<<2;
      }
      else 
      {
         xmax = ATL_rzero;
         x = X;
         nr = (N>>2)<<2;
      }
/*      if ( (((size_t)x)>>4)<<4 != (size_t)x ) exit(-1); */
      if (nr)
      {
         stX = x + nr;
         vxp = x;
         do
         {
            v0 = vec_ldl(0, x); x += 4;
            v0 = vec_abs(v0);
            if (vec_all_ge(vmax, v0)) continue; 
            vmax = vec_max(v0, vmax);
            v0 = vec_splat(vmax, 0);
            v1 = vec_splat(vmax, 1);
            v2 = vec_splat(vmax, 2);
            vmax = vec_splat(vmax, 3);
            v0 = vec_max(v0, v1);
            vmax = vec_max(v2, vmax);
            vmax = vec_max(v0, vmax);
            vxp = x - 4;
         }
         while (x != stX);
         tp = ATL_AlignPtr((void*)ch);
         vec_st(vmax, 0, tp);
         for (i=0; i < 4; i++)
         {
            if (tp[i] > xmax) { xmax = tp[i]; xp = vxp; }
         }
         if (xp == vxp)
         {
            for (i=0; i < 4; i++) if (fabs(xp[i]) == xmax) break;
            if (i == 4) exit(-1);
            xp += i;
         }
      }
      stX = X + N;
      while (x != stX)
      {
         x0 = fabs(*x);
         if (x0 > xmax) { xmax = x0; xp = x; }
         x++;
      }
   }
   return((int)(xp-X));
}

#else

int ATL_UIAMAX(const int N, const TYPE *X, const int incX)
{
   register TYPE xmax, x0;
   int i, iret=0;
   if (N > 0)
   {
      xmax = *X;
      xmax = fabs(xmax);
      for (i=1; i < N; i++)
      {
         x0 = X[i];
         x0 = fabs(x0);
         if (x0 <= xmax) continue;
         else
         {
            xmax = x0;
            iret = i;
         }
      }
   }
   return(iret);
}

#endif
@ROUT iamax_absg_x1
#include "atlas_misc.h"
#include "atlas_prefetch.h"
#include <math.h>

int ATL_UIAMAX(const int N, const TYPE *X, const int incX)
{
   register TYPE xmax, x0;
   const TYPE *x=X+1, *stX = X + N, *mptr=X+1;
   int i, iret=0;
   if (N > 0)
   {
      xmax = *X;
      xmax = fabs(xmax);
      if (x != stX)
      {
XLOOP:
            ATL_pfl1R(x+36);
            x0 = *x++;
            x0 = fabs(x0);
            if (x0 > xmax) goto NEWMAX;
         if (x != stX) goto XLOOP;
      }
   }
   return((int)(mptr-X)-1);
NEWMAX:
   xmax = x0;
   mptr = x;
   if (x != stX) goto XLOOP;
   return((int)(mptr-X)-1);
}
@ROUT iamax_sse
#include "atlas_asm.h"

#ifdef SREAL
#ifndef ATL_SSE1
   #error "This routine requires SSE1!"
#endif

#ifdef ATL_GAS_x8632
   #define movq movl
   #define addq addl
   #define subq subl
   #define rsp  esp
   #define rax  eax
#elif !defined(ATL_GAS_x8664)
   #error "This kernel requires a gas x86 assembler!"
#endif
#ifdef ATL_GAS_x8632
   #define N	%eax
   #define X	%edx
   #define maxX	%ecx
   #define X0	%edi
   #define N8   %ebp
   #define reg1 %ebx
   #define reg2 %esi
#else
   #define N	%rax
   #define X	%rsi
   #define maxX	%rcx
   #define X0	%rdi
   #define N8   %rdx
   #define reg1	%r8
   #define reg2 %r9
#endif

#define maxval  %xmm0
#define absval	%xmm1
#define rX0     %xmm2
#define rX1     %xmm3
#define rX2     %xmm4
#define rX3     %xmm5

# IREG                   rdi            rsi
# int ATL_UIAMAX(const int N, const TYPE *X, const int incX)

# IREG                   rdi            rsi
# int ATL_UIAMAX(const int N, const TYPE *X, const int incX)
        .text
.global	ATL_asmdecor(ATL_UIAMAX)
ATL_asmdecor(ATL_UIAMAX):
#ifdef ATL_GAS_x8632
	subl	$16, %esp
   #define SOFF 0
#else
   #define SOFF -8
#endif
#
#	Temporarily store 1.0 and -1.0 to stack
#
	fld1
	fldz
	fsub	%st(1), %st
	fstps	SOFF(%rsp)
	fstps	SOFF+4(%rsp)
#
#       eax = all bits 1
#
	xorl	%eax, %eax
	notl	%eax
#
#	absval = (-1.0 ^ 1.0) = sign bit only
#
	movss	SOFF(%rsp), absval
	movss	SOFF+4(%rsp), rX0
	xorps	rX0, absval
#
#       absval = NOT(sign bit) & (all ones) == all bits but sign bet set
#
	movl	%eax, SOFF(%rsp)
	movss	SOFF(%rsp), rX0
	andnps	rX0, absval
	shufps	$0x00, absval, absval
#ifdef ATL_GAS_x8632
#
#       Save iregs
#
	movl	%edi, (%esp)
	movl	%ebp, 4(%esp)
        movl    %ebx, 8(%esp)
	movl	%esi, 12(%esp)
#
	movl	20(%esp), N
	movl	24(%esp), X
#
	movl	X, X0
	movl	X, maxX
	cmp	$1, N
	jbe	DONE
#else
#
#       X already in right register, X0 = X, maxX = X, init N
#
	movl	%edi, %eax
	movq	X, X0
	movq	X, maxX
	cmp	$1,%eax
	jbe	DONE
	cltq
#endif
        xorps   maxval, maxval
#
#       Get X aligned to 16 byte boundary
#
	test	$15, X
	jnz	FORCEALIGN

ALIGNED_STARTUP:
        movq    N, N8
        shr     $4, N8
        jz      LOOP1
	shl	$4, N8
	subq	N8, N
	shr	$4, N8
LOOP8:
   #if defined(ATL_ARCH_HAMMER64) || defined(ATL_ARCH_HAMMER32)
		prefetchnta	608(X)
   #elif defined(ATL_ARCH_P4)
                prefetchnta     464(X)
   #else
		prefetchnta	128(X)
		prefetchnta	160(X)
   #endif
        movaps  (X), rX0
        movaps  16(X), rX1
	movaps	32(X), rX2
	movaps	48(X), rX3
	andps	absval, rX0
	andps	absval, rX1
	andps	absval, rX2
	andps	absval, rX3
        cmpps   $6, maxval, rX0
        cmpps   $6, maxval, rX1
        cmpps   $6, maxval, rX2
        cmpps   $6, maxval, rX3
        movmskps        rX0, reg1
        movmskps        rX1, reg2
	shl	$4, reg1
	or	reg2, reg1
	movmskps	rX2, reg2
	shl	$4, reg1
	or	reg2, reg1
	movmskps	rX3, reg2
	shl	$4, reg1
	or	reg2, reg1

	cmp	$0, reg1
	jne	LOOP8_NEWMAX
LOOP8INC:
	addq    $64, X
	dec	N8
	jnz	LOOP8
#
#
#	Find which of 16 possible vals created maxval
#
FIND:
	movups	(maxX), rX0
	movups	16(maxX), rX1
	andps	absval, rX0
	andps	absval, rX1
	cmpps	$0, maxval, rX0
	cmpps	$0, maxval, rX1
	movmskps	rX0, reg1
	movmskps	rX1, reg2
	test	$15, reg1
	jnz	FIND_0
	test	$15, reg2
	jnz	FIND_4

	movups	32(maxX), rX0
	movups	48(maxX), rX1
	andps	absval, rX0
	andps	absval, rX1
	cmpps	$0, maxval, rX0
	cmpps	$0, maxval, rX1
	movmskps	rX0, reg1
	movmskps	rX1, reg2
	test	$15, reg1
	jnz	FIND_8
	addq	$48, maxX
	test	$1, reg2
	jnz	FIND_CU
	addq	$4, maxX
	test	$2, reg2
	jnz	FIND_CU
	addq	$4, maxX
	test	$4, reg2
	jnz	FIND_CU
	addq	$4, maxX
	jmp	FIND_CU
	
FIND_0:
	test	$1, reg1
	jnz	FIND_CU
	addq	$4, maxX
	test	$2, reg1
	jnz	FIND_CU
	addq	$4, maxX
	test	$4, reg1
	jnz	FIND_CU
	addq	$4, maxX
	jmp	FIND_CU
FIND_4:
	addq	$16, maxX
	test	$1, reg2
	jnz	FIND_CU
	addq	$4, maxX
	test	$2, reg2
	jnz	FIND_CU
	addq	$4, maxX
	test	$4, reg2
	jnz	FIND_CU
	addq	$4, maxX
	jmp	FIND_CU
FIND_8:
	addq	$32, maxX
	test	$1, reg1
	jnz	FIND_CU
	addq	$4, maxX
	test	$2, reg1
	jnz	FIND_CU
	addq	$4, maxX
	test	$4, reg1
	jnz	FIND_CU
	addq	$4, maxX
FIND_CU:
	cmp	$0, N
	jnz	LOOP1
DONE:
	movq	maxX, %rax
	subq	X0, %rax
	shr	$2, %rax
#ifdef ATL_GAS_x8632
	movl	(%esp), %edi
	movl	4(%esp), %ebp
	movl	8(%esp), %ebx
	movl	12(%esp), %esi
        addl    $16, %esp
#endif
	ret

LOOP8_NEWMAX:
	movq	X, maxX
	test	$0xFF00, reg1
	jz	L8NM_8
	movaps	(X), rX0
	movaps	16(X), rX1
	andps	absval, rX0
	andps	absval, rX1
	maxps	rX1, rX0
	movhlps	rX0, rX1
	maxps	rX1, rX0
	movaps	rX0, maxval
	shufps	$0x11,	maxval, maxval
	maxps	rX0, maxval
	movlhps	maxval, maxval
	test	$0x00FF, reg1
	jz	LOOP8INC
L8NM_8:
	movaps	32(X), rX0
	movaps	48(X), rX1
	andps	absval, rX0
	andps	absval, rX1
	maxps	rX1, rX0
	movhlps	rX0, rX1
	maxps	rX1, rX0
	movaps	rX0, rX1
	shufps	$0x11,	rX1, rX1
	maxps	rX0, rX1
	movlhps	rX1, rX1
	maxps	rX1, maxval
	jmp	LOOP8INC
#
#  Assumes X at start, and N # of iterations
#
LOOP1:
	movss	(X), rX0
	andps	absval, rX0
	comiss	rX0, maxval
	jb	NEWMAX1
LOOPINC1:
	addq	$4, X
        dec     N
	jnz	LOOP1
        shufps  $0x00, maxval, maxval
	jmp	DONE
NEWMAX1:
	movss	rX0, maxval
	movq	X, maxX
	jmp	LOOPINC1
FORCEALIGN:
	movss	(X), rX0
	andps	absval, rX0
	comiss	rX0, maxval
	jb FA_NEWMAX
FA_INC:
	dec	N
	jz	DONE
	addq	$4, X
	test	$15, X
	jnz	FORCEALIGN
#
        shufps  $0x00, maxval, maxval
        jmp     ALIGNED_STARTUP
FA_NEWMAX:
	movss	rX0, maxval
	movq	X, maxX
	jmp	FA_INC
#else

#ifndef ATL_SSE2
   #error "This routine requires SSE2!"
#endif

#ifdef ATL_GAS_x8632
   #define movq movl
   #define addq addl
   #define subq subl
   #define rsp  esp
   #define rax  eax
#elif !defined(ATL_GAS_x8664)
   #error "This kernel requires a gas x86 assembler!"
#endif
#ifdef ATL_GAS_x8632
   #define N	%eax
   #define X	%edx
   #define maxX	%ecx
   #define X0	%edi
   #define N4   %ebp
   #define reg1 %ebx
   #define reg2 %esi
#else
   #define N	%rax
   #define X	%rsi
   #define maxX	%rcx
   #define X0	%rdi
   #define N4   %rdx
   #define reg1	%r8
   #define reg2 %r9
#endif

#define maxval  %xmm0
#define absval	%xmm1
#define rX0     %xmm2
#define rX1     %xmm3
#define rX2     %xmm4
#define rX3     %xmm5

# IREG                   rdi            rsi
# int ATL_UIAMAX(const int N, const TYPE *X, const int incX)
        .text
.global	ATL_asmdecor(ATL_UIAMAX)
ATL_asmdecor(ATL_UIAMAX):
#ifdef ATL_GAS_x8632
	subl	$16, %esp
   #define SOFF 0
#else
   #define SOFF -16
#endif
#
#	Temporarily store 1.0 and -1.0 to stack
#
	fld1
	fldz
	fsub	%st(1), %st
	fstpl	SOFF(%rsp)
	fstpl	SOFF+8(%rsp)
#
#       eax = all bits 1
#
	xorl	%eax, %eax
	notl	%eax
#
#	absval = (-1.0 ^ 1.0) = sign bit only
#
	movlpd	SOFF(%rsp), absval
	movlpd	SOFF+8(%rsp), rX0
	xorpd	rX0, absval
#
#       absval = NOT(sign bit) & (all ones) == all bits but sign bet set
#
	movl	%eax, SOFF(%rsp)
	movl	%eax, 4+SOFF(%rsp)
	movlpd	SOFF(%rsp), rX0
	andnpd	rX0, absval
	unpcklpd	absval, absval
#ifdef ATL_GAS_x8632
#
#       Save iregs
#
	movl	%edi, (%esp)
	movl	%ebp, 4(%esp)
        movl    %ebx, 8(%esp)
	movl	%esi, 12(%esp)
#
	movl	20(%esp), N
	movl	24(%esp), X
#
	movl	X, X0
	movl	X, maxX
	cmp	$1, N
	jbe	DONE
#else
#
#       X already in right register, X0 = X, maxX = X, init N
#
	movl	%edi, %eax
	movq	X, X0
	movq	X, maxX
	cmp	$1,%eax
	jbe	DONE
	cltq
#endif
        xorpd   maxval, maxval
#
#       Get X aligned to 16 byte boundary
#
	test	$15, X
	jnz	FORCEALIGN

ALIGNED_STARTUP:
        movq    N, N4
        shr     $3, N4
        jz      LOOP1
	shl	$3, N4
	subq	N4, N
	shr	$3, N4
LOOP4:
        movapd  (X), rX0
        movapd  16(X), rX1
#if defined(ATL_ARCH_HAMMER64) || defined(ATL_ARCH_HAMMER32)
					prefetchnta	608(X)
#else
					prefetchnta	464(X)
					prefetchnta	496(X)
#endif
	andpd	absval, rX0
        movapd  32(X), rX2
	andpd	absval, rX1
	cmppd	$6, maxval, rX0
        movapd  48(X), rX3
	andpd	absval, rX2
        cmppd   $6, maxval, rX1
	andpd	absval, rX3
        cmppd   $6, maxval, rX2
        movmskpd        rX0, reg1
        cmppd   $6, maxval, rX3
        movmskpd        rX1, reg2
	shl	$2, reg1
	or 	reg2, reg1
        movmskpd        rX2, reg2
	shl	$2, reg1
	or 	reg2, reg1
        movmskpd        rX3, reg2
	shl	$2, reg1
	or 	reg2, reg1

        cmp     $0, reg1
        jne     LOOP4_NEWMAX
LOOP4INC:
	addq    $64, X
	dec	N4
	jnz	LOOP4
#
#
#	Find which of 8 possible vals is maxval
#
	movupd	(maxX), rX0
	movupd	16(maxX), rX1
	andpd	absval, rX0
	andpd	absval, rX1
	cmppd	$0, maxval, rX0
	cmppd	$0, maxval, rX1
	movmskpd	rX0, reg1
	movmskpd	rX1, reg2
	test	$3, reg1
	jnz	DONE_0
	test	$3, reg2
	jnz	DONE_2
	movupd	32(maxX), rX0
	movupd	48(maxX), rX1
	andpd	absval, rX0
	andpd	absval, rX1
	cmppd	$0, maxval, rX0
	cmppd	$0, maxval, rX1
	movmskpd	rX0, reg1
	movmskpd	rX1, reg2
	test	$3, reg1
	jnz	DONE_4
	addq	$48, maxX
	test	$1, reg2
	jnz	DONE_CU
	addq	$8, maxX
	jmp	DONE_CU
DONE_0:
	test	$1, reg1
	jnz	DONE_CU
	add	$8, maxX
	jmp	DONE_CU
DONE_2:
	addq	$16, maxX
	test	$1, reg2
	jnz	DONE_CU
	add	$8, maxX
	jmp	DONE_CU
DONE_4:
	addq	$32, maxX
	test	$1, reg1
	jnz	DONE_CU
	add	$8, maxX
DONE_CU:
	cmp	$0, N
	jnz	LOOP1
DONE:
	finit
	movq	maxX, %rax
	subq	X0, %rax
	shr	$3, %rax
#ifdef ATL_GAS_x8632
	movl	(%esp), %edi
	movl	4(%esp), %ebp
	movl	8(%esp), %ebx
	movl	12(%esp), %esi
        addl    $16, %esp
#endif
	ret
LOOP4_NEWMAX:
	movq	X, maxX
	movapd	(X), rX0
	movapd	16(X), rX1
	andpd	absval, rX0
	movapd	32(X), rX2
	andpd	absval, rX1
	movapd	48(X), rX3
	andpd	absval, rX2
	maxpd	rX1, rX0
	andpd	absval, rX3
	maxpd	rX3, rX2
	maxpd	rX2, rX0
	movapd	rX0, maxval
	unpcklpd rX0, rX0
	unpckhpd maxval, maxval
	maxpd	rX0, maxval
	jmp	LOOP4INC
#
#  Assumes X at start, and N # of iterations, 
#
LOOP1:
	movlpd	(X), rX0
	andpd	absval, rX0
	comisd	rX0, maxval
	jb	NEWMAX1
LOOPINC1:
	addq	$8, X
        dec     N
	jnz	LOOP1
	jmp	DONE
NEWMAX1:
	movlpd	(X), maxval
	unpcklpd	maxval, maxval
	andpd	absval, maxval
	movq	X, maxX
	jmp	LOOPINC1
FORCEALIGN:
	movlpd	(X), maxval
	dec	N
	unpcklpd	maxval, maxval
	andpd	absval, maxval
	addq	$8, X
	test	$15, X
	jnz	LOOP1
	jmp	ALIGNED_STARTUP
#endif
@ROUT iamax8_x86

#include "atlas_asm.h"

#ifdef SREAL

#ifdef ATL_GAS_x8632
   #define movq movl
   #define addq addl
   #define subq subl
   #define rsp  esp
   #define rax  eax
#elif !defined(ATL_GAS_x8664)
   #error "This kernel requires a gas x86 assembler!"
#endif
#ifdef ATL_GAS_x8632
   #define N	%eax
   #define X	%edx
   #define maxX	%ecx
   #define X0	%edi
   #define N8   %ebp
   #define reg1 %ebx
#else
   #define N	%rax
   #define X	%rsi
   #define maxX	%rcx
   #define X0	%rdi
   #define N8   %rdx
   #define reg1	%r8
#endif

#define maxval  %xmm0
#define rX0     %xmm1
#define rX1     %xmm2
#define absval	%xmm3

# IREG                   rdi            rsi
# int ATL_UIAMAX(const int N, const TYPE *X, const int incX)
        .text
.global	ATL_asmdecor(ATL_UIAMAX)
ATL_asmdecor(ATL_UIAMAX):
#ifdef ATL_GAS_x8632
	subl	$16, %esp
   #define SOFF 0
#else
   #define SOFF -8
#endif
#
#	Temporarily store 1.0 and -1.0 to stack
#
	fld1
	fldz
	fsub	%st(1), %st
	fstps	SOFF(%rsp)
	fstps	SOFF+4(%rsp)
#
#       eax = all bits 1
#
	xorl	%eax, %eax
	notl	%eax
#
#	absval = (-1.0 ^ 1.0) = sign bit only
#
	movss	SOFF(%rsp), absval
	movss	SOFF+4(%rsp), rX0
	xorps	rX0, absval
#
#       absval = NOT(sign bit) & (all ones) == all bits but sign bet set
#
	movl	%eax, SOFF(%rsp)
	movss	SOFF(%rsp), rX0
	andnps	rX0, absval
	shufps	$0x00, absval, absval
#ifdef ATL_GAS_x8632
#
#       Save iregs
#
	movl	%edi, (%esp)
	movl	%ebp, 4(%esp)
        movl    %ebx, 8(%esp)
#
	movl	20(%esp), N
	movl	24(%esp), X
#
	movl	X, X0
	movl	X, maxX
	cmp	$1, N
	jbe	DONE
#else
#
#       X already in right register, X0 = X, maxX = X, init N
#
	movl	%edi, %eax
	movq	X, X0
	movq	X, maxX
	cmp	$1,%eax
	jbe	DONE
	cltq
#endif
        xorps   maxval, maxval
#
#       Get X aligned to 16 byte boundary
#
        movq    X, N8
        shr     $4, N8
        shl     $4, N8
        cmp     X, N8
        jne     FORCEALIGN

ALIGNED_STARTUP:
        movq    N, N8
        shr     $3, N8
        jz      CLEANUP
	shl	$3, N8
	subq	N8, N
	shr	$3, N8
LOOP8:
        movaps  (X), rX0
        movaps  16(X), rX1
	andps	absval, rX0
	andps	absval, rX1
        maxps   maxval, rX0
        maxps   maxval, rX1
        cmpps   $4, maxval, rX0
   #if defined(ATL_ARCH_HAMMER64) || defined(ATL_ARCH_HAMMER32)
		prefetchnta	320(X)
   #elif defined(ATL_ARCH_P4)
                prefetchnta     464(X)
   #else
		prefetchnta	192(X)
   #endif
        cmpps   $4, maxval, rX1
        movmskps        rX0, reg1
        cmp     $0, reg1
        jne     LOOP8_1
        movmskps        rX1, reg1
        cmp     $0, reg1
        jne     LOOP8_2
LOOP8INC:
	addq    $32, X
	dec	N8
	jnz	LOOP8
#
	cmp	$0, N
	jnz	CLEANUP
DONE:
	finit
	movq	maxX, %rax
	subq	X0, %rax
	shr	$2, %rax
#ifdef ATL_GAS_x8632
	movl	(%esp), %edi
	movl	4(%esp), %ebp
	movl	8(%esp), %ebx
        addl    $16, %esp
#endif
	ret
	
LOOP8_1:
	flds	(X)
	fabs
	movq	$-12, reg1
	movq	$-16, maxX
LOOP8NML:
	flds	16(X,reg1)
	fabs
	fcomi	%st(1), %st
	jbe	LOOP8NMLINC
	mov	reg1, maxX
	fxch
LOOP8NMLINC:
	fstp	%st
	addq	$4, reg1
	jnz	LOOP8NML
#
	fstp	%st
	addq	$16, maxX
	addq	X, maxX
	movss	(maxX), maxval
	shufps	$0x00, maxval, maxval
	andps	absval, maxval
        movmskps        rX1, reg1
        cmp     $0, reg1
        jz      LOOP8INC
	movaps	16(X), rX1
	andps	absval, rX1
        maxps   maxval, rX1
        cmpps   $4, maxval, rX1
        movmskps        rX1, reg1
        cmp     $0, reg1
	je	LOOP8INC
	jmp	LOOP8_2
LOOP8_2:
	flds	16(X)
	fabs
	movq	$-12, reg1
	movq	$-16, maxX
LOOP8NML2:
	flds	32(X,reg1)
	fabs
	fcomi	%st(1), %st
	jbe	LOOP8NML2INC
	mov	reg1, maxX
	fxch
LOOP8NML2INC:
	fstp	%st
	addq	$4, reg1
	jnz	LOOP8NML2
#
	fstp	%st
	addq	$32, maxX
	addq	X, maxX
	movss	(maxX), maxval
	shufps	$0x00, maxval, maxval
	andps	absval, maxval
        jmp     LOOP8INC
CLEANUP:
	flds	(maxX)
	fabs
        
#
#  Assumes X at start, and N # of iterations, %st(0) has max so far
#
LOOP1:
	flds	(X)
	fabs
	fcomip	%st(1), %st
	ja	NEWMAX1
LOOPINC1:
	addq	$4, X
        dec     N
	jnz	LOOP1
	jmp	DONE
NEWMAX1:
	fstp	%st(0)
	flds	(X)
	fabs
	movq	X, maxX
	jmp	LOOPINC1
FORCEALIGN:
	flds	(X)
	fabs
        
LOOPALIGN:
	flds	(X)
	fabs
	fcomip	%st(1), %st
	ja	NEWMAXA
ALIGNINC:
	addq	$4, X
        movq    X, N8
        shr     $4, N8
        shl     $4, N8
        cmp     X, N8
        jz      ALIGNED
        dec     N
	jnz	LOOPALIGN
	jmp	DONE

NEWMAXA:
	fstp	%st(0)
	flds	(X)
	fabs
	movq	X, maxX
	jmp	ALIGNINC
ALIGNED:
        dec     N
	jz	DONE
        movss   (maxX), maxval
        shufps  $0x00, maxval, maxval
	andps	absval, maxval
        jmp     ALIGNED_STARTUP

#else

#ifdef ATL_GAS_x8632
   #define movq movl
   #define addq addl
   #define subq subl
   #define rsp  esp
   #define rax  eax
#elif !defined(ATL_GAS_x8664)
   #error "This kernel requires a gas x86 assembler!"
#endif
#ifdef ATL_GAS_x8632
   #define N	%eax
   #define X	%esi
   #define stX	%edx
   #define stX4	%ebx
   #define maxX	%ecx
   #define X0	%edi
#else
   #define N	%rax
   #define X	%rsi
   #define stX	%rdx
   #define stX4	%r8   
   #define maxX	%rcx
   #define X0	%rdi
#endif

# int ATL_UIAMAX(const int N, const TYPE *X, const int incX)
        .text
.global	ATL_asmdecor(ATL_UIAMAX)
ATL_asmdecor(ATL_UIAMAX):
#ifdef ATL_GAS_x8632
	subl	$12, %esp
	movl	%ebx, (%esp)
	movl	%esi, 4(%esp)
	movl	%edi, 8(%esp)
#
	movl	16(%esp), N
	movl	20(%esp), X
#
	movl	X, X0
	movl	X, maxX
	cmp	$1, N
	jbe	DONE
#else
#
#       X already in right register, init N, stX = X + N
#
	movl	%edi, %eax
	movq	X, X0
	movq	X, maxX
	cmp	$1,%eax
	jbe	DONE
	cltq
#endif
	movq	N, stX
	shl	$3, stX
	addq	X, stX
	cmp	X, stX

	fldl	(X)
	fabs
	addq	$8, X
	movq	N, stX4
	subq	$1, stX4
	shr	$3, stX4
	shl	$6, stX4
	addq	X, stX4
	cmp	stX4, X
	je	LOOP1
	ALIGN16
LOOP:
	fldl	(X)
	fabs
	fcomip	%st(1), %st
   #if defined(ATL_ARCH_P4)
	        prefetchnta	768(X)
   #else
	        prefetchnta	572(X)
   #endif
	ja	NEWMAX_1
LOOP_2:
	fldl	8(X)
	fabs
	fcomip	%st(1), %st
	ja	NEWMAX_2
LOOP_3:
	fldl	16(X)
	fabs
	fcomip	%st(1), %st
	ja	NEWMAX_3
LOOP_4:
	fldl	24(X)
	fabs
	fcomip	%st(1), %st
	ja	NEWMAX_4
LOOP_5:
	fldl	32(X)
	fabs
	fcomip	%st(1), %st
	ja	NEWMAX_5
LOOP_6:
	fldl	40(X)
	fabs
	fcomip	%st(1), %st
	ja	NEWMAX_6
LOOP_7:
	fldl	48(X)
	fabs
	fcomip	%st(1), %st
	ja	NEWMAX_7
LOOP_8:
	fldl	56(X)
	fabs
	fcomip	%st(1), %st
	ja	NEWMAX_8
LOOP_9:
	addq	$64, X
	cmp	stX4, X
	jne	LOOP

	cmp	stX4, stX
	jne	LOOP1

DONE:
	finit
	movq	maxX, %rax
	subq	X0, %rax
	shr	$3, %rax
#ifdef ATL_GAS_x8632
        movl    (%esp), %ebx
        movl    4(%esp), %esi
        movl    8(%esp), %edi
        addl    $12, %esp
#endif
	ret
NEWMAX_1:
	fstp	%st(0)
	fldl	(X)
	fabs
	movq	X, maxX
	jmp	LOOP_2
NEWMAX_2:
	fstp	%st(0)
	fldl	8(X)
	fabs
	movq	X, maxX
	addq	$8, maxX
	jmp	LOOP_3
NEWMAX_3:
	fstp	%st(0)
	fldl	16(X)
	fabs
	movq	X, maxX
	addq	$16, maxX
	jmp	LOOP_4
NEWMAX_4:
	fstp	%st(0)
	fldl	24(X)
	fabs
	movq	X, maxX
	addq	$24, maxX
	jmp	LOOP_5
NEWMAX_5:
	fstp	%st(0)
	fldl	32(X)
	fabs
	movq	X, maxX
	addq	$32, maxX
	jmp	LOOP_6
NEWMAX_6:
	fstp	%st(0)
	fldl	40(X)
	fabs
	movq	X, maxX
	addq	$40, maxX
	jmp	LOOP_7
NEWMAX_7:
	fstp	%st(0)
	fldl	48(X)
	fabs
	movq	X, maxX
	addq	$48, maxX
	jmp	LOOP_8
NEWMAX_8:
	fstp	%st(0)
	fldl	56(X)
	fabs
	movq	X, maxX
	addq	$56, maxX
	jmp	LOOP_9
#
#  Assumes X at start, and stX where to quit, %st(0) has max so far
#
LOOP1:
	fldl	(X)
	fabs
	fcomip	%st(1), %st
	ja	NEWMAX1
LOOPINC1:
	addq	$8, X
	cmp	stX, X
	jne	LOOP1
	jmp	DONE
NEWMAX1:
	fstp	%st(0)
	fldl	(X)
	fabs
	movq	X, maxX
	jmp	LOOPINC1

#endif
@ROUT ciamax_abs1_x0
#include "atlas_misc.h"
#include <math.h>

int ATL_UIAMAX(const int N, const TYPE *X, const int incX)
{
   const int incX2 = incX+incX;
   register TYPE xr, xi, xmax=0.0;
   int i, imax=0;

   for (i=0; i < N; i++)
   {
      xr = *X; xi = X[1]; X += incX2;
      xr = fabs(xr) + fabs(xi);
      if (xmax >= xr) continue;
      else { xmax = xr; imax = i; }
   }
   return(imax);
}
@ROUT ciamax_abs1_x1
#include "atlas_misc.h"
#include <math.h>

int ATL_UIAMAX(const int N, const TYPE *X, const int incX)
{
   const int incX2 = incX<<1;
   register TYPE xr, xi, xmax=0.0;
   int i, imax=0;

   for (i=0; i < N; i++)
   {
      xr = *X; xi = X[1]; X += 2;
      xr = fabs(xr) + fabs(xi);
      if (xmax >= xr) continue;
      else { xmax = xr; imax = i; }
   }
   return(imax);
}
@ROUT ciamax_abs2_x1
#include "atlas_misc.h"
#include <math.h>

#if defined(ATL_AltiVec) && defined(SCPLX)

#define ATL_NoFakePF
#include "atlas_prefetch.h"

static int ATL_amax_av(const int N, const TYPE *X, const int incX)
/*
 * Assuming aligned X && N multiple of 4, finds abs max
*/
{
   const TYPE *stX = X + N+N;
#ifdef ATL_AVgcc
   const vector unsigned char vp0 = (vector unsigned char) 
      {0, 1, 2, 3, 8, 9, 10, 11, 16, 17, 18, 19, 24, 25, 26, 27};
   const vector unsigned char vp1 = (vector unsigned char) 
      {4, 5, 6, 7, 12, 13, 14, 15, 20, 21, 22, 23, 28, 29, 30, 31};
   vector float v0, v1, v2, v3, vmax = (vector float){0.0f, 0.0f, 0.0f, 0.0f};
#else
   const vector unsigned char vp0 = (vector unsigned char) 
      (0, 1, 2, 3, 8, 9, 10, 11, 16, 17, 18, 19, 24, 25, 26, 27);
   const vector unsigned char vp1 = (vector unsigned char) 
      (4, 5, 6, 7, 12, 13, 14, 15, 20, 21, 22, 23, 28, 29, 30, 31);
   vector float v0, v1, v2, v3, vmax = (vector float)(0.0f, 0.0f, 0.0f, 0.0f);
#endif
   const TYPE *xp=X, *x=X;
   char ch[128];
   TYPE *tp;
   int i;
   register TYPE r0, r1;

   tp = ATL_AlignPtr((void*)ch);
   do
   {
      v0 = vec_ldl(0, X);
      v0 = vec_abs(v0);
      v1 = vec_ldl(0, X+4); X += 8;
      v1 = vec_abs(v1);
      v2 = vec_perm(v0, v1, vp0);
      v3 = vec_perm(v0, v1, vp1);
      v0 = vec_add(v2, v3);
      if (vec_all_ge(vmax, v0)) continue;

      vmax = vec_max(v0, vmax);
      v0 = vec_splat(vmax, 0);
      v1 = vec_splat(vmax, 1);
      v2 = vec_splat(vmax, 2);
      vmax = vec_splat(vmax, 3);
      v0 = vec_max(v0, v1);
      vmax = vec_max(v2, vmax);
      vmax = vec_max(v0, vmax);
      xp = X - 8;
   }
   while (X != stX);
   vec_st(vmax, 0, tp);
   r1 = *tp;
   for (i=0; i < 4; i++)
   {
      r0 = fabs(*xp) + fabs(xp[1]);
      if (r0 == r1) break;
      xp += 2;
   }
   if (i == 4) exit(-1);
   return(((int)(xp-x))>>1);
}

static int ATL_amax(const int N, const TYPE *X, const int incX)
{
   const int incX2 = incX+incX;
   register TYPE xr, xi, yr, yi, xmax;
   int imax=0;
   const TYPE *stX = X + N+N, *xp=X, *x;
   int cwrd = ATL_MulBySize(N)>>4;

   switch(N)
   {
   case 1:
      return(0);
   case 2:
      xr = fabs(*X) + fabs(X[1]);
      xi = fabs(X[2]) + fabs(X[3]);
      if (xr >= xi) return(0);
      else return(1);
   case 3:
      xr = fabs(*X) + fabs(X[1]);
      xi = fabs(X[2]) + fabs(X[3]);
      yr = fabs(X[4]) + fabs(X[5]);
      if (xr >= xi && xr >= yr) return(0);
      else if (xi >= yr) return(1);
      else return(2);
   default:;
   }
   xr = *X;
   xi = X[1];
   xmax = fabs(xr) + fabs(xi);
   if ((N>>1)<<1 == N)
   {
      xr = X[2]; xi = X[3];
      xr = fabs(xr) + fabs(xi);
      if (xr > xmax) { xmax = xr; xp = X + 2; }
      x = X + 4;
   }
   else x = X + 2;
   if (N > 2)
   {
      do
      {
         ATL_pfl1R(x + 32);
         xr = *x; xi = x[1]; yr = x[2]; yi = x[3];  x += 4;
         xr = fabs(xr) + fabs(xi); yr = fabs(yr) + fabs(yi);
         if (xmax >= xr && xmax >= yr) continue;
         else if (xr >= yr) { xmax = xr; xp = x - 4; }
         else { xmax = yr; xp = x - 2; }
      }
      while(x != stX);
   }
   imax = (int) (xp - X);
   return(imax>>1);
}

static int GetMax(int I0, int I1, const TYPE *X)
/*
 * Returns max of two maxes, assuming i0 is smaller index
 */
{
   register TYPE r0, r1;
   const int i0 = I0<<1, i1 = I1<<1;
   r0 = fabs(X[i0]) + fabs(X[i0+1]);
   r1 = fabs(X[i1]) + fabs(X[i1+1]);
   if (r0 >= r1) return(I0);
   else return(I1);
}

int ATL_UIAMAX(const int N, const TYPE *X, const int incX)
{
   int cwrd = ATL_MulBySize(N)>>4;
   int im=0;
   int n0, n1, n2;

   if (N > 64)
   {
      if (cwrd >= 64) 
      {
         cwrd = (cwrd+31)>>5;
         if (cwrd <= 256) cwrd = ATL_GetCtrl(512, cwrd <= 255 ? cwrd : 0, 0);
         else /* use all pipes */
         {
            cwrd >>= 2;
            cwrd = ATL_GetCtrl(2048, cwrd <= 255 ? cwrd : 0, 0);
            ATL_pfavR(X+128, cwrd, 1); 
            ATL_pfavR(X+256, cwrd, 2); 
            ATL_pfavR(X+384, cwrd, 3); 
         }
      }
      else cwrd = ATL_GetCtrl(64, (cwrd+3)>>2, 4);
      ATL_pfavR(X, cwrd, 0); 
      n0 = ATL_AlignOffset(N, X, ATL_sizeof, ATL_MulBySize(4));
      if (n0) im = ATL_amax(n0, X, incX);
      n1 = ((N - n0)>>2)<<2;
      n2 = N - n0 - n1;
      if (n1) im = GetMax(im, n0+ATL_amax_av(n1, X+n0+n0, incX), X);
      if (n2) im = GetMax(im, n0+n1+ATL_amax(n2, X+n0+n0+n1+n1, incX), X);
   }
   else im = ATL_amax(N, X, incX);
   return(im);
}

#else

int ATL_UIAMAX(const int N, const TYPE *X, const int incX)
{
   const int incX2 = incX+incX;
   register TYPE xr, xi, yr, yi, xmax;
   int imax=0;
   const TYPE *stX = X + N+N, *xp=X, *x;

   if (N > 0)
   {
      xr = *X;
      xi = X[1];
      xmax = fabs(xr) + fabs(xi);
      if ((N>>1)<<1 == N)
      {
         xr = X[2]; xi = X[3];
         xr = fabs(xr) + fabs(xi);
         if (xr > xmax) { xmax = xr; xp = X + 2; }
         x = X + 4;
      }
      else x = X + 2;
   }
   if (N > 2)
   {
      do
      {
         xr = *x; xi = x[1]; yr = x[2]; yi = x[3];  x += 4;
         xr = fabs(xr) + fabs(xi); yr = fabs(yr) + fabs(yi);
         if (xmax >= xr && xmax >= yr) continue;
         else if (xr >= yr) { xmax = xr; xp = x - 4; }
         else { xmax = yr; xp = x - 2; }
      }
      while(x != stX);
   }
   imax = (int) (xp - X);
   return(imax>>1);
}

#endif
@ROUT ciamax_noabs1_x0 ciamax_noabs1_x1
#include "atlas_misc.h"

int ATL_UIAMAX(const int N, const TYPE *X, const int incX)
{
   int i, imax=N;
   const int incx = incX<<1;
   register TYPE pmax=0, nmax=0, x0, x1, tmp;
   if (N > 1)
   {
@ROUT ciamax_noabs1_x1
      for(i=N; i; i--, X += 2)
@ROUT ciamax_noabs1_x0
      for(i=N; i; i--, X += incx)
@ROUT ciamax_noabs1_x0 ciamax_noabs1_x1
      {
         x0 = *X;
         tmp = X[1];
         x1 = x0 - tmp;
         x0 += tmp;

         if (x0 >= x1)
         {
            if (x0 <= pmax && x1 >= nmax) continue;
            if (x0 > pmax) 
            { 
               if (x1 >= nmax) { pmax = x0; nmax = -x0; }
               else if (x0-pmax >= nmax-x1) { pmax = x0; nmax = -x0; }
               else { pmax = -x1; nmax = x1; }
            }
            else { pmax = -x1; nmax = x1; }
         }
         else
         {
            if (x1 <= pmax && x0 >= nmax) continue;
            if (x1 > pmax) 
            {
               if (x0 >= nmax) { pmax = x1; nmax = -x1; }
               else if (x1-pmax >= nmax-x0) { pmax = x1; nmax = -x1; }
               else { pmax = -x0; nmax = x0; }
            }
            else { pmax = -x0; nmax = x0; }
         }
         imax = i;
      }
   }
   return(N-imax);
}
@ROUT ciamax_abs2p32
#include "atlas_misc.h"
#ifdef ATL_AltiVec
   #define ATL_NoFakePF
#endif
#include "atlas_prefetch.h"
#include <math.h>
int ATL_UIAMAX(const int N, const TYPE *X, const int incX)
{
   const int incX2 = incX+incX;
   register TYPE xr, xi, yr, yi, xmax;
   int imax=0;
   const TYPE *stX = X + N+N, *xp=X, *x;
   #ifdef ATL_AltiVec
      int cwrd = ATL_MulBySize(N)>>4;
   #endif

   if (N > 0)
   {
      #ifdef ATL_AltiVec
         if (cwrd >= 64) cwrd = ATL_GetCtrl(512, (cwrd+31)>>5, 0);
         else cwrd = ATL_GetCtrl(64, (cwrd+3)>>2, 4);
         ATL_pfavR(X, cwrd, 0);
      #endif
      xr = *X;
      xi = X[1];
      xmax = fabs(xr) + fabs(xi);
      if ((N>>1)<<1 == N)
      {
         xr = X[2]; xi = X[3];
         xr = fabs(xr) + fabs(xi);
         if (xr > xmax) { xmax = xr; xp = X + 2; }
         x = X + 4;
      }
      else x = X + 2;
   }
   if (N > 2)
   {
      do
      {
         ATL_pfl1R(x + 32);
         xr = *x; xi = x[1]; yr = x[2]; yi = x[3];  x += 4;
         xr = fabs(xr) + fabs(xi); yr = fabs(yr) + fabs(yi);
         if (xmax >= xr && xmax >= yr) continue;
         else if (xr >= yr) { xmax = xr; xp = x - 4; }
         else { xmax = yr; xp = x - 2; }
      }
      while(x != stX);
   }
   imax = (int) (xp - X);
   return(imax>>1);
}
@ROUT dcases.iamax scases.iamax
10
 1  1 iamax_abs1_x1.c     "R. Clint Whaley"
 2  1 iamax_abs2_x1.c     "R. Clint Whaley"
 3  1 iamax_abs3_x1.c     "R. Clint Whaley"
 4  0 iamax_abs1_x0.c     "R. Clint Whaley"
 5  1 iamax_noabs4_x1.c   "R. Clint Whaley"
 6  0 iamax_noabs1_x0.c   "R. Clint Whaley"
 7  1 iamax_abs2p24_x1.c  "R. Clint Whaley"
 8  1 iamax_abs2p36_x1.c  "R. Clint Whaley"
 9  1 iamax8_x86.c        "R. Clint Whaley" \
gcc
-x assembler-with-cpp
10  1 iamax_sse.c        "R. Clint Whaley" \
gcc
-x assembler-with-cpp

<ID> <incX> <rout> <author> [\]
[<CC>
 <CCFLAGS>]
@ROUT ccases.iamax
7
@ROUT zcases.iamax
6
@ROUT ccases.iamax zcases.iamax
 1  0 ciamax_abs1_x0.c     "R. Clint Whaley"
 2  1 ciamax_abs1_x1.c     "R. Clint Whaley"
 3  1 ciamax_abs2_x1.c     "R. Clint Whaley"
 4  0 ciamax_noabs1_x0.c   "R. Clint Whaley"
 5  1 ciamax_noabs1_x1.c   "R. Clint Whaley"
 6  1 ciamax_abs2p32.c     "R. Clint Whaley"
@ROUT ccases.iamax
 7  1 ciamax_avx.c         "R. Clint Whaley" \
gcc
-x assembler-with-cpp
@ROUT ccases.iamax zcases.iamax
<ID> <incX> <rout> <author> [\]
[<CC>
 <CCFLAGS>]
@ROUT rot4_x1y1
#include "atlas_misc.h"
#include "atlas_prefetch.h"

#define ATL_PFD 24

void ATL_UROT(const int N, TYPE *X, const int incX, TYPE *Y, const int incY,
              const TYPE c, const TYPE s)
/*
 * rot, no unrolling, incX=incY=1, arbitrary S & C
 */
{
   const register TYPE C=c, S=s;
   register TYPE x0, x1, y0, y1;
   TYPE *stX = X + ((N>>2)<<2), *stX0 = X + N;
   
   if (X != stX)
   {
      do
      {
         x0 = *X;   y0 = *Y;
         x1 = X[1]; y1 = Y[1];
         *X   = C*x0 + S*y0; ATL_pfl1W(X+ATL_PFD); ATL_pfl1W(Y+ATL_PFD);
         *Y   = C*y0 - S*x0; x0 = X[2];
         Y[1] = C*y1 - S*x1; y0 = Y[2];
         X[1] = C*x1 + S*y1; x1 = X[3];
         X[2] = C*x0 + S*y0; y1 = Y[3];
         Y[2] = C*y0 - S*x0;
         X[3] = C*x1 + S*y1;
         Y[3] = C*y1 - S*x1;
         Y += 4;
         X += 4;
      }
      while (X != stX);
   }
   while (X != stX0)
   {
      x0 = *X; y0 = *Y;
      *X++ = C*x0 + S*y0;
      *Y++ = C*y0 - S*x0;
   }
}
@ROUT rot1_x1y1
#include "atlas_misc.h"
void ATL_UROT(const int N, TYPE *X, const int incX, TYPE *Y, const int incY,
              const TYPE c, const TYPE s)
/*
 * rot, no unrolling, incX=incY=1, arbitrary S & C
 */
{
   int i;
   TYPE tmp;

   for (i=0; i < N; i++)
   {
      tmp = c * X[i] + s * Y[i];
      Y[i] = c * Y[i] - s * X[i];
      X[i] = tmp;
   }
}
@ROUT rot1_x0y0
#include "atlas_misc.h"
void ATL_UROT(const int N, TYPE *X, const int incX, TYPE *Y, const int incY,
              const TYPE c, const TYPE s)
/*
 * rot, no unrolling, arbitrary incX, incY, S & C
 */
{
   int i;
   TYPE tmp;

   for (i=N; i; i--, Y += incY, X += incX)
   {
      tmp = c * *X + s * *Y;
      *Y = c * *Y - s * *X;
      *X = tmp;
   }
}
@ROUT crot1_x0y0
#include "atlas_misc.h"
void ATL_UROT(const int N, TYPE *X, const int incx, TYPE *Y, const int incy,
              const TYPE c0, const TYPE s0)
/*
 * rot, no unrolling, arbitrary incX, incY, S & C
 */
{
   int i;
   const int incX = incx+incx, incY = incy+incy;
   const register TYPE c = c0, s = s0;
   register TYPE rx, ix, ry, iy;

   for (i=N; i; i--, Y += incY, X += incX)
   {
      rx = *X;  ix = X[1];
      ry = *Y;  iy = Y[1];
      *X   = c * rx + s * ry;
      X[1] = c * ix + s * iy;
      *Y   = c * ry - s * rx;
      Y[1] = c * iy - s * ix;
   }
}
@ROUT scases.rot dcases.rot
3
1 2 2 0 0 rot1_x0y0.c          "R. Clint Whaley"
2 2 2 1 1 rot1_x1y1.c          "R. Clint Whaley"
3 2 2 1 1 rot4_x1y1.c          "R. Clint Whaley"
@ROUT ccases.rot zcases.rot
1
1 2 2 0 0 crot1_x0y0.c         "R. Clint Whaley"
@ROUT ccases.rot zcases.rot scases.rot dcases.rot

<ID> <C> <S> <incX> <incY> <rout> "<author>"
@ROUT !
